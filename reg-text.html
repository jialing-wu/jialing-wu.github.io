---
layout: methods-course
title: "Text as Data"
breadcrumb: "Computational Methods"
bilingual: true
prev:
  url: reg-ml.html
  title: "Machine Learning"
next:
  url: reg-network.html
  title: "Network Analysis"
---

<style>
.problem-index{margin:0 0 8px;padding:16px 20px;border:1px solid var(--parchment);border-radius:4px;background:var(--warm)}
.problem-index-title{font-family:var(--sans);font-size:10px;font-weight:700;letter-spacing:.12em;text-transform:uppercase;color:var(--gold);margin-bottom:12px}
.problem-index a{display:block;font-size:14.5px;line-height:2;color:var(--ink-faded);text-decoration:none;transition:color .2s}
.problem-index a:hover{color:var(--red)}
.problem-index a .pi-arrow{font-family:var(--sans);font-size:11px;color:var(--gold);margin-left:6px}
.compare-grid{display:grid;grid-template-columns:1fr 1fr;gap:0;margin:16px 0;border:1px solid var(--parchment);border-radius:4px;overflow:hidden}
.compare-col{padding:18px;background:var(--paper)}
.compare-col.alt{background:var(--warm)}
.compare-label{font-family:var(--sans);font-size:10px;font-weight:700;letter-spacing:.1em;text-transform:uppercase;color:var(--red);margin-bottom:12px}
.compare-footer{grid-column:1/-1;padding:12px 18px;background:rgba(194,153,61,.05);border-top:1px solid var(--parchment);font-size:13px;color:var(--ink-faded);font-style:italic}
.compare-col p{font-size:14.5px;line-height:1.65;color:var(--ink-faded);margin-bottom:8px}
@media(max-width:860px){.compare-grid{grid-template-columns:1fr}}
</style>

<!-- HEADER -->
<div class="method-header">
  <h1>Text as Data</h1>
  <div class="method-meta">Computational Methods &middot; Advanced 14</div>
</div>

<!-- INTRO CARDS -->
<div class="intro-cards">
  <div class="intro-card">
    <div class="card-label" data-lang="en">What Is This?</div>
    <div class="card-label" data-lang="zh">这一页讲什么？</div>
    <div data-lang="en"><p>Text is the richest data source in social science — yet it is unstructured and messy. This page covers the full pipeline from raw text to statistical analysis: preprocessing, representation (turning words into numbers), discovery (unsupervised learning), measurement (scaling and sentiment), and classification (supervised learning). Organizing documents into analyzable data.</p></div>
    <div data-lang="zh"><p>文本是社会科学中最丰富的数据来源——但不结构化且混乱。本页涵盖从原始文本到统计分析的完整流程：预处理、表示（把字转为数字）、发现（无监督学习）、测量（量表化和情感）和分类（有监督学习）。把文档组织为可分析数据。</p></div>
  </div>
  <div class="intro-card">
    <div class="card-label" data-lang="en">Prerequisites</div>
    <div class="card-label" data-lang="zh">前置知识</div>
    <div data-lang="en"><p>Basic statistics. No linguistics background needed. Comfortable with matrices and counts.</p></div>
    <div data-lang="zh"><p>基础统计。无需语言学背景。熟悉矩阵和计数。</p></div>
  </div>
  <div class="intro-card">
    <div class="card-label" data-lang="en">Software &amp; Tools</div>
    <div class="card-label" data-lang="zh">软件工具</div>
    <div data-lang="en"><p>R (quanteda, stm, tidytext) or Python (scikit-learn, gensim, spaCy, transformers).</p></div>
    <div data-lang="zh"><p>R（quanteda、stm、tidytext）或 Python（scikit-learn、gensim、spaCy、transformers）。</p></div>
  </div>
</div>

<!-- PROBLEM INDEX -->
<div class="problem-index">
  <div class="problem-index-title" data-lang="en">What problem are you facing?</div>
  <div class="problem-index-title" data-lang="zh">你遇到了什么问题？</div>
  <a href="#ta-s1" data-lang="en">How do I turn text into analyzable quantitative data? <span class="pi-arrow">&rarr; &sect;1</span></a>
  <a href="#ta-s1" data-lang="zh">我怎么把文本转化为可分析的量化数据？<span class="pi-arrow">&rarr; &sect;1</span></a>
  <a href="#ta-s2" data-lang="en">I want to discover the topics present in a large corpus <span class="pi-arrow">&rarr; &sect;2</span></a>
  <a href="#ta-s2" data-lang="zh">我想发现大型语料库中存在的主题<span class="pi-arrow">&rarr; &sect;2</span></a>
  <a href="#ta-s3" data-lang="en">I want to measure sentiment, ideology, or position from text <span class="pi-arrow">&rarr; &sect;3</span></a>
  <a href="#ta-s3" data-lang="zh">我想从文本中测量情感、意识形态或立场<span class="pi-arrow">&rarr; &sect;3</span></a>
  <a href="#ta-s4" data-lang="en">I want to use large language models to label or classify text <span class="pi-arrow">&rarr; &sect;4</span></a>
  <a href="#ta-s4" data-lang="zh">我想用大语言模型对文本进行标注或分类<span class="pi-arrow">&rarr; &sect;4</span></a>
</div>

<hr class="section-divider">

<!-- SECTION 1 -->
<div class="section" id="ta-s1">
  <h2 data-lang="en">How Do I Turn Text Into Analyzable Quantitative Data?</h2>
  <h2 data-lang="zh">我怎么把文本转化为可分析的量化数据？</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You have 10,000 speeches, articles, or tweets. Your computer sees text as just characters — it doesn't understand language. Before any analysis (counting, modeling, classification), you must clean the text and convert it into a numerical format: a matrix where rows are documents and columns are features.</p>
    <p data-lang="zh"><strong>问题：</strong>你有 10,000 份演讲、文章或推文。计算机把文本看作纯字符——不理解语言。任何分析（计数、建模、分类）前，必须清洁文本并转为数字格式：矩阵，行是文档，列是特征。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Preprocessing: Cleaning and Standardizing</h3>
    <h3 data-lang="zh">预处理：清洁与标准化</h3>
    <p class="method-desc" data-lang="en">Raw text needs cleaning before anything else. Key steps: (1) <strong>Lowercasing</strong> — "The" and "the" become identical. (2) <strong>Tokenization</strong> — split "don't" into individual tokens; is it one word or two? (3) <strong>Removing punctuation and numbers</strong> — usually not meaningful. (4) <strong>Removing stopwords</strong> — common words like "the," "is," "and" carry little information. (5) <strong>Stemming or lemmatization</strong> — reduce words to root forms so "running," "ran," and "runs" become equivalent.</p>
    <p class="method-desc" data-lang="zh">原始文本需先清洁。关键步骤：（1）<strong>小写化</strong>——"The"和"the"变相同。（2）<strong>分词</strong>——把"don't"分成个词；一个词还是两个？（3）<strong>移除标点和数字</strong>——通常无意义。（4）<strong>删除停用词</strong>——"the""is""and"这类常词信息少。（5）<strong>词干提取或词形还原</strong>——把词还原到词根，"running""ran""runs"变等价。</p>
    <p class="method-desc" data-lang="en">Each choice matters. Removing stopwords works for topic modeling (topics emerge from content words) but may hurt sentiment analysis (negation like "not bad" requires "not" to be recognized). Always test your preprocessing pipeline on a small sample before applying it to your entire corpus.</p>
    <p class="method-desc" data-lang="zh">每个选择都重要。移除停用词对主题建模有效（主题从内容词出现），但可能伤害情感分析（否定如"not bad"需识别"not"）。总是在小样本上测试你的预处理流程，然后应用到整个语料库。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> Preprocessing is like mise en place in cooking — before you cook, you prep the ingredients (wash, peel, chop). The prep work is unglamorous but determines the final result.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>预处理像烹饪的准备阶段——做菜前准备食材（洗、削、切）。准备工作不起眼但决定最终结果。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Bag-of-Words and Document-Term Matrices</h3>
    <h3 data-lang="zh">词袋模型与文档-词项矩阵</h3>
    <p class="method-desc" data-lang="en"><strong>Bag-of-Words (BoW)</strong> is the simplest representation: forget word order, just count how many times each word appears in each document. Result: a <strong>Document-Term Matrix (DTM)</strong> — rows = documents, columns = unique words (terms), cells = counts. "Dog bites man" and "man bites dog" produce identical rows because only word frequencies matter.</p>
    <p class="method-desc" data-lang="zh"><strong>词袋模型 (BoW)</strong> 最简单的表示：忽略词序，只数每个词在每份文档中出现几次。结果：<strong>文档-词项矩阵 (DTM)</strong>——行=文档、列=唯一词（词项）、格子=计数。"Dog bites man"和"man bites dog"产生相同行，因为只有词频重要。</p>
    <p class="method-desc" data-lang="en"><strong>TF-IDF weighting</strong> improves on raw counts: TF = term frequency (how often a word appears in this document), IDF = inverse document frequency (log of total documents / documents containing this term). Words that are common in THIS document but rare elsewhere get high TF-IDF scores; words that appear everywhere get low scores. This surfaces the words that truly distinguish documents from one another.</p>
    <p class="method-desc" data-lang="zh"><strong>TF-IDF 加权</strong>改进原始计数：TF = 词频（一个词在该文档中出现多少），IDF = 逆文档频率（总文档数/包含该词的文档数的对数）。在该文档常见但其他地方稀有的词得高 TF-IDF；到处都出现的词得低分。这表面化真正区分文档的词。</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> BoW + TF-IDF is the default for document classification and topic modeling. Fast, interpretable, works well for medium-sized corpora. Limitation: treats all words as independent, misses that "happy" and "joyful" are synonymous.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>BoW + TF-IDF 是文档分类和主题建模的默认选择。快、可解释、对中等规模语料库有效。局限：把所有词视为独立，遗漏"happy"和"joyful"同义。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Word Embeddings: Learning Semantic Similarity</h3>
    <h3 data-lang="zh">词嵌入：学习语义相似性</h3>
    <p class="method-desc" data-lang="en"><strong>Word embeddings</strong> (Word2Vec, GloVe) represent each word as a vector of numbers (typically 100–300 dimensions). Key insight: similar words have similar vectors. The insight comes from distribution: "you shall know a word by the company it keeps" (Firth, 1957). If "cat" and "dog" appear next to the same words ("pet," "cute," "feed"), they are semantically similar.</p>
    <p class="method-desc" data-lang="zh"><strong>词嵌入</strong>（Word2Vec、GloVe）把每个词表示为数字向量（通常 100–300 维）。关键见解：相似词有相似向量。见解来自分布："通过一个词的伙伴了解它"（Firth, 1957）。如果"cat"和"dog"与相同的词相邻（"pet""cute""feed"），它们语义相似。</p>
    <p class="method-desc" data-lang="en"><strong>Word2Vec</strong> learns these vectors by training a shallow neural network: predict a word from its neighbors (CBOW) or predict neighbors from a word (Skip-gram). <strong>GloVe</strong> takes a different approach, analyzing global co-occurrence statistics. Both produce vectors where geometric distance captures meaning: vec("king") − vec("man") + vec("woman") ≈ vec("queen") — the model learned gender relationships from word patterns alone!</p>
    <p class="method-desc" data-lang="zh"><strong>Word2Vec</strong> 通过训练浅神经网络学习这些向量：从邻居预测词（CBOW）或从词预测邻居（Skip-gram）。<strong>GloVe</strong> 采不同方法，分析全局共现统计。两者产生向量，几何距离捕捉含义：vec("king") − vec("man") + vec("woman") ≈ vec("queen")——仅从词模式学会性别关系！</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> When you need the model to understand word similarity or semantic relationships. Use as features for classifiers or to detect semantic drift (how has a word's meaning changed over time?). Not ideal when every word's exact role matters (e.g., legal documents).</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>需要模型理解词相似性或语义关系时。用作分类器的特征或检测语义漂移（词义如何随时间变化？）。当每个词的确切角色重要时不理想（如法律文件）。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 2 -->
<div class="section" id="ta-s2">
  <h2 data-lang="en">I Want to Discover Topics in a Large Corpus</h2>
  <h2 data-lang="zh">我想发现大型语料库中存在的主题</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You have 50,000 documents and no labels or categories. You want to discover what themes they cover without reading them all. Topic models let the data speak for itself: they find clusters of words that co-occur frequently, infer that these clusters represent latent topics, and estimate which topics each document contains.</p>
    <p data-lang="zh"><strong>问题：</strong>你有 50,000 份文档，无标签或类别。想发现它们涵盖什么主题而不必全部读完。主题模型让数据自己"说话"：发现频繁共现的词簇，推断这些簇代表潜在主题，估计每份文档包含哪些主题。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Latent Dirichlet Allocation (LDA)</h3>
    <h3 data-lang="zh">潜在狄利克雷分配 (LDA)</h3>
    <p class="method-desc" data-lang="en"><strong>LDA</strong> (Blei et al., 2003) answers: "What are people talking about?" Imagine each document is a mixture of K latent topics, and each topic is a probability distribution over words. For example, a document on politics might be 60% politics topic, 30% economics topic, 10% culture topic. LDA's job: given the words you see, infer the hidden topics that generated them.</p>
    <p class="method-desc" data-lang="zh"><strong>LDA</strong>（Blei et al., 2003）回答："大家在讨论什么？"想象每份文档是 K 个潜在主题的混合，每个主题是词上的概率分布。例如，政治文档可能是 60% 政治主题、30% 经济主题、10% 文化主题。LDA 的任务：给定你看到的词，推断产生它们的隐藏主题。</p>
    <p class="method-desc" data-lang="en">You must choose K (number of topics). Common guidance: (1) <strong>Held-out perplexity</strong> — does the model generalize? Lower is better. (2) <strong>Topic coherence</strong> — do the top words for each topic actually co-occur in the corpus? Higher is better. (3) <strong>Human judgment</strong> — do the topics make sense substantively? Most important.</p>
    <p class="method-desc" data-lang="zh">必须选择 K（主题数）。常见指导：（1）<strong>留出困惑度</strong>——模型能泛化吗？低更好。（2）<strong>主题连贯性</strong>——每个主题的高频词在语料库中真的共现吗？高更好。（3）<strong>人工判断</strong>——主题在实质上有意义吗？最重要。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> LDA is like a librarian who has never read the books — just by seeing which words appear together (books about "monarchy" and "king" cluster together), she infers there's a "history" section, without ever opening a single book.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>LDA 像从未读过书的图书管理员——仅通过看哪些词组合（关于"monarchy"和"king"的书聚在一起），她推断有"历史"部分，不用打开任何书。</div>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> When you have large unlabeled corpora and want exploratory content analysis. Great for agenda-setting research (what topics did media cover over time?). Limitation: topics can be ambiguous; labeling them requires human interpretation.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>有大型未标注语料库且想探索性内容分析时。适合议程设置研究（媒体随时间覆盖什么主题？）。局限：主题可能模糊；标注需人工解读。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Structural Topic Model (STM) with Covariates</h3>
    <h3 data-lang="zh">带协变量的结构主题模型 (STM)</h3>
    <p class="method-desc" data-lang="en"><strong>STM</strong> (Roberts et al., 2014) extends LDA by allowing document-level metadata (author, date, source ideology) to influence both topic prevalence and topic content. Example: If you feed STM Congressional speeches with party labels, it tells you not just "what topics are discussed" but also "Democrats discuss healthcare more than Republicans" and "when both parties discuss 'economy,' they use different vocabulary."</p>
    <p class="method-desc" data-lang="zh"><strong>STM</strong>（Roberts et al., 2014）扩展 LDA，允许文档级元数据（作者、日期、来源意识形态）影响主题出现频率和主题内容。例：如果把国会演讲和政党标签输入 STM，它告诉你不仅"讨论什么主题"还有"民主党讨论医疗超过共和党"和"两党讨论'经济'时用不同词汇"。</p>
    <p class="method-desc" data-lang="en">Two effects: (1) <strong>Prevalence</strong> — how does a covariate change the proportion of each topic in a document? (2) <strong>Content</strong> — do the same topics use different words depending on the covariate? This makes STM ideal for social science: you test hypotheses about which groups discuss what.</p>
    <p class="method-desc" data-lang="zh">两种效应：（1）<strong>出现频率</strong>——协变量如何改变文档中每个主题的比例？（2）<strong>内容</strong>——相同主题根据协变量用不同词吗？这让 STM 对社会科学理想：测试关于哪些群体讨论什么的假设。</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> When you have metadata and want to connect topics to covariates theoretically. The go-to method for social scientists doing text analysis.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>有元数据且想在理论上把主题连到协变量时。社会科学家文本分析的首选。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 3 -->
<div class="section" id="ta-s3">
  <h2 data-lang="en">I Want to Measure Sentiment, Ideology, or Position From Text</h2>
  <h2 data-lang="zh">我想从文本中测量情感、意识形态或立场</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You want a single number per document: "Is this speech positive or negative?" "Is this politician left-wing or right-wing?" "Does this country cooperate with its neighbors or conflict?" Traditional scaling methods require labeled training data or reference texts. Unsupervised methods infer the scale purely from word patterns — no labels needed.</p>
    <p data-lang="zh"><strong>问题：</strong>想给每份文档一个数字："这个演讲正面还是负面？""这个政治家左翼还是右翼？""这个国家与邻国合作还是冲突？"传统量表方法需标注训练数据或参考文本。无监督方法纯从词模式推断量表——无需标签。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Dictionary Methods: Fast but Rough</h3>
    <h3 data-lang="zh">词典方法：快但粗糙</h3>
    <p class="method-desc" data-lang="en">The simplest approach: create a word list with scores. LIWC (Linguistic Inquiry and Word Count) contains psychological categories. AFINN is a sentiment dictionary: "happy" = +3, "sad" = −3, "okay" = +1. To score a document, sum the scores of all its words. Fast, transparent, reproducible — but crude.</p>
    <p class="method-desc" data-lang="zh">最简单的方法：创建有分数的词表。LIWC（语言探究和词计数）包含心理类别。AFINN 是情感词典："happy" = +3，"sad" = −3，"okay" = +1。给文档打分，把所有词的分数加起来。快、透明、可复现——但粗糙。</p>
    <p class="method-desc" data-lang="en">Problems: (1) No context — "not good" gets scored as positive (sees "good"). (2) No sarcasm — "brilliant work" sarcastically is negative, but the method sees it as positive. (3) Domain variation — "sick" is negative in medicine but positive in slang. Always validate against a hand-coded gold standard before deploying.</p>
    <p class="method-desc" data-lang="zh">问题：（1）无上下文——"not good"被评为正面（看到"good"）。（2）无讽刺——讽刺的"brilliant work"是负面，但方法看成正面。（3）领域差异——"sick"在医学是负面，在俚语是正面。部署前总是对照人工编码的黄金标准验证。</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> Quick baseline when you have clear word lists. Good for research design validation ("does this measure correlate with theory?"). Not suitable for fine-grained analysis, sarcasm, or domain-specific language.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>有清晰词表时的快速基线。适合研究设计验证（"这个措施与理论相关吗？"）。不适合细致分析、讽刺或领域特定语言。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Wordfish and Wordscores: Unsupervised Scaling</h3>
    <h3 data-lang="zh">Wordfish 和 Wordscores：无监督量表化</h3>
    <p class="method-desc" data-lang="en"><strong>Wordfish</strong> (Slapin & Proksch, 2008) discovers latent scales purely from word frequencies. It assumes most word frequency variation across documents comes from a single ideological dimension. No reference texts needed; the algorithm infers left-right position directly from who uses which words frequently. Limitation: assumes unidimensionality (one scale dominates).</p>
    <p class="method-desc" data-lang="zh"><strong>Wordfish</strong>（Slapin & Proksch, 2008）纯从词频发现潜在量表。假设文档间词频变化大多来自单个意识形态维度。无需参考文本；算法从谁频繁用哪些词直接推断左右位置。局限：假设单维性（一个量表主导）。</p>
    <p class="method-desc" data-lang="en"><strong>Wordscores</strong> (Laver et al., 2003) is supervised: you provide reference texts with known positions (clearly left-wing and right-wing party manifestos), then scale unknown texts using shared vocabulary. More flexible than Wordfish but requires you to choose reference texts — this choice introduces bias.</p>
    <p class="method-desc" data-lang="zh"><strong>Wordscores</strong>（Laver et al., 2003）是有监督的：你提供立场已知的参考文本（明确左翼和右翼政党宣言），然后用共享词汇量表未知文本。比 Wordfish 灵活但需你选择参考文本——这个选择引入偏见。</p>
    <div class="method-example" data-lang="en"><strong>Political science example:</strong> Wordfish on party manifestos from 10 European countries. No human coding of left-right positions. Result: algorithm recovers a meaningful left-right scale, closely matching known party positions, purely from which parties emphasize which words.</div>
    <div class="method-example" data-lang="zh"><strong>政治学例子：</strong>10 个欧洲国家的政党宣言上的 Wordfish。无人工编码左右位置。结果：算法恢复有意义的左右量表，密切匹配已知党派位置，纯粹从哪些政党强调哪些词。</div>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> Wordfish when dimensions are ideological and word usage captures them (political manifestos, parliamentary speeches). Wordscores when you have good reference texts and can justify the choice.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>维度是意识形态且词使用捕捉它们时用 Wordfish（政党宣言、议会演讲）。有好参考文本且能论证选择时用 Wordscores。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Deep Learning Approaches: BERT and Fine-tuning</h3>
    <h3 data-lang="zh">深度学习方法：BERT 和微调</h3>
    <p class="method-desc" data-lang="en">For nuanced sentiment or position detection, fine-tune a pre-trained language model (BERT, RoBERTa). Provide labeled training examples, and the model learns to extract contextual features (unlike word lists, BERT understands that "not good" is negative). Requires labeled data (hundreds to thousands of examples) and GPU resources, but achieves state-of-the-art accuracy.</p>
    <p class="method-desc" data-lang="zh">细致情感或立场检测，微调预训练语言模型（BERT、RoBERTa）。提供标注训练样本，模型学习提取上下文特征（不像词表，BERT 明白"not good"是负面）。需标注数据（数百到数千样本）和 GPU，但达到最先进准确率。</p>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 4 -->
<div class="section" id="ta-s4">
  <h2 data-lang="en">I Want to Use Large Language Models to Label or Classify Text</h2>
  <h2 data-lang="zh">我想用大语言模型对文本进行标注或分类</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You have thousands of documents to classify (protest events, types of repression, policy domains) but limited budget for human annotation. LLMs like GPT-4 can classify texts at scale — zero-shot (no examples), few-shot (a handful of examples), or by having humans verify a sample and training a traditional model on top. The challenge: LLMs are expensive, non-deterministic (outputs vary), and can introduce subtle biases.</p>
    <p data-lang="zh"><strong>问题：</strong>有数千文档要分类（抗议事件、压制类型、政策领域）但标注人类预算有限。LLM 如 GPT-4 能大规模分类文本——零样本（无例子）、少样本（少数例子）或人工验证样本并在其上训练传统模型。挑战：LLM 昂贵、非确定性（输出变化），且能引入微妙偏见。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Zero-Shot and Few-Shot Classification</h3>
    <h3 data-lang="zh">零样本和少样本分类</h3>
    <p class="method-desc" data-lang="en"><strong>Zero-shot</strong>: Write a prompt describing the task and categories, feed documents to GPT-4, receive classifications. No training examples needed. Astonishingly flexible — works for novel classification tasks with single-digit prompting. <strong>Few-shot</strong>: Provide 2–5 labeled examples in the prompt, then classify new documents. Performance often matches or exceeds models trained on hundreds of examples.</p>
    <p class="method-desc" data-lang="zh"><strong>零样本</strong>：写个提示词描述任务和类别，把文档输入 GPT-4，获得分类。无需训练样本。惊人灵活——对新分类任务用几句提示就行。<strong>少样本</strong>：在提示词中提供 2–5 个标注样本，然后分类新文档。性能常常等于或超过用数百样本训练的模型。</p>
    <p class="method-desc" data-lang="en"><strong>The validation pipeline:</strong> (1) GPT-4 pre-labels thousands of documents cheaply. (2) You randomly sample 200–500 documents and have human experts code them. (3) Calculate agreement between GPT-4 and humans. (4) If agreement is high (>80% F1), use GPT labels for your analysis. If not, revise the prompt, collect more human labels, or abandon LLM labeling.</p>
    <p class="method-desc" data-lang="zh"><strong>验证流程：</strong>（1）GPT-4 便宜地预标注数千文档。（2）随机抽样 200–500 文档由人类专家编码。（3）计算 GPT-4 和人类间的一致性。（4）一致性高（>80% F1）则用 GPT 标签分析。否则修改提示、收集更多人工标签或放弃。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">LLM Annotation: Cost-Quality Tradeoff</h3>
    <h3 data-lang="zh">LLM 标注：成本-质量权衡</h3>
    <p class="method-desc" data-lang="en"><strong>GPT-4</strong> is expensive but accurate. <strong>GPT-3.5 (ChatGPT)</strong> is cheaper but less reliable on complex tasks. <strong>Open-source models</strong> (LLaMA, Mistral) are free but often underperform on nuance. Key trade-off: faster annotation at the cost of quality, especially on ambiguous cases or domain-specific knowledge.</p>
    <p class="method-desc" data-lang="zh"><strong>GPT-4</strong> 贵但准确。<strong>GPT-3.5（ChatGPT）</strong> 便宜但复杂任务不可靠。<strong>开源模型</strong>（LLaMA、Mistral）免费但细微处常不足。关键权衡：更快标注但质量下降，特别是模糊情况或领域特定知识。</p>
    <p class="method-desc" data-lang="en"><strong>Reproducibility requirement:</strong> Always report the exact prompt, model version (e.g., "GPT-4-turbo, March 2024"), temperature setting, and inter-rater agreement with human coders. LLM outputs change between model versions — what worked in January may fail in March. Your results must be reproducible by others using the same model version.</p>
    <p class="method-desc" data-lang="zh"><strong>可重复性要求：</strong>总是报告确切提示词、模型版本（如"GPT-4-turbo, March 2024"）、温度设置和与人类编码者的一致性。LLM 输出随模型版本改变——1月行的东西3月可能失败。其他人用相同模型版本应能重复你的结果。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Limitations and Ethical Considerations</h3>
    <h3 data-lang="zh">局限与伦理考量</h3>
    <p class="method-desc" data-lang="en"><strong>Bias in training data:</strong> LLMs learned from human-written text, which encodes historical biases. Sentiment classifiers may rate African American Vernacular English (AAVE) as more negative. Political classifiers may have implicit assumptions about what "liberal" or "conservative" means. <strong>Solution:</strong> Audit your model's predictions across demographic groups (nationality, gender, race when applicable). Report disparate error rates transparently.</p>
    <p class="method-desc" data-lang="zh"><strong>训练数据中的偏见：</strong>LLM 从人类写的文本学习，编码了历史偏见。情感分类器可能把非裔美国人俚语（AAVE）评为更负面。政治分类器可能对"自由"或"保守"含义有隐含假设。<strong>解决：</strong>审计模型在人口群体间的预测（国籍、性别、种族如适用）。透明报告不同错误率。</p>
    <p class="method-desc" data-lang="en"><strong>Non-transparency:</strong> How does GPT-4 actually classify text? You can't open the hood. This matters for research where you need to defend your measurement approach. Use LLMs for pre-labeling, but fine-tune simpler models (logistic regression, Random Forest) on verified labels for full transparency and reproducibility.</p>
    <p class="method-desc" data-lang="zh"><strong>非透明性：</strong>GPT-4 实际如何分类文本？无法打开引擎盖。研究中需为测量方法辩护时这很重要。用 LLM 预标注，但在验证标签上微调简单模型（逻辑回归、随机森林）以获完全透明和可重复性。</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> LLMs as a labor-saving tool, never as the final decision. Use zero-shot to validate that a classification task is feasible. Then invest in human labeling or fine-tune transparent models for your final analysis.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>LLM 作节省劳动的工具，不作最终决定。用零样本验证分类任务可行。然后投资人工标注或微调透明模型用于最终分析。</div>
  </div>
</div>

<hr class="section-divider">


<!-- RESOURCES -->
<hr class="section-divider">
<div class="section" id="ta-resources">
  <h2 data-lang="en">Resources</h2>
  <h2 data-lang="zh">资源</h2>

  <div class="method-section">
    <h3 data-lang="en">Key References</h3>
    <h3 data-lang="zh">关键参考</h3>
    <ul style="font-size:14.5px;line-height:1.8;color:var(--ink-faded);margin-left:20px">
      <li>Grimmer, J., Roberts, M. E., &amp; Stewart, B. M. (2022). <em>Text as Data: A New Framework for Machine Learning and the Social Sciences.</em> Princeton University Press.</li>
      <li>Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003). Latent Dirichlet allocation. <em>Journal of Machine Learning Research</em>, 3, 993–1022.</li>
      <li>Roberts, M. E., Stewart, B. M., Tingley, D., et al. (2014). Structural topic models for open-ended survey responses. <em>American Journal of Political Science</em>, 58(4), 1064–1082.</li>
      <li>Slapin, J. B., &amp; Proksch, S.-O. (2008). A scaling model for estimating time-series party positions from texts. <em>American Journal of Political Science</em>, 52(3), 705–722.</li>
      <li>Gilardi, F., Alizadeh, M., &amp; Kubli, M. (2023). Chatgpt outperforms crowd-workers for text-annotation tasks. <em>arXiv:2303.15056</em>.</li>
    </ul>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Software Tools</h3>
    <h3 data-lang="zh">软件工具</h3>
    <ul style="font-size:14.5px;line-height:1.8;color:var(--ink-faded);margin-left:20px">
      <li><strong>R:</strong> quanteda (DTM, Wordscores, Wordfish), stm (Structural Topic Models), tidytext (tidy text workflows)</li>
      <li><strong>Python:</strong> scikit-learn (TF-IDF, classification), gensim (LDA, Word2Vec), spaCy (preprocessing, NER), transformers (BERT, fine-tuning)</li>
      <li><strong>LLM APIs:</strong> OpenAI (GPT-4, GPT-3.5), HuggingFace (open-source models)</li>
    </ul>
  </div>
</div>

<!-- PAGE NAV -->
<div class="page-nav">
  <a class="pn-link pn-prev" href="/methods/reg-ml.html">
    <span class="pn-arrow">&larr;</span>
    <span><span class="pn-title">Machine Learning</span></span>
  </a>
  <a class="pn-link pn-next" href="/methods/reg-network.html">
    <span><span class="pn-title">Network Analysis</span></span>
    <span class="pn-arrow">&rarr;</span>
  </a>
</div>
