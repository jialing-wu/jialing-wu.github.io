---
layout: methods-course
title: "Regression Analysis"
breadcrumb: "Statistics"
bilingual: true
prev:
  url: reg-dataviz.html
  title: "Data Visualization"
next:
  url: reg-mle.html
  title: "MLE & Generalized Linear Models"
---

<style>
.problem-index{margin:0 0 8px;padding:16px 20px;border:1px solid var(--parchment);border-radius:4px;background:var(--warm)}
.problem-index-title{font-family:var(--sans);font-size:10px;font-weight:700;letter-spacing:.12em;text-transform:uppercase;color:var(--gold);margin-bottom:12px}
.problem-index a{display:block;font-size:14.5px;line-height:2;color:var(--ink-faded);text-decoration:none;transition:color .2s}
.problem-index a:hover{color:var(--red)}
.problem-index a .pi-arrow{font-family:var(--sans);font-size:11px;color:var(--gold);margin-left:6px}
</style>

<!-- HEADER -->
<div class="method-header">
  <h1>Regression Analysis</h1>
  <div class="method-meta">Statistics &middot; Foundations 03</div>
</div>

<!-- INTRO CARDS -->
<div class="intro-cards">
  <div class="intro-card">
    <div class="card-label" data-lang="en">What Is This?</div>
    <div class="card-label" data-lang="zh">这一页讲什么？</div>
    <div data-lang="en"><p>Regression is the workhorse of quantitative social science. It lets you estimate how much X changes Y, while holding other things constant. This page covers OLS from first intuition to diagnostics.</p></div>
    <div data-lang="zh"><p>回归是量化社会科学的主力工具。它让你估计 X 变化多少会改变 Y，同时控制其他因素。本页从直觉到诊断，完整介绍 OLS。</p></div>
  </div>
  <div class="intro-card">
    <div class="card-label" data-lang="en">Prerequisites</div>
    <div class="card-label" data-lang="zh">前置知识</div>
    <div data-lang="en"><p>Statistical Foundations (§3 on hypothesis testing). Basic algebra.</p></div>
    <div data-lang="zh"><p>统计基础（§3 假设检验）。基础代数。</p></div>
  </div>
  <div class="intro-card">
    <div class="card-label" data-lang="en">Software &amp; Tools</div>
    <div class="card-label" data-lang="zh">软件工具</div>
    <div data-lang="en"><p>R (lm, modelsummary) or Stata (reg).</p></div>
    <div data-lang="zh"><p>R（lm、modelsummary）或 Stata（reg）。</p></div>
  </div>
</div>

<!-- PROBLEM INDEX -->
<div class="problem-index">
  <div class="problem-index-title" data-lang="en">What problem are you facing?</div>
  <div class="problem-index-title" data-lang="zh">你遇到了什么问题？</div>
  <a href="#ols-s1" data-lang="en">Can X predict Y — and by how much? <span class="pi-arrow">&rarr; &sect;1</span></a>
  <a href="#ols-s1" data-lang="zh">X 能预测 Y 吗？能预测多少？<span class="pi-arrow">&rarr; &sect;1</span></a>
  <a href="#ols-s2" data-lang="en">What if other variables are confounding my result? <span class="pi-arrow">&rarr; &sect;2</span></a>
  <a href="#ols-s2" data-lang="zh">如果其他变量在干扰我的结果怎么办？<span class="pi-arrow">&rarr; &sect;2</span></a>
  <a href="#ols-s3" data-lang="en">How do I know if my regression assumptions hold? <span class="pi-arrow">&rarr; &sect;3</span></a>
  <a href="#ols-s3" data-lang="zh">我怎么知道回归假设是否成立？<span class="pi-arrow">&rarr; &sect;3</span></a>
  <a href="#ols-s4" data-lang="en">Does the effect of X on Y change across contexts? <span class="pi-arrow">&rarr; &sect;4</span></a>
  <a href="#ols-s4" data-lang="zh">X 对 Y 的影响会随情境变化吗？<span class="pi-arrow">&rarr; &sect;4</span></a>
</div>

<hr class="section-divider">

<!-- SECTION 1 -->
<div class="section" id="ols-s1">
  <h2 data-lang="en">OLS Basics: The Line That Minimizes Errors</h2>
  <h2 data-lang="zh">OLS 基础：最小化误差的那条线</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You have data on years of education and annual income for 200 people. You want to estimate: on average, how much does each additional year of education increase income? Regression answers this. It finds the best-fit line through the scatter of points, such that the vertical distance from each point to the line (the error) is minimized. The slope of that line is your answer: the average increase in Y per unit increase in X.</p>
    <p data-lang="zh"><strong>问题：</strong>你有200个人的教育年数和年收入数据。你想估计：平均而言，每额外教育年数增加多少收入？回归回答这个。它通过点散布找到最好拟合线，使从每个点到线的垂直距离（误差）最小。那条线的斜率是你的答案：每单位X增加Y的平均增加。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">The Regression Equation and Interpretation</h3>
    <h3 data-lang="zh">回归方程与解释</h3>
    <p class="method-desc" data-lang="en">Simple regression (one predictor X) takes the form: Y = β₀ + β₁X + ε, where β₀ is the intercept (the predicted value of Y when X=0), β₁ is the slope (the change in Y for each unit increase in X), and ε is the error term (the deviation between predicted and actual Y). Ordinary Least Squares (OLS) finds the values of β₀ and β₁ that minimize the sum of squared errors.</p>
    <p class="method-desc" data-lang="zh">简单回归（一个预测变量X）采用形式：Y = β₀ + β₁X + ε，其中β₀是截距（当X=0时Y的预测值），β₁是斜率（每单位X增加时Y的变化），ε是误差项（预测和实际Y间的偏差）。普通最小二乘法（OLS）找到最小化平方误差和的β₀和β₁值。</p>
    <p class="method-desc" data-lang="en">The slope β₁ is the most important quantity. In the education-income example, suppose β₁ = 3.5 (thousand dollars). This means: each additional year of education is associated with, on average, an additional $3,500 in annual income. This is conditional on the model specification; if important variables are missing, the estimate may be biased. The intercept β₀ is often not meaningful (e.g., "predicted income when education = 0 years" is nonsensical for an adult). Report the intercept for completeness, but focus interpretation on the slope.</p>
    <p class="method-desc" data-lang="zh">斜率β₁是最重要的数量。在教育-收入例子中，假设β₁=3.5（千美元）。这意味着：每额外教育年数平均关联年收入额外3500美元。这以模型规范为条件；如果重要变量缺失，估计可能有偏。截距β₀常常没有意义（如"当教育=0年时预测收入"对成人无意义）。为完整报告截距，但聚焦解释在斜率。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> A regression line is your best guess, given incomplete information. If someone tells you "I studied for the exam," you might guess a higher score than if they say "I didn't study," but you are not certain. A regression line quantifies this guess. The slope tells you, on average, how much the outcome changes with the predictor, accounting for random variation.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>回归线是你的最佳猜测，给定不完整信息。如果有人说"我为考试学习了"，你可能猜比他们说"我没学习"更高分数，但你不确定。回归线量化这个猜测。斜率告诉你，平均而言，结果如何随预测变化，说明随机变异。</div>
    <p class="method-desc" data-lang="en">R-squared (R²) measures how well the regression line fits the data. R² ranges from 0 to 1 and represents the proportion of variance in Y explained by X. An R² of 0.3 means X explains 30% of variation in Y; 70% is explained by other factors or random noise. High R² (0.7+) is uncommon in social science — human behavior is inherently variable. A low R² does not invalidate a regression; it just means your predictor is one of many factors.</p>
    <p class="method-desc" data-lang="zh">R平方（R²）衡量回归线与数据的拟合好坏。R²范围0到1，代表Y变异中X解释的比例。R²=0.3意味着X解释30%的Y变异；70%由其他因素或随机噪声解释。高R²（0.7+）在社会科学不常见——人类行为本质上可变。低R²不使回归无效；它仅意味着你的预测是许多因素之一。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use regression when you want to estimate how much one variable affects another. Regression is ideal for observational data where you cannot run experiments. Always report β₁, its standard error, and a confidence interval. Do not rely solely on R² to judge model quality; focus on whether the effect size is practically meaningful. Do not interpret regression as causal without strong theoretical justification; correlation and confounding variables remain threats.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>当想估计一个变量多少影响另一个时用回归。回归对你无法运行实验的观察数据理想。总是报告β₁、其标准误和置信区间。不要仅依赖R²判断模型质量；聚焦效应大小是否实际有意义。没有强理论理由不要解释回归为因果；相关和混淆变量仍然是威胁。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher models the effect of years of education on annual income using 500 survey respondents. The regression yields: Income = 25,000 + 3,500 × Education. The intercept ($25k) represents predicted baseline income (perhaps from non-education factors). The slope ($3.5k per year) means each additional year of education is associated with $3,500 more annual income. If education also correlates with family wealth (a confounder), this estimate is biased upward — it conflates education's effect with wealth's effect. Adding family income as a control variable in multiple regression can address this.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>研究者用500个调查受访者对年收入建模教育年数的效应。回归产生：收入=25000+3500×教育。截距（25000美元）代表预测基线收入（也许来自非教育因素）。斜率（每年3500美元）意味着每额外教育年数关联年收入多3500美元。如果教育也与家庭财富相关（混淆），这个估计有向上偏（它混淆了教育效应与财富效应）。在多元回归中添加家庭收入作为控制变量可以解决这个。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Statistical Inference: Significance and Confidence</h3>
    <h3 data-lang="zh">统计推断：显著性与置信</h3>
    <p class="method-desc" data-lang="en">Every regression coefficient comes with a standard error (SE), which quantifies sampling variability. The larger the sample or the less noise in the data, the smaller the SE. A 95% confidence interval around β₁ tells you the range of values likely to contain the true population parameter. If the confidence interval excludes zero, the effect is statistically significant at p &lt; 0.05.</p>
    <p class="method-desc" data-lang="zh">每个回归系数带标准误（SE），量化抽样变异。样本越大或数据中噪声越少，SE越小。β₁周围的95%置信区间告诉你可能包含真实总体参数的值范围。如果置信区间排除零，效应在p &lt; 0.05统计显著。</p>
    <p class="method-desc" data-lang="en">A t-statistic is the ratio of the coefficient to its standard error: t = β₁ / SE(β₁). Large t-statistics (|t| &gt; 1.96 for large samples) correspond to small p-values. But remember the lessons from the Statistical Foundations chapter: p &lt; 0.05 does not mean the effect is large or practically important. A regression coefficient can be statistically significant but economically trivial. Report both statistical significance and effect size (the actual coefficient value) so readers can judge importance themselves.</p>
    <p class="method-desc" data-lang="zh">t统计量是系数与其标准误的比：t = β₁ / SE(β₁)。大t统计（|t| &gt; 1.96对大样本）对应小P值。但记得统计基础章的课程：p &lt; 0.05不意味着效应很大或实际重要。回归系数可以统计显著但经济上平凡。报告统计显著和效应大小（实际系数值）以便读者可以自己判断重要性。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Report p-values and confidence intervals for all coefficients, but do not treat p &lt; 0.05 as the arbitration of truth. A p-value of 0.049 is not meaningfully different from 0.051. In publications, highlight the coefficient magnitude and its practical meaning. If a coefficient's confidence interval is very wide, interpret cautiously — the precision is low. If coefficients from different studies point in the same direction, even if individually p &gt; 0.05, that convergence is evidence.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>为所有系数报告P值和置信区间，但不要把p &lt; 0.05当作真理的仲裁。P值0.049与0.051没有有意义不同。在出版中，突出系数大小及其实际含义。如果系数的置信区间很宽，谨慎解释——精度低。如果不同研究的系数指向同一方向，即使个别p &gt; 0.05，那个融合是证据。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">The Five OLS Assumptions</h3>
    <h3 data-lang="zh">五个OLS假设</h3>
    <p class="method-desc" data-lang="en">For OLS estimates to be valid, five key assumptions must (roughly) hold. (1) Linearity: The relationship between X and Y is linear (or you have correctly specified the functional form). (2) Independence: Observations are independent (not repeated measures or clustered data). (3) Homoskedasticity: The variance of errors is constant across all values of X (errors do not get bigger as X increases). (4) Normality: Errors are normally distributed. (5) No omitted variables: All important predictors are included in the model.</p>
    <p class="method-desc" data-lang="zh">为OLS估计有效，五个关键假设必须（大约）成立。(1)线性：X和Y间的关系是线性的（或你正确规定了函数形式）。(2)独立：观察独立（不是重复测量或聚类数据）。(3)同方差：误差的方差跨X所有值恒定（误差当X增加不变大）。(4)正态：误差正态分布。(5)无遗漏变量：所有重要预测在模型中包含。</p>
    <p class="method-desc" data-lang="en">These assumptions are often violated in real data. That does not mean regression is useless — it means you must check assumptions and adjust your inference accordingly. Violation of assumptions does not invalidate the point estimates (β₁ is still unbiased under most violations) but may invalidate confidence intervals and p-values. The good news: large sample sizes and robust standard errors can mitigate many problems.</p>
    <p class="method-desc" data-lang="zh">这些假设在真实数据中常常违反。这不意味着回归无用——这意味着你必须检查假设并相应调整推断。假设违反不使点估计无效（β₁在大多数违反下仍无偏）但可能使置信区间和P值无效。好消息：大样本大小和稳健标准误可以缓解许多问题。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always check OLS assumptions graphically (residual plots, Q-Q plots). Do not assume assumptions hold just because your sample is large — large samples can have heteroskedasticity or other problems. If assumptions are severely violated, consider transformations (log, square root) or alternative methods (robust regression, quantile regression). Report standard errors clearly and note any assumption violations in your methods section.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>总是图形地检查OLS假设（残差图、Q-Q图）。不要仅因样本很大就假设假设成立——大样本可以有异方差或其他问题。如假设严重违反，考虑转换（对数、平方根）或替代方法（稳健回归、分位数回归）。清晰报告标准误并在方法部分注明任何假设违反。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 2 -->
<div class="section" id="ols-s2">
  <h2 data-lang="en">Multiple Regression: Controlling for Confounders</h2>
  <h2 data-lang="zh">多元回归：控制混淆变量</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You estimate that education increases income by $3,500 per year, but you suspect this is biased. Wealthier families produce children with both more education and higher incomes, independent of education's causal effect. You need to disentangle education's true effect from the effect of family wealth. Multiple regression includes additional predictor variables (controls), and the coefficient on education changes to represent its effect while holding wealth constant. This is the power of multiple regression: isolating causal effects by controlling for confounding variables.</p>
    <p data-lang="zh"><strong>问题：</strong>你估计教育每年增加收入3500美元，但你怀疑这有偏。较富裕家庭产生既有更多教育又有更高收入的孩子，独立于教育的因果效应。你需要将教育的真实效应与家庭财富的效应分离。多元回归包含额外预测变量（控制），教育系数变化以代表其效应而保持财富恒定。这是多元回归的力量：通过控制混淆变量隔离因果效应。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">The Multiple Regression Model and "Holding Constant"</h3>
    <h3 data-lang="zh">多元回归模型与"保持恒定"</h3>
    <p class="method-desc" data-lang="en">Multiple regression takes the form: Y = β₀ + β₁X₁ + β₂X₂ + ... + βₖXₖ + ε. Each coefficient βᵢ represents the change in Y for a one-unit increase in Xᵢ, holding all other X variables constant. This "holding constant" is done mathematically by the regression algorithm — it partitions the variance in Y into components attributable to each X variable separately.</p>
    <p class="method-desc" data-lang="zh">多元回归采用形式：Y = β₀ + β₁X₁ + β₂X₂ + ... + βₖXₖ + ε。每个系数βᵢ代表给定Xᵢ一单位增加，Y的变化，保持所有其他X变量恒定。这个"保持恒定"由回归算法数学上完成——它将Y的方差分割为分别归因于每个X变量的成分。</p>
    <p class="method-desc" data-lang="en">Suppose you regress income on education alone: Income = 25,000 + 3,500 × Education. Now add family wealth as a control: Income = 20,000 + 2,000 × Education + 0.8 × Wealth. The education coefficient dropped from $3,500 to $2,000. This means: after accounting for family wealth, each additional year of education is associated with $2,000 more income (not $3,500). The difference, $1,500, is the portion of the original effect attributable to family wealth (confounding).</p>
    <p class="method-desc" data-lang="zh">假设你仅对教育回归收入：收入=25000+3500×教育。现在添加家庭财富作为控制：收入=20000+2000×教育+0.8×财富。教育系数从3500美元跌到2000美元。这意味着：解释家庭财富后，每额外教育年数关联收入多2000美元（不是3500美元）。差异1500美元是原始效应归因于家庭财富的部分（混淆）。</p>
    <p class="method-desc" data-lang="en">But multiple regression can only control for variables you include. If an important confounder is unmeasured (e.g., parental intelligence, which affects both education and income), you cannot control for it, and bias remains. This is the problem of omitted variable bias (OVB): any variable excluded from the model that correlates with both Y and included X variables biases the coefficient estimates.</p>
    <p class="method-desc" data-lang="zh">但多元回归只能控制你包含的变量。如果重要混淆未测量（如父母智力，影响教育和收入），你无法控制它，偏差仍然存在。这是遗漏变量偏差（OVB）问题：任何从模型排除的与Y和包含的X变量都相关的变量使系数估计有偏。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> A blind taste test of wine removes confounding from the label (price, prestige). Without controlling for the label, you might think expensive wine is better, but that could reflect psychology, not taste. Adding visual cues back (color, packaging) re-introduces confounding. Multiple regression is like running many experiments: you observe how Y changes as you vary X₁ while keeping X₂ constant (statistically), then repeat for other X variables.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>葡萄酒的盲味测试移除标签的混淆（价格、声望）。不控制标签，你可能认为贵葡萄酒更好，但那可能反映心理学，不是味道。添加视觉提示回（颜色、包装）重新引入混淆。多元回归像运行许多实验：你观察当你变化X₁同时保持X₂恒定（统计上）Y如何变化，然后对其他X变量重复。</div>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use multiple regression when you have measured potential confounders. Include controls that are theoretically motivated — do not throw every available variable into the model hoping something sticks. Too many controls can introduce multicollinearity (see below) and reduce precision. A common guideline: include controls for variables that plausibly cause Y. Do not include mediators (variables that are caused by X and cause Y, through which X's effect flows); including mediators breaks the causal chain you want to estimate.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>当测量了潜在混淆时用多元回归。包含理论上有动机的控制——不要把所有可用变量扔进模型希望某些起作用。太多控制可以引入多重共线性（见下）和减少精度。常见准则：包含对有理由导致Y的变量的控制。不要包含中介（被X导致且导致Y的变量，通过它X的效应流向）；包含中介破坏你想估计的因果链。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher studies whether voting for environmental parties increases environmental behavior. In a simple regression, the coefficient is strong and positive: β = 0.8 (on a 0–4 scale of behavior). But voters for environmental parties may already care about the environment (selection, not causal effect). Adding a control for "baseline environmental concern" reduces the coefficient to β = 0.2. The change reveals confounding: much of the original association reflected prior attitudes, not the voting behavior's causal effect. The controlled coefficient (0.2) better estimates the true causal effect.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>研究者研究投票环保政党是否增加环保行为。在简单回归中，系数强且正：β=0.8（在0-4行为尺度）。但环保政党投票者可能已经关心环保（选择，不是因果效应）。添加"基线环保关注"控制将系数减少到β=0.2。变化揭示混淆：原始关联大部分反映先前态度，不是投票行为的因果效应。受控系数（0.2）更好地估计真实因果效应。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Multicollinearity: When Controls Go Wrong</h3>
    <h3 data-lang="zh">多重共线性：控制何时出错</h3>
    <p class="method-desc" data-lang="en">Multicollinearity occurs when two or more predictor variables are highly correlated with each other. This does not bias the coefficients (they are still unbiased estimates), but it inflates their standard errors, making confidence intervals wider and p-values larger. In the extreme case, if two variables are perfectly correlated, the regression cannot distinguish their separate effects.</p>
    <p class="method-desc" data-lang="zh">多重共线性发生于两个或更多预测变量彼此高度相关。这不使系数有偏（它们仍然是无偏估计），但它膨胀它们的标准误，使置信区间更宽、P值更大。在极端情况，如果两个变量完全相关，回归无法区分它们的单独效应。</p>
    <p class="method-desc" data-lang="en">A simple example: if you include both temperature in Celsius and temperature in Fahrenheit as predictors, they are perfectly collinear (one is a linear transformation of the other). The regression will break — you cannot estimate separate effects because the variables are redundant. A practical example: if you include both unemployment rate and employment rate (which sum to the total labor force), they are nearly collinear. The regression will estimate very uncertain effects for each.</p>
    <p class="method-desc" data-lang="zh">一个简单例子：如果你包含摄氏度和华氏度温度作为预测，它们完全共线（一个是另一个的线性转换）。回归会断裂——你无法估计单独效应因为变量冗余。一个实际例子：如果包含失业率和就业率（总和为总劳动力），它们几乎共线。回归将为每个估计非常不确定的效应。</p>
    <p class="method-desc" data-lang="en">How to detect multicollinearity? Calculate the variance inflation factor (VIF) for each variable. VIF &gt; 5 indicates problematic multicollinearity; VIF &gt; 10 is severe. Alternatively, look at correlation matrices — if two predictors have a correlation above 0.8, worry. The solution: drop one of the correlated variables, create a composite variable (e.g., average standardized scores), or use regularization methods (ridge regression, lasso) that shrink highly uncertain coefficients.</p>
    <p class="method-desc" data-lang="zh">如何检测多重共线性？计算每个变量的方差膨胀因子（VIF）。VIF &gt; 5表示有问题的多重共线性；VIF &gt; 10是严重的。或者，看相关矩阵——如果两个预测器的相关超过0.8，担心。解决：放弃一个相关变量、创建复合变量（如平均标准化分数）或用收缩高度不确定系数的正则化方法（岭回归、套索）。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always check for multicollinearity when you have many controls. Do not include redundant variables (e.g., both "years of education" and "highest degree attained" if they measure the same thing). If you must include correlated variables, acknowledge the uncertainty in your results. Do not over-interpret individual coefficients when multicollinearity is present — focus on overall model fit and key predictors with lower VIF.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>有许多控制时总是检查多重共线性。不要包含冗余变量（如既"教育年数"又"最高达成学位"如果它们衡量同样事）。如必须包含相关变量，承认结果的不确定性。当多重共线性存在时不要过度解释单个系数——聚焦整体模型拟合和较低VIF的关键预测。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher models crime rates with predictors: poverty, unemployment, and per-capita income. These three variables are highly correlated (richer areas have lower poverty and unemployment). Each coefficient will be estimated with high uncertainty. The researcher might find the poverty coefficient is not statistically significant, not because poverty does not affect crime, but because unemployment and income capture that effect. The solution: drop one variable or combine them into a single "economic disadvantage" index. This improves interpretability and reduces multicollinearity.</div>
    <div data-lang="zh"><strong>社会科学例子：</strong>研究者用预测建模犯罪率：贫困、失业和人均收入。这三个变量高度相关（较富地区有较低贫困和失业）。每个系数将用高度不确定估计。研究者可能发现贫困系数不统计显著，不是因为贫困不影响犯罪，而是失业和收入捕获那个效应。解决：放弃一个变量或把它们合并成单个"经济劣势"指数。这改进了解释性和减少了多重共线性。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Bad Controls: Mistakes in Model Specification</h3>
    <h3 data-lang="zh">坏的控制：模型规范中的错误</h3>
    <p class="method-desc" data-lang="en">Not all variables should be controlled for. A "bad control" is a variable that is caused by the main predictor X. If you include it, you block the causal path from X to Y that you are trying to estimate. For example: Does education cause income? Suppose you regress income on education and also control for "job quality." But job quality is caused by education (more education → better jobs). By controlling for job quality, you remove part of education's effect, underestimating the true causal effect.</p>
    <p class="method-desc" data-lang="zh">不是所有变量都应该被控制。"坏控制"是一个被主要预测X导致的变量。如果你包含它，你阻断了你尝试估计的从X到Y的因果路径。例如：教育导致收入吗？假设你在教育上回归收入，也控制"工作质量"。但工作质量由教育导致（更多教育→更好工作）。通过控制工作质量，你移除了教育的一部分效应，低估了真实因果效应。</p>
    <p class="method-desc" data-lang="en">Another bad control is a "collider": a variable caused by both X and Y. If you condition on a collider (control for it), you create spurious correlation between X and Y even if none exists. This is subtle and often overlooked. An example: Does parental education affect children's educational attainment? Both parental and child education affect whether the child attends a selective school. If you analyze only children who attend selective schools (a collider), you artificially introduce correlation between parental and child education.</p>
    <p class="method-desc" data-lang="zh">另一个坏控制是"碰撞器"：由X和Y都导致的变量。如果你条件于碰撞器（控制它），你创建了X和Y间的虚假相关即使不存在。这很微妙且常常被忽视。例子：父母教育是否影响孩子的教育成就？父母和孩子教育都影响孩子是否上选择学校。如果你仅分析上选择学校的孩子（碰撞器），你人为引入了父母和孩子教育间的相关。</p>
    <p class="method-desc" data-lang="en">The rule: include controls that cause both X and Y (true confounders). Exclude variables caused by X (mediators, unless you specifically want to study indirect effects). Exclude colliders. Think about causal direction before including a variable. Drawing a directed acyclic graph (DAG) of your variables and causal relationships helps clarify which variables to control for.</p>
    <p class="method-desc" data-lang="zh">规则：包含导致X和Y的控制（真实混淆）。排除由X导致的变量（中介，除非你特别想研究间接效应）。排除碰撞器。包含变量前思考因果方向。绘制你的变量和因果关系的有向无环图（DAG）帮助澄清应该控制哪些变量。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Before specifying your regression model, list potential confounders, mediators, and colliders. Include confounders. Exclude mediators unless you are studying mediation. Be cautious about controlling for post-treatment variables (those measured after X occurs) — they often act as colliders. When in doubt, show results with and without a controversial control variable and discuss both.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>在规定你的回归模型前，列举潜在混淆、中介和碰撞器。包含混淆。除非你研究中介，排除中介。小心控制处理后变量（那些X发生后测量的）——它们常常作为碰撞器。不确定时，展示结果有和没有有争议的控制变量并讨论两者。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher studies whether attending university increases political engagement. Controls might include: age (confounder: older people both go to university and are more engaged), income (confounder), and parental education (confounder). Bad controls: employment (mediated by university — university causes employment), or "political interest at age 25" (outcome, not a control). The researcher should include age, income, and parental education but exclude employment and later political interest measures.</div>
    <div data-lang="zh"><strong>社会科学例子：</strong>研究者研究上大学是否增加政治参与。控制可能包括：年龄（混淆：年长人既上大学也更参与）、收入（混淆）和父母教育（混淆）。坏控制：就业（由大学中介——大学导致就业），或"25岁时政治兴趣"（结果，不是控制）。研究者应包含年龄、收入和父母教育但排除就业和后来的政治兴趣措施。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 3 -->
<div class="section" id="ols-s3">
  <h2 data-lang="en">Regression Diagnostics: Are the Assumptions Met?</h2>
  <h2 data-lang="zh">回归诊断：假设是否成立？</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You run a regression and get coefficient estimates. But have you checked whether the data satisfy OLS assumptions? Violations of assumptions do not invalidate the point estimates but may invalidate standard errors, p-values, and confidence intervals. Residual plots (plots of errors) visually reveal assumption violations. This section covers how to diagnose problems and what to do about them.</p>
    <p data-lang="zh"><strong>问题：</strong>你运行回归并得到系数估计。但你检查了数据是否满足OLS假设吗？假设违反不使点估计无效但可能使标准误、P值和置信区间无效。残差图（误差的图）直观揭示假设违反。这部分介绍如何诊断问题和怎么做。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Residual Plots: What Each Pattern Means</h3>
    <h3 data-lang="zh">残差图：每个模式代表什么</h3>
    <p class="method-desc" data-lang="en">A residual is the difference between observed and predicted Y: e = Y - Ŷ. A residual plot graphs fitted values (predicted Y) on the x-axis and residuals on the y-axis. Key patterns tell you what is wrong: (1) A funnel shape (residuals spread wider as fitted values increase) indicates heteroskedasticity: error variance is not constant. (2) A curved pattern suggests nonlinearity: the relationship between X and Y is not linear. (3) Points above/below a horizontal line indicate outliers or extreme values.</p>
    <p class="method-desc" data-lang="zh">残差是观察和预测Y的差：e = Y - Ŷ。残差图在x轴上绘制拟合值（预测Y），在y轴上绘制残差。关键模式告诉你什么出错了：(1)漏斗形（残差当拟合值增加时更宽地散布）表示异方差：误差方差不恒定。(2)曲线模式暗示非线性：X和Y间的关系不是线性。(3)上方/下方点表示异常值或极端值。</p>
    <p class="method-desc" data-lang="en">A good residual plot shows random scatter around zero with no pattern. Bad residual plots show systematic patterns. For example, in a study of income, heteroskedasticity is common: high-income individuals have much more variation in spending than low-income individuals. If you regress spending on income, the residual plot shows a funnel — the assumption of homoskedasticity is violated.</p>
    <p class="method-desc" data-lang="zh">好的残差图在零周围显示随机散布，无模式。坏的残差图显示系统模式。例如，在收入研究中，异方差常见：高收入个人的支出变异比低收入个人多得多。如果你在收入上回归支出，残差图显示漏斗——同方差假设被违反。</p>
    <p class="method-desc" data-lang="en">A Q-Q plot (quantile-quantile plot) tests normality of residuals. It plots the quantiles of the residuals against the quantiles of a normal distribution. If residuals are normally distributed, points fall on a diagonal line. Deviations from the line (especially at the tails) indicate non-normality. Non-normality is less critical than other violations (with large samples, the Central Limit Theorem makes inference robust even if residuals are non-normal), but it is worth noting.</p>
    <p class="method-desc" data-lang="zh">Q-Q图（分位数-分位数图）测试残差的正态。它绘制残差的分位数对正态分布的分位数。如果残差正态分布，点落在对角线。从线的偏差（特别在尾部）表示非正态。非正态比其他违反不那么关键（对大样本，中心极限定理使推断稳健即使残差非正态），但值得注明。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always plot residuals. If heteroskedasticity is apparent, use robust standard errors (which adjust for varying error variance). If nonlinearity is evident, try transforming X (log, polynomial) or using a nonlinear model. If outliers are extreme, investigate whether they are data errors; if valid, either keep them (with robust methods) or report results with and without them. Large samples are forgiving — some heteroskedasticity or non-normality is tolerable if the effect is not driven by outliers.</div>
    <div data-lang="zh"><strong>何时用/不用：</strong>总是绘制残差。如果异方差明显，用稳健标准误（它们调整变化误差方差）。如果非线性明显，尝试转换X（对数、多项式）或使用非线性模型。如果异常值是极端的，调查它们是否是数据错误；如有效，要么保留它们（用稳健方法），要么报告有和没有它们的结果。大样本是宽容的——如果效应不被异常值驱动，一些异方差或非正态是可容忍的。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Heteroskedasticity and Robust Standard Errors</h3>
    <h3 data-lang="zh">异方差与稳健标准误</h3>
    <p class="method-desc" data-lang="en">Heteroskedasticity is the violation of the constant-variance assumption. It is extremely common in social science data. For example, wealthy people's spending varies much more than poor people's spending (everyone poor spends most of their income on basics; wealthy people have discretion). Income inequality studies almost always have heteroskedasticity: high-income earners vary more in their behavior.</p>
    <p class="method-desc" data-lang="zh">异方差是恒定方差假设的违反。在社会科学数据中极其常见。例如，富人的支出比穷人的支出变异多得多（所有穷人花大部分收入在基础；富人有选择权）。收入不平等研究几乎总是有异方差：高收入赚者在他们的行为变异多。</p>
    <p class="method-desc" data-lang="en">The problem with heteroskedasticity: it invalidates standard hypothesis tests. The standard error formula assumes constant variance, so it is wrong when variance is not constant. The good news: you do not need to re-estimate coefficients. Just use robust standard errors (also called Huber-White standard errors). These adjust for heteroskedasticity and give you valid confidence intervals and p-values even when error variance varies.</p>
    <p class="method-desc" data-lang="zh">异方差的问题：它使标准假设检验无效。标准误公式假设恒定方差，所以当方差不恒定时是错的。好消息：你不需要重新估计系数。仅用稳健标准误（也叫Huber-White标准误）。这些调整异方差并给你有效置信区间和P值即使误差方差变化。</p>
    <p class="method-desc" data-lang="en">Robust SEs are almost always larger than ordinary SEs because they are more conservative (honest). Confidence intervals become wider, and some effects lose statistical significance. This is a feature, not a bug — it reflects the true uncertainty. In modern practice, you should always report robust SEs (they hurt when the OLS assumption holds and help when it does not, making them a good default). Some researchers report both ordinary and robust SEs to show the sensitivity of results to the choice.</p>
    <p class="method-desc" data-lang="zh">稳健SE几乎总是比普通SE大因为它们更保守（诚实）。置信区间变宽，一些效应失去统计显著。这是特征，不是缺陷——它反映真实不确定性。在现代实践中，你应该总是报告稳健SE（当OLS假设成立时它们伤害，当不成立时帮助，使它们是好默认）。一些研究者报告普通和稳健SE两者以展示结果对选择的敏感性。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use robust standard errors by default in any regression. In R, use the sandwich or lmtest packages; in Stata, use regress ..., robust. Always report robust SEs in publications. If robust and ordinary SEs differ drastically, investigate heteroskedasticity further. Do not assume homoskedasticity holds just because you have a small sample — small samples can have heteroskedasticity too.</div>
    <div data-lang="zh"><strong>何时用/不用：</strong>在任何回归中默认使用稳健标准误。在R中，使用sandwich或lmtest包；在Stata中，使用regress ...，robust。总是在出版中报告稳健SE。如果稳健和普通SE差异很大，进一步调查异方差。不要仅因样本小就假设同方差成立——小样本也可以有异方差。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher studies how family income affects children's educational outcomes. Ordinary regression yields: Outcome = 20 + 0.15 × Income, SE = 0.03, p &lt; 0.001. Robust SEs are: SE = 0.08. The robust confidence interval is [−0.01, 0.31], compared to the ordinary CI [0.09, 0.21]. The ordinary SE suggested tight precision; the robust SE reveals greater uncertainty. This is because families with high income have more variability in children's outcomes (heteroskedasticity). The robust result is more honest about the true precision.</div>
    <div data-lang="zh"><strong>社会科学例子：</strong>研究者研究家庭收入如何影响儿童教育结果。普通回归产生：结果=20+0.15×收入，SE=0.03，p&lt;0.001。稳健SE是：SE=0.08。稳健置信区间是[−0.01, 0.31]，比普通CI [0.09, 0.21]。普通SE暗示紧精度；稳健SE揭示更大不确定性。这是因为高收入家庭在儿童结果有更多变异性（异方差）。稳健结果对真实精度更诚实。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Outliers, Influential Points, and Robustness Checks</h3>
    <h3 data-lang="zh">异常值、有影响点与稳健性检查</h3>
    <p class="method-desc" data-lang="en">An outlier is an observation with a large residual (far from the regression line). An influential point is an outlier that, if removed, substantially changes the regression coefficients. Some influential points are legitimate data; others are errors or special cases that distort the model. Identifying influential points is important because a few extreme cases can drive conclusions.</p>
    <p class="method-desc" data-lang="zh">异常值是有大残差的观察（远离回归线）。有影响点是一个异常值，如果移除，大幅改变回归系数。一些有影响点是合法数据；其他是错误或特殊情况扭曲模型。识别有影响点很重要因为少数极端情况可以驱动结论。</p>
    <p class="method-desc" data-lang="en">Methods for detecting influential points: Calculate Cook's distance (a measure of how much removing an observation changes the regression). Cook's distance &gt; 4/n (where n is sample size) suggests influence. Alternatively, look at leverage (how far an observation is from the center of X) and studentized residuals (standardized residuals accounting for leverage). An observation with high leverage and large residual is influential.</p>
    <p class="method-desc" data-lang="zh">检测有影响点的方法：计算Cook距离（移除观察多少改变回归的度量）。Cook距离&gt; 4/n（其中n是样本大小）暗示影响。或者，看杠杆（观察距X中心多远）和学生化残差（说明杠杆的标准化残差）。有高杠杆和大残差的观察是有影响的。</p>
    <p class="method-desc" data-lang="en">What to do about influential points? First, investigate. Is it a data entry error? A special case (e.g., a billionaire in a sample of typical income earners)? If it is an error, fix or remove it. If it is real but extreme, you have options: report results both with and without the point; use robust regression (which downweights extreme points); or use quantile regression (which fits a line through the median rather than the mean). Transparency is key: inform readers about influential cases, even if you ultimately include them.</p>
    <p class="method-desc" data-lang="zh">关于有影响点做什么？首先，调查。是数据输入错误吗？特殊情况（如一个亿万富翁在典型收入赚者样本中）？如果是错误，修复或移除它。如果真实但极端，你有选项：报告有和没有点的结果；用稳健回归（它贬低极端点）；或使用分位数回归（它通过中位数而非平均值拟合线）。透明度关键：通知读者关于有影响情况，即使你最终包括它们。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always check for influential points in your regression. Report Cook's distance or leverage diagnostics in appendices. When influential points exist, show results with and without them. If excluding influential points substantially changes your conclusions, that is important — readers need to know the findings are not robust. Use robust regression or quantile regression when extreme outliers are present and legitimate.</div>
    <div data-lang="zh"><strong>何时用/不用：</strong>总是检查你回归的有影响点。在附录中报告Cook距离或杠杆诊断。当有影响点存在时，显示有和没有它们的结果。如果排除有影响点大幅改变你的结论，那很重要——读者需要知道发现不稳健。当极端异常值存在且合法时用稳健回归或分位数回归。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher studies the relationship between government spending and economic growth using 50 countries. Ordinary OLS gives: Growth = 2 + 0.3 × Spending. But one country (Norway, with very high spending and high growth) is highly influential. Removing Norway yields: Growth = 2 + 0.05 × Spending (a much weaker relationship). Both results are valid, but they tell different stories. The honest approach: report both, investigate why Norway is different (oil wealth causes both), and discuss whether the relationship holds for typical economies.</div>
    <div data-lang="zh"><strong>社会科学例子：</strong>研究者用50个国家研究政府支出和经济增长的关系。普通OLS给出：增长=2+0.3×支出。但一个国家（挪威，有非常高支出和高增长）高度有影响。移除挪威给出：增长=2+0.05×支出（更弱关系）。两个结果都有效，但它们讲不同故事。诚实方法：报告两者，调查为什么挪威不同（石油财富导致两者），并讨论关系是否对典型经济成立。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 4 -->
<div class="section" id="ols-s4">
  <h2 data-lang="en">Interactions and Nonlinearity</h2>
  <h2 data-lang="zh">交互项与非线性</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You estimate that economic growth increases government approval by 1% per point of growth. But does this relationship hold equally for all countries? Maybe in democracies, where voters hold leaders accountable and see economic conditions clearly, growth matters more. In autocracies, voters have less information and may credit growth less to leaders. The effect of X on Y might depend on another variable Z. This is an interaction: the effect is not constant but varies across contexts.</p>
    <p data-lang="zh"><strong>问题：</strong>你估计经济增长每增长一点增加政府赞成1%。但这个关系对所有国家同样成立吗？也许在民主制，选民审查领导人并清楚看到经济条件，增长更重要。在独裁制，选民有较少信息，可能较少归功于领导人。X对Y的效应可能取决于另一个变量Z。这是交互：效应不是恒定而是跨背景变化。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Interaction Terms: What the Coefficient Means</h3>
    <h3 data-lang="zh">交互项：系数代表什么</h3>
    <p class="method-desc" data-lang="en">An interaction term is a product of two variables: X₁ × X₂. When included in a regression, it tests whether the effect of X₁ on Y depends on the level of X₂. The model is: Y = β₀ + β₁X₁ + β₂X₂ + β₃(X₁ × X₂) + ε. The coefficient β₃ is the interaction effect: it tells you how much the effect of X₁ changes as X₂ increases by one unit.</p>
    <p class="method-desc" data-lang="zh">交互项是两个变量的乘积：X₁ × X₂。在回归中包含时，它测试X₁对Y的效应是否取决于X₂的水平。模型是：Y = β₀ + β₁X₁ + β₂X₂ + β₃(X₁ × X₂) + ε。系数β₃是交互效应：它告诉你当X₂增加一单位时X₁的效应变化多少。</p>
    <p class="method-desc" data-lang="en">Example: Economic Growth (X₁) and Democracy (X₂, coded 0=autocracy, 1=democracy) predict Approval (Y). The regression yields: Approval = 40 + 2 × Growth + 5 × Democracy + 1.5 × (Growth × Democracy). Interpretation: In an autocracy (Democracy=0), each point of growth increases approval by 2 percentage points. In a democracy (Democracy=1), each point of growth increases approval by 2 + 1.5 = 3.5 percentage points. The interaction coefficient (1.5) quantifies how much larger growth's effect is in democracies.</p>
    <p class="method-desc" data-lang="zh">例子：经济增长（X₁）和民主制（X₂，编码0=独裁制，1=民主制）预测赞成（Y）。回归给出：赞成=40+2×增长+5×民主制+1.5×（增长×民主制）。解释：在独裁制（民主制=0），每增长点增加赞成2个百分点。在民主制（民主制=1），每增长点增加赞成2+1.5=3.5个百分点。交互系数（1.5）量化增长的效应在民主制中多少更大。</p>
    <p class="method-desc" data-lang="en">A common mistake: interpreting the main effects (β₁ and β₂) as unconditional effects when an interaction is present. They are not. β₁ (the effect of X₁) is conditional on X₂=0. If X₂=0 is not a meaningful value (e.g., "zero democracy" when democracy is coded 0-10), the main effect is hard to interpret. Solution: center variables by subtracting their mean before creating the interaction. Then the main effects represent effects at the mean value of the other variable, which is often meaningful.</p>
    <p class="method-desc" data-lang="zh">常见错误：当交互存在时解释主要效应（β₁和β₂）为无条件效应。它们不是。β₁（X₁的效应）以X₂=0为条件。如果X₂=0不是有意义的值（如"零民主制"当民主制编码0-10），主要效应很难解释。解决：通过在创建交互前减去平均值来中心化变量。然后主要效应代表在另一个变量的平均值的效应，这常常有意义。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> The effect of rain on mood depends on your circumstances. Rain helps a farmer (needed for crops) but ruins a picnicker's day (unwanted). Rain is X, your role is Z, and mood is Y. The main effect of rain (β₁) alone does not tell the full story; you need the interaction to know that rain's effect differs for farmers versus picnickers.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>雨对心情的效应取决于你的情况。雨帮助农民（作物需要）但毁了野餐者的日子（不需要）。雨是X，你的角色是Z，心情是Y。仅雨的主要效应（β₁）不讲完整故事；你需要交互知道雨的效应对农民对野餐者不同。</div>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Include an interaction only if you have a theoretical reason to expect it. Do not add interactions exploratory (searching for significance). If you include an interaction, always include the main effects (X₁ and X₂) even if they are not significant. Center variables before creating interactions to make main effects interpretable. Report both the interaction coefficient and simple slopes (the effect of X₁ at different levels of X₂) for clarity.</div>
    <div data-lang="zh"><strong>何时用/不用：</strong>仅当你有理论理由期望交互时包含。不要探索性添加交互（寻找显著）。如包含交互，总是包含主要效应（X₁和X₂）即使它们不显著。在创建交互前中心化变量以使主要效应可解释。报告交互系数和简单斜率（X₁在X₂不同水平的效应）以清晰。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Nonlinearity: When a Straight Line Is Not Enough</h3>
    <h3 data-lang="zh">非线性：当直线不够</h3>
    <p class="method-desc" data-lang="en">Some relationships are not linear. Education's effect on income may flatten at high education levels (diminishing returns): the jump from 8th grade to 12th grade education increases income substantially, but the jump from a bachelor's to a master's degree does less. You can model nonlinearity in two ways: (1) Polynomial terms: include X² or even X³ to fit curves; (2) Log transformation: if Y (but not X) is right-skewed, use log(Y) as the outcome.</p>
    <p class="method-desc" data-lang="zh">一些关系不是线性的。教育对收入的效应在高教育水平可能平坦（收益递减）：从8年级到12年级教育跳跃大幅增加收入，但从学士到硕士学位的跳跃少得多。你可以用两种方式模型非线性：(1)多项式项：包含X²甚至X³拟合曲线；(2)对数转换：如果Y（不是X）右偏，使用log(Y)作为结果。</p>
    <p class="method-desc" data-lang="en">Polynomial regression (adding X² or higher powers) can fit curved relationships. For example: Income = 25,000 + 3,000 × Education − 150 × Education². The negative coefficient on Education² means the effect of education decreases at higher levels. But be careful: polynomials can overfit (wobble at the edges) and are hard to interpret. Log transformations are often better. If income is right-skewed, regressing log(Income) on Education linearizes the relationship and is more interpretable: the coefficient on Education gives the percentage change in income per year of education (e.g., β = 0.08 means 8% increase per year).</p>
    <p class="method-desc" data-lang="zh">多项式回归（添加X²或更高幂）可拟合弯曲关系。例如：收入=25000+3000×教育-150×教育²。教育²的负系数意味着教育的效应在更高水平减少。但要小心：多项式可以过度拟合（在边缘摆动）且难解释。对数转换通常更好。如果收入右偏，在教育上回归log（收入）线性化关系并更可解释：教育系数给教育每年收入的百分比变化（如β=0.08意味着每年8%增加）。</p>
    <p class="method-desc" data-lang="en">How to detect nonlinearity? Look at scatter plots with LOESS smoothers (from the Data Visualization chapter). If the LOESS curve deviates substantially from a straight line, nonlinearity is present. Residual plots also reveal nonlinearity: if residuals show a curved pattern (positive, then negative, then positive again), fit a polynomial. Always plot predictions from nonlinear models to ensure they make intuitive sense — some complex models produce nonsensical predictions outside the data range.</p>
    <p class="method-desc" data-lang="zh">如何检测非线性？看带LOESS平滑器的散点图（来自数据可视化章）。如果LOESS曲线大幅偏离直线，非线性存在。残差图也揭示非线性：如果残差显示弯曲模式（正、然后负、然后正），拟合多项式。总是绘制来自非线性模型的预测以确保它们有直观意义——一些复杂模型在数据范围外产生无意义预测。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use log transformations when data are skewed and the relationship makes sense on a log scale. Avoid polynomial terms unless scatter plots clearly suggest curvature. If you use polynomials, include lower-order terms (do not skip from X to X³). Test whether nonlinearity improves fit using a model comparison test. Report predictions or marginal effects (how Y changes as X changes) rather than just coefficients, as nonlinear models are harder to interpret from coefficients alone.</div>
    <div data-lang="zh"><strong>何时用/不用：</strong>当数据偏斜且关系在对数尺度上有意义时用对数转换。除非散点图清楚暗示曲率，避免多项式项。如使用多项式，包含低阶项（不要从X跳到X³）。使用模型比较检验测试非线性是否改进拟合。报告预测或边际效应（Y当X变化如何变化）而不仅仅系数，因为非线性模型仅从系数很难解释。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher studies how political experience (years in office) affects electoral success (vote share). A linear model estimates: VoteShare = 45 + 1.2 × Experience. But a scatter plot reveals that experience helps candidates with 0–15 years (slope steep) but provides little benefit beyond that (slope flat). A quadratic model fits better: VoteShare = 45 + 2 × Experience − 0.08 × Experience². The negative quadratic term captures diminishing returns: early experience boosts electoral prospects substantially, but additional experience past a threshold adds little. This nonlinear insight would be missed by a simple linear regression.</div>
    <div data-lang="zh"><strong>社会科学例子：</strong>研究者研究政治经验（在职年数）如何影响选举成功（得票率）。线性模型估计：得票率=45+1.2×经验。但散点图揭示经验帮助0-15年候选（斜率陡）但在那之外提供很少益处（斜率平）。二次模型拟合更好：得票率=45+2×经验-0.08×经验²。负二次项捕获收益递减：早期经验大幅提升选举前景，但超过阈值的额外经验添加很少。这个非线性洞察会被简单线性回归遗漏。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Distinguishing Theory-Driven from Exploratory Analyses</h3>
    <h3 data-lang="zh">区分理论驱动与探索性分析</h3>
    <p class="method-desc" data-lang="en">Adding interactions and nonlinear terms should be driven by theory, not data exploration. A theory-driven analysis specifies the model before seeing results: "I predict that the effect of growth on approval is stronger in democracies, so I will include a Growth × Democracy interaction." An exploratory analysis comes after looking at the data: "I plotted growth vs. approval for each regime type and noticed the slopes differ, so I added an interaction."</p>
    <p class="method-desc" data-lang="zh">添加交互和非线性项应由理论驱动，不是数据探索。理论驱动分析在看结果前规定模型："我预测增长对赞成的效应在民主制中更强，所以我将包含增长×民主制交互。"探索性分析在看数据后："我为每个体制类型绘制增长对赞成，注意到斜率不同，所以我添加了交互。"</p>
    <p class="method-desc" data-lang="en">The distinction matters because exploratory models are prone to overfitting: if you test many interactions and keep those that are significant, you will find spurious effects by chance. The solution: pre-register your analysis (commit to a model before seeing data), label exploratory findings as such, and use lower p-value thresholds for exploratory results (p &lt; 0.01 or p &lt; 0.001 instead of p &lt; 0.05). If exploratory analyses are interesting, replicate them in a new sample before publishing.</p>
    <p class="method-desc" data-lang="zh">区分重要因为探索性模型容易过度拟合：如果你测试许多交互并保留显著的，你会通过机会发现虚假效应。解决：预注册你的分析（看数据前承诺模型），标记探索性发现为此，对探索性结果用更低P值阈值（p &lt; 0.01或p &lt; 0.001而不是p &lt; 0.05）。如探索性分析有趣，在发表前在新样本中复制它们。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> When possible, pre-register your regression model (coefficients, interactions, controls, transformations) before analyzing data. Clearly label post-hoc analyses and exploratory findings. In publications, separate confirmatory analyses (pre-specified) from exploratory analyses (data-driven). When reporting exploratory results, be honest about the multiple testing problem: if you tested 20 interactions, expect one to be "significant" by chance. Apply Bonferroni or similar corrections to exploratory p-values.</div>
    <div data-lang="zh"><strong>何时用/不用：</strong>可能时，在分析数据前预注册你的回归模型（系数、交互、控制、转换）。清楚标记事后分析和探索性发现。在出版中，分离确认分析（预指定）和探索性分析（数据驱动）。报告探索性结果时，对多重检验问题诚实：如果你测试20个交互，期望一个通过机会"显著"。对探索性P值应用Bonferroni或类似纠正。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher pre-registers a hypothesis: "Economic growth's effect on government approval is moderated by regime type (democracy vs. autocracy)." The analysis includes a Growth × Regime interaction, specified before data analysis. The interaction is significant (p = 0.03) and aligns with theory. This is confirmatory. Later, the researcher explores whether the effect also depends on whether the country is in a natural-resource-rich region. A second interaction (Growth × Resources) is "significant" (p = 0.04). But this was exploratory, tested after seeing results. The researcher should report both but label the first as confirmatory and the second as exploratory. The replication standard for the exploratory finding should be higher (pre-register in a future study).</div>
    <div data-lang="zh"><strong>社会科学例子：</strong>研究者预注册一个假设："经济增长对政府赞成的效应由体制类型（民主对独裁）调节。"分析包含增长×体制交互，在数据分析前规定。交互显著（p=0.03）且与理论一致。这是确认。后来，研究者探索效应是否也取决于国家是否在天然资源丰富地区。第二个交互（增长×资源）"显著"（p=0.04）。但这是探索性，在看结果后测试。研究者应报告两者但标记第一为确认，第二为探索性。探索性发现的复制标准应该更高（在未来研究中预注册）。</div>
  </div>
</div>

<hr class="section-divider">

<!-- RESOURCES -->
<hr class="section-divider">
<div class="section" id="ols-resources">
  <h2 data-lang="en">Resources</h2>
  <h2 data-lang="zh">资源</h2>
  <h3 data-lang="en">Key References</h3>
  <h3 data-lang="zh">关键参考</h3>
  <ul class="resource-list">
    <li data-lang="en"><strong>Angrist, J. D., & Pischke, J.-S. (2008).</strong> <em>Mostly Harmless Econometrics: An Empiricist's Companion.</em> Princeton University Press.</li>
    <li data-lang="zh"><strong>安格里斯特与皮施克(2008)。</strong><em>基本上无伤计量经济学：经验研究者伴侣。</em>普林斯顿大学出版社。</li>
    <li data-lang="en"><strong>Pearl, J., & Mackenzie, D. (2018).</strong> <em>The Book of Why: The New Science of Cause and Effect.</em> Basic Books.</li>
    <li data-lang="zh"><strong>珀尔与麦肯锡(2018)。</strong><em>为什么之书：因果新科学。</em>Basic Books。</li>
    <li data-lang="en"><strong>Rotnitzky, A., & Robins, J. M. (2005).</strong> "Semiparametric Regression Estimation of Mean Treatment Effects." <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 67(2), 301–323.</li>
    <li data-lang="zh"><strong>罗特尼茨基与罗宾斯(2005)。</strong>"平均处理效应的半参数回归估计。" <em>英国皇家统计学会杂志：B系列(统计方法)</em>，67(2)，301–323。</li>
    <li data-lang="en"><strong>Wooldridge, J. M. (2010).</strong> <em>Econometric Analysis of Cross Section and Panel Data (2nd ed.)</em>. MIT Press.</li>
    <li data-lang="zh"><strong>伍尔德里奇(2010)。</strong><em>截面和面板数据的计量经济分析(第2版)</em>。麻省理工学院出版社。</li>
  </ul>
</div>

<!-- PAGE NAV -->
<div class="page-nav">
  <a class="pn-link pn-prev" href="/methods/reg-dataviz.html">
    <span class="pn-arrow">&larr;</span>
    <span><span class="pn-title">Data Visualization</span></span>
  </a>
  <a class="pn-link pn-next" href="/methods/reg-mle.html">
    <span><span class="pn-title">MLE & Generalized Linear Models</span></span>
    <span class="pn-arrow">&rarr;</span>
  </a>
</div>
