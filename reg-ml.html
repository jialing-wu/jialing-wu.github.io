---
layout: methods-course
title: "Machine Learning"
breadcrumb: "Computational Methods"
bilingual: true
prev:
  url: reg-sem.html
  title: "Structural Equation Models"
next:
  url: reg-text.html
  title: "Text as Data"
---

<style>
.problem-index{margin:0 0 8px;padding:16px 20px;border:1px solid var(--parchment);border-radius:4px;background:var(--warm)}
.problem-index-title{font-family:var(--sans);font-size:10px;font-weight:700;letter-spacing:.12em;text-transform:uppercase;color:var(--gold);margin-bottom:12px}
.problem-index a{display:block;font-size:14.5px;line-height:2;color:var(--ink-faded);text-decoration:none;transition:color .2s}
.problem-index a:hover{color:var(--red)}
.problem-index a .pi-arrow{font-family:var(--sans);font-size:11px;color:var(--gold);margin-left:6px}
.compare-grid{display:grid;grid-template-columns:1fr 1fr;gap:0;margin:16px 0;border:1px solid var(--parchment);border-radius:4px;overflow:hidden}
.compare-col{padding:18px;background:var(--paper)}
.compare-col.alt{background:var(--warm)}
.compare-label{font-family:var(--sans);font-size:10px;font-weight:700;letter-spacing:.1em;text-transform:uppercase;color:var(--red);margin-bottom:12px}
.compare-footer{grid-column:1/-1;padding:12px 18px;background:rgba(194,153,61,.05);border-top:1px solid var(--parchment);font-size:13px;color:var(--ink-faded);font-style:italic}
.compare-col p{font-size:14.5px;line-height:1.65;color:var(--ink-faded);margin-bottom:8px}
@media(max-width:860px){.compare-grid{grid-template-columns:1fr}}
</style>

<!-- HEADER -->
<div class="method-header">
  <h1>Machine Learning for Social Science Research</h1>
  <div class="method-meta">Computational Methods &middot; Advanced 13</div>
</div>

<!-- INTRO CARDS -->
<div class="intro-cards">
  <div class="intro-card">
    <div class="card-label" data-lang="en">What Is This?</div>
    <div class="card-label" data-lang="zh">这一页讲什么？</div>
    <div data-lang="en"><p>Traditional regression asks: given theory, what are the coefficients? Machine learning asks: given data, what is the best prediction? These are different questions. ML excels at prediction and variable selection with high-dimensional data — but requires different logic than causal inference.</p></div>
    <div data-lang="zh"><p>传统回归问：给定理论，系数是多少？机器学习问：给定数据，最好的预测是什么？这是两个不同的问题。ML 在高维数据的预测和变量选择方面表现出色——但需要与因果推断不同的逻辑。</p></div>
  </div>
  <div class="intro-card">
    <div class="card-label" data-lang="en">Prerequisites</div>
    <div class="card-label" data-lang="zh">前置知识</div>
    <div data-lang="en"><p>Regression Analysis. Basic R or Python.</p></div>
    <div data-lang="zh"><p>回归分析。基础 R 或 Python。</p></div>
  </div>
  <div class="intro-card">
    <div class="card-label" data-lang="en">Software &amp; Tools</div>
    <div class="card-label" data-lang="zh">软件工具</div>
    <div data-lang="en"><p>R (tidymodels, caret, ranger) or Python (scikit-learn).</p></div>
    <div data-lang="zh"><p>R（tidymodels、caret、ranger）或 Python（scikit-learn）。</p></div>
  </div>
</div>

<!-- PROBLEM INDEX -->
<div class="problem-index">
  <div class="problem-index-title" data-lang="en">What problem are you facing?</div>
  <div class="problem-index-title" data-lang="zh">你遇到了什么问题？</div>
  <a href="#ml-s1" data-lang="en">I want to predict an outcome as accurately as possible <span class="pi-arrow">&rarr; &sect;1</span></a>
  <a href="#ml-s1" data-lang="zh">我想尽可能准确地预测一个结果<span class="pi-arrow">&rarr; &sect;1</span></a>
  <a href="#ml-s2" data-lang="en">I have many variables — which ones actually matter? <span class="pi-arrow">&rarr; &sect;2</span></a>
  <a href="#ml-s2" data-lang="zh">我有很多变量——哪些真正重要？<span class="pi-arrow">&rarr; &sect;2</span></a>
  <a href="#ml-s3" data-lang="en">I want to use tree-based models for prediction <span class="pi-arrow">&rarr; &sect;3</span></a>
  <a href="#ml-s3" data-lang="zh">我想用树类模型进行预测<span class="pi-arrow">&rarr; &sect;3</span></a>
  <a href="#ml-s4" data-lang="en">How do I understand what my black-box model is doing? <span class="pi-arrow">&rarr; &sect;4</span></a>
  <a href="#ml-s4" data-lang="zh">我怎么理解黑箱模型在做什么？<span class="pi-arrow">&rarr; &sect;4</span></a>
</div>

<hr class="section-divider">

<!-- SECTION 1 -->
<div class="section" id="ml-s1">
  <h2 data-lang="en">I Want to Predict an Outcome as Accurately as Possible</h2>
  <h2 data-lang="zh">我想尽可能准确地预测一个结果</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You have a dataset with hundreds of predictors and you want to forecast an outcome — election results, economic indicators, criminal recidivism — with maximum accuracy. In-sample R² is worthless: a perfect fit on past data often fails catastrophically on new data. You need to know how well your model will perform when it encounters data it has never seen.</p>
    <p data-lang="zh"><strong>问题：</strong>你有一个包含数百个预测变量的数据集，想预测某个结果——选举结果、经济指标、犯罪再犯率——追求最大准确率。样本内 R² 毫无价值：在历史数据上完美拟合的模型在新数据上常常彻底失效。你需要知道模型在遇到从未见过的新数据时会表现得多好。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Prediction vs. Inference</h3>
    <h3 data-lang="zh">预测 vs. 推断</h3>
    <p class="method-desc" data-lang="en">This distinction is fundamental. <strong>Inference</strong> asks: "What is the causal effect of X on Y, controlling for confounders?" (Goal: unbiased β). <strong>Prediction</strong> asks: "Given these features, what is Y?" (Goal: minimize out-of-sample error). These goals often conflict. OLS maximizes in-sample R²; complex ML models sacrifice in-sample fit to generalize better to new data. In social science, you cannot have both simultaneously — you must choose.</p>
    <p class="method-desc" data-lang="zh">这个区分是基础性的。<strong>推断</strong>问："X 对 Y 的因果效应是什么，控制了混杂因素之后？"（目标：无偏的 β）。<strong>预测</strong>问："给定这些特征，Y 是什么？"（目标：最小化样本外误差）。这两个目标常常冲突。OLS 最大化样本内 R²；复杂的 ML 模型牺牲样本内拟合以更好地泛化到新数据。在社会科学中，你不能同时有两者——必须选择。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> Studying for an exam by memorizing past exam questions is prediction-focused — you get perfect scores on old tests but fail on new questions. Learning the material is inference-focused — you may struggle on the old tests but pass any test the professor writes.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>通过死记硬背过去的考题来备考是预测导向的——你在旧题上得分完美但新题失败。学习原理是推断导向的——旧题上可能吃力但能通过任何教授出的新题。</div>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> When your research question is "what will happen next?" rather than "why does X cause Y?" Use prediction logic when deploying models in practice (loan approval, risk assessment). Use inference logic for hypothesis testing and causal claims.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>当你的研究问题是"下一步会发生什么？"而不是"为什么 X 导致 Y？"。在实践中部署模型（贷款审批、风险评估）时使用预测逻辑。假设检验和因果声明时用推断逻辑。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Train/Test Split and Cross-Validation</h3>
    <h3 data-lang="zh">训练/测试划分与交叉验证</h3>
    <p class="method-desc" data-lang="en">The simplest guard against overfitting: split your data before you do anything. Train on 70–80%, test on 20–30%. Train your model on the training set, evaluate it only on the test set. Never touch the test set until you're done. This simulates what happens in the real world: your model encounters unfamiliar data.</p>
    <p class="method-desc" data-lang="zh">防止过拟合最简单的方法：先分割数据再做任何事。在 70–80% 上训练，在 20–30% 上测试。在训练集上训练模型，只在测试集上评估。完成前不要碰测试集。这模拟了现实：模型遇到陌生数据。</p>
    <p class="method-desc" data-lang="en"><strong>Cross-validation</strong> (k-fold) is better when you have limited data. Divide data into k folds (typically k=5 or k=10). Fit k models, each trained on k−1 folds and tested on the held-out fold. Average the k test errors for your final estimate. This squeezes more signal from small datasets while still respecting the train-test boundary.</p>
    <p class="method-desc" data-lang="zh"><strong>交叉验证</strong>（k-折）在数据有限时更好。把数据分成 k 份（通常 k=5 或 k=10）。训练 k 个模型，每个在 k−1 份上训练，在保留的 1 份上测试。取 k 个测试误差的平均值作为最终估计。这在小数据集上充分利用信号，同时尊重训练-测试边界。</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> Always. There is no excuse for reporting only in-sample fit. If you have a large test set (thousands of observations), simple train/test is fine. If sample size is smaller, use cross-validation to maximize information.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>总是用。没有理由只报告样本内拟合。如果有大的测试集（数千观测），简单的训练/测试就够。样本较小时，用交叉验证最大化信息利用。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">The Bias-Variance Tradeoff</h3>
    <h3 data-lang="zh">偏差-方差权衡</h3>
    <p class="method-desc" data-lang="en">Total prediction error = bias² + variance + irreducible error. <strong>Bias</strong> = systematic error (model is consistently wrong). <strong>Variance</strong> = sensitivity to small changes in training data (model is unstable). A simple model (e.g., OLS) has high bias (misses true patterns) but low variance (stable). A complex model (e.g., polynomial with degree 20) has low bias (fits many patterns) but high variance (fits noise instead of signal, fails on new data). The sweet spot: pick a model complex enough to capture the true pattern, but simple enough that it doesn't memorize noise.</p>
    <p class="method-desc" data-lang="zh">总预测误差 = 偏差² + 方差 + 不可约误差。<strong>偏差</strong> = 系统误差（模型总是有偏差）。<strong>方差</strong> = 对训练数据小变化的敏感性（模型不稳定）。简单模型（如 OLS）偏差大（遗漏真实规律）但方差小（稳定）。复杂模型（如 20 次多项式）偏差小（拟合很多规律）但方差大（拟合噪声而非信号，在新数据上失败）。最优点：选择足够复杂以捕捉真实规律，但足够简单以不记住噪声的模型。</p>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> Predicting civil war onset with 50 country-year predictors. A linear model might underfit (misses important nonlinear thresholds). A neural network with 10 hidden layers fits the training data perfectly but fails on future years because it memorized spurious correlations in your specific sample.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>用 50 个国家-年份预测变量预测内战爆发。线性模型可能欠拟合（遗漏重要的非线性阈值）。10 层隐藏层的神经网络完美拟合训练数据但在未来年份失败，因为它记住了你特定样本中的虚假相关。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 2 -->
<div class="section" id="ml-s2">
  <h2 data-lang="en">I Have Many Variables — Which Ones Actually Matter?</h2>
  <h2 data-lang="zh">我有很多变量——哪些真正重要？</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You have 500 potential predictors and your sample size is 1000. Most classical methods break down: you'll have more parameters than observations, multicollinearity runs wild, and you can find any pattern by chance (overfitting). You need a principled way to select which variables matter and shrink the others toward zero.</p>
    <p data-lang="zh"><strong>问题：</strong>你有 500 个潜在预测变量，样本量是 1000。大多数经典方法失效：参数比观测多，多重共线性疯狂，能凭巧合找到任何规律（过拟合）。你需要有原则地选择哪些变量重要，把其他变量缩向零。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Regularization: Adding a Penalty</h3>
    <h3 data-lang="zh">正则化：加入惩罚项</h3>
    <p class="method-desc" data-lang="en">Regularization penalizes model complexity. Instead of minimizing just SSE, minimize SSE + λ×(penalty on coefficients). The penalty makes the model "prefer" simpler solutions. Larger λ = more penalty = more coefficients shrink toward zero. The key insight: by deliberately introducing bias (coefficients that are slightly wrong), you dramatically reduce variance (the model becomes stable on new data).</p>
    <p class="method-desc" data-lang="zh">正则化惩罚模型复杂度。不只最小化 SSE，而是最小化 SSE + λ×(系数惩罚)。惩罚让模型"偏好"更简单的解。更大的 λ = 更大惩罚 = 更多系数缩向零。关键见解：故意引入偏差（稍微错误的系数），大幅降低方差（模型在新数据上稳定）。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> Hiring for a startup: if you require candidates to be perfect (overfitting), you won't find anyone and remain understaffed. If you tolerate candidates who are "good enough" (regularization), you find strong people quickly, and any hiring mistakes are small.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>初创企业招聘：如果要求候选人完美（过拟合），找不到人且招聘不足。如果容许"足够好"的候选人（正则化），快速找到强人，任何招聘失误都很小。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Lasso: L1 Regularization and Variable Selection</h3>
    <h3 data-lang="zh">Lasso：L1 正则化与变量选择</h3>
    <p class="method-desc" data-lang="en"><strong>Lasso</strong> (Least Absolute Shrinkage and Selection Operator) adds the penalty λ×Σ|β| — the sum of absolute values of coefficients. The magic property: Lasso shrinks some coefficients exactly to zero, automatically doing variable selection. If Lasso sets β₅ = 0, variable 5 is irrelevant. This interpretability is invaluable: you get a sparse model where you see exactly which variables drive the prediction.</p>
    <p class="method-desc" data-lang="zh"><strong>Lasso</strong>（最小绝对值收缩和选择算子）加入惩罚 λ×Σ|β| ——系数绝对值之和。神奇的性质：Lasso 把一些系数正好缩为零，自动做变量选择。如果 Lasso 设 β₅ = 0，变量 5 无关。这种可解释性无价：得到稀疏模型，清楚看到哪些变量驱动预测。</p>
    <p class="method-desc" data-lang="en">For causal inference with high dimensions, use <strong>Double Lasso</strong> (or Post-Lasso): (1) Lasso selects relevant predictors of Y; (2) Lasso selects relevant predictors of your treatment X; (3) Regress Y on X using only variables selected by either step. This gives unbiased treatment effect estimates while controlling for hundreds of potential confounders. Chernozhukov et al. (2018) provide the theory.</p>
    <p class="method-desc" data-lang="zh">在高维因果推断中，用<strong>双重 Lasso</strong>（或后-Lasso）：（1）Lasso 选择 Y 的相关预测变量；（2）Lasso 选择处理 X 的相关预测变量；（3）用任一步选中的变量回归 Y 对 X。这给出无偏的处理效应估计，同时控制数百个潜在混杂变量。Chernozhukov et al. (2018) 提供理论。</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> When you have more predictors than observations or severe multicollinearity. Excellent for prediction. For causal inference in high dimensions, use Double Lasso. Limitation: assumes sparsity (true model has few nonzero coefficients). If many variables truly matter, Lasso can underselect.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>预测变量多于观测或存在严重多重共线性时。预测效果好。高维因果推断时用双重 Lasso。局限：假设稀疏性（真实模型只有少数非零系数）。如果许多变量真的重要，Lasso 可能选少了。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Ridge and Elastic Net</h3>
    <h3 data-lang="zh">Ridge 和弹性网</h3>
    <p class="method-desc" data-lang="en"><strong>Ridge</strong> uses penalty λ×Σβ² (sum of squared coefficients). Unlike Lasso, Ridge shrinks all coefficients proportionally toward zero but never exactly to zero. Good when all variables are truly relevant (hard to believe in social science). <strong>Elastic Net</strong> combines both: λ₁×Σ|β| + λ₂×Σβ². Gives you the sparsity of Lasso with the stability of Ridge. Tune both λ₁ and λ₂ via cross-validation to find the balance.</p>
    <p class="method-desc" data-lang="zh"><strong>Ridge</strong> 用惩罚 λ×Σβ²（系数平方和）。不像 Lasso，Ridge 把所有系数按比例缩向零但永不为零。当所有变量真的相关时（社会科学中难以置信）较好。<strong>弹性网</strong>结合两者：λ₁×Σ|β| + λ₂×Σβ²。给你 Lasso 的稀疏性加 Ridge 的稳定性。通过交叉验证调节 λ₁ 和 λ₂ 找到平衡。</p>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 3 -->
<div class="section" id="ml-s3">
  <h2 data-lang="en">I Want to Use Tree-Based Models</h2>
  <h2 data-lang="zh">我想用树类模型进行预测</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> Linear models assume a linear relationship between X and Y. Reality is messier: effects may threshold (nothing happens until X crosses a value, then everything changes). Tree-based models capture these nonlinear patterns, feature interactions, and discontinuities automatically — without you specifying them in advance. The tradeoff: even harder to interpret than neural nets.</p>
    <p data-lang="zh"><strong>问题：</strong>线性模型假设 X 和 Y 的线性关系。现实更复杂：效应可能有阈值（X 跨过某值前什么都不发生，然后一切改变）。树类模型自动捕捉这些非线性规律、特征交互和不连续——不需提前指定。权衡：比神经网络更难解释。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Decision Trees: The Building Block</h3>
    <h3 data-lang="zh">决策树：基本单元</h3>
    <p class="method-desc" data-lang="en">A tree is just a series of binary splits: "If X₁ > 5, go left; else go right." Each split maximizes information gain (reduces uncertainty in the target variable). Trees are highly interpretable — you can draw them and show exactly which rule applies. But a single tree overfits terribly: it splits until it perfectly memorizes the training data, then fails on new data.</p>
    <p class="method-desc" data-lang="zh">树就是一系列二分割：如果 X₁ > 5，左转；否则右转。每个分割最大化信息增益（减少目标变量的不确定性）。树高度可解释——能绘制并清楚显示哪条规则适用。但单棵树过拟合可怕：不断分割直到完美记住训练数据，然后在新数据上失败。</p>
    <p class="method-desc" data-lang="en"><strong>Pruning</strong> is the simple fix: grow a deep tree, then cut back branches that don't improve out-of-sample performance. But this still doesn't solve the instability problem: one small change in the training data can flip the entire tree structure.</p>
    <p class="method-desc" data-lang="zh"><strong>剪枝</strong>是简单的修复：先长成深树，再剪掉不改善样本外性能的分支。但这仍不解决不稳定性：训练数据的小改变可能翻转整棵树。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Random Forests: Ensemble of Trees</h3>
    <h3 data-lang="zh">随机森林：树的集合</h3>
    <p class="method-desc" data-lang="en"><strong>Random Forest</strong> grows hundreds of trees, but each tree sees a random sample of observations and a random subset of features. No two trees are identical. Then, to predict, average (for regression) or take majority vote (for classification) across all trees. This reduces variance drastically: individual trees may be unreliable, but their average is stable.</p>
    <p class="method-desc" data-lang="zh"><strong>随机森林</strong>生长数百棵树，但每棵看到随机的观测样本和随机的特征子集。没有两棵树相同。预测时，对所有树进行平均（回归）或多数投票（分类）。这大幅降低方差：单棵树可能不可靠，但它们的平均稳定。</p>
    <p class="method-desc" data-lang="en"><strong>Out-of-bag (OOB) error</strong> is a bonus: roughly 1/3 of observations are left out of each bootstrap sample, so you can estimate test error without a separate test set. Report both OOB error and held-out test performance.</p>
    <p class="method-desc" data-lang="zh"><strong>袋外（OOB）误差</strong>是额外好处：约 1/3 的观测被排除在每个自助样本外，所以能估计测试误差而不需单独的测试集。报告 OOB 误差和保留的测试性能。</p>
    <p class="method-desc" data-lang="en"><strong>Variable importance</strong> is computed as the average increase in prediction error when you randomly shuffle a variable. Variables that cause large increases in error are important; variables that cause no change are irrelevant. This is the closest tree-based models come to interpretability.</p>
    <p class="method-desc" data-lang="zh"><strong>变量重要性</strong>计算为随机打乱一个变量时预测误差的平均增加。导致误差大幅增加的变量重要；引起零变化的无关。这是树类模型最接近可解释性的。</p>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> Predicting which neighborhoods gentrify (Hwang & Sampson, 2014 logic). Random Forest finds that a neighborhood's cultural amenities (bookstores, cafes) interact nonlinearly with proximity to universities and income inequality. Linear regression would miss these interaction thresholds.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>预测哪些社区绅士化（Hwang & Sampson, 2014 的逻辑）。随机森林发现社区的文化便利设施（书店、咖啡馆）与大学邻近性和收入不平等进行非线性相互作用。线性回归会遗漏这些交互阈值。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Gradient Boosting: Sequential Improvement</h3>
    <h3 data-lang="zh">梯度提升：逐步改进</h3>
    <p class="method-desc" data-lang="en"><strong>Gradient Boosting</strong> (XGBoost, LightGBM) takes a different approach: fit one tree, compute residuals (where the model was wrong), fit a new tree to those residuals, compute new residuals, repeat. Each tree corrects the previous tree's mistakes. This sequential refinement often beats Random Forest, especially on large datasets.</p>
    <p class="method-desc" data-lang="zh"><strong>梯度提升</strong>（XGBoost、LightGBM）采取不同方法：拟合一棵树，计算残差（模型出错的地方），对残差拟合新树，计算新残差，重复。每棵树纠正前一棵树的错误。这种顺序改进常常胜过随机森林，特别在大数据集上。</p>
    <p class="method-desc" data-lang="en">When does gradient boosting beat Random Forest? (1) On larger datasets (>10K observations) it typically wins. (2) When feature engineering is limited (boosting learns interactions more effectively). (3) On structured (tabular) data, especially. When does Random Forest win? (1) With smaller samples, Random Forest is more robust (less prone to overfitting). (2) When you need variable importance estimates. (3) When you need training to be fast (parallelizes better).</p>
    <p class="method-desc" data-lang="zh">梯度提升何时胜过随机森林？（1）在较大数据集上（>10K 观测）通常赢。（2）当特征工程受限（提升更有效学习交互）。（3）在结构化（表格）数据上，特别是。随机森林何时赢？（1）小样本时，随机森林更鲁棒（不易过拟合）。（2）需要变量重要性估计时。（3）需要快速训练时（更好地并行化）。</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> Gradient boosting when you have thousands to millions of observations and want maximum predictive accuracy. Random Forest when sample size is smaller, you need variable importance, or interpretability matters. Both beat OLS on nonlinear problems.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>数千到数百万观测且要最大预测准确率时用梯度提升。样本较小、需要变量重要性或可解释性时用随机森林。两者都胜过 OLS 在非线性问题上。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 4 -->
<div class="section" id="ml-s4">
  <h2 data-lang="en">How Do I Understand What My Black-Box Model Is Doing?</h2>
  <h2 data-lang="zh">我怎么理解黑箱模型在做什么？</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> Your Random Forest or gradient boosting model achieves 95% accuracy. But if you're recommending policy, denying loans, or assessing risk, you need to explain why. "The model said so" is not acceptable in social science research, which prioritizes understanding mechanisms. You need interpretability: which features drive each prediction? How do predictions change if you change an input?</p>
    <p data-lang="zh"><strong>问题：</strong>你的随机森林或梯度提升模型达到 95% 准确率。但如果推荐政策、拒绝贷款或评估风险，需要解释为什么。"模型这么说"在社会科学研究中不能接受，其优先考虑理解机制。需要可解释性：哪些特征驱动每个预测？改变输入时预测如何改变？</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">The Interpretability-Performance Tradeoff</h3>
    <h3 data-lang="zh">可解释性-性能权衡</h3>
    <p class="method-desc" data-lang="en">In practice, you often face a choice: a simple, interpretable model (logistic regression) that achieves 80% accuracy, or a complex black-box model that achieves 95% accuracy. If the gap is small and interpretability matters (e.g., you're justifying a policy decision), choose interpretability. If the accuracy gap is huge and stakes are lower (e.g., recommending products to users), complex models win. There is no universal rule — it depends on your research goal.</p>
    <p class="method-desc" data-lang="zh">实践中常面临选择：简单、可解释的模型（逻辑回归）达到 80% 准确率，或复杂的黑箱模型达到 95%。如果差距小且可解释性重要（如论证政策决策），选可解释性。准确率差距大且赌注低（如向用户推荐产品）时，复杂模型赢。无通用规则——取决于研究目标。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">SHAP Values: Local Feature Contribution</h3>
    <h3 data-lang="zh">SHAP 值：局部特征贡献</h3>
    <p class="method-desc" data-lang="en"><strong>SHAP</strong> (SHapley Additive exPlanations) values, based on cooperative game theory, tell you each feature's contribution to each individual prediction. For a single case, SHAP decomposes the prediction into contributions from each input variable, showing both direction (does this feature push prediction up or down?) and magnitude (how much?).</p>
    <p class="method-desc" data-lang="zh"><strong>SHAP</strong> 值（基于合作博弈论）告诉你每个特征对每个单独预测的贡献。对于单个案例，SHAP 把预测分解为每个输入变量的贡献，显示方向（这个特征把预测推高还是推低？）和幅度（多少？）。</p>
    <p class="method-desc" data-lang="en">Aggregating SHAP values across all observations gives you <strong>global feature importance</strong> and the direction of effects. A summary plot shows: "Feature X has the highest impact on predictions, and high values of X tend to push predictions up, while low values push them down." This is the closest you get to a "coefficient" in a black-box model.</p>
    <p class="method-desc" data-lang="zh">聚合所有观测的 SHAP 值给出<strong>全局特征重要性</strong>和效应方向。汇总图显示："特征 X 对预测影响最大，X 的高值倾向把预测推高，低值推低。"这是你在黑箱模型中最接近"系数"的。</p>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> SHAP analysis of a model predicting political protest in countries. For Sudan in 2019 (an actual case of protest), SHAP shows: "recent economic decline pushed prediction up most (+0.4), but repression level pushed down (−0.15), and democratic institutions pushed down slightly (−0.08). Net result: protest predicted with 72% probability." This tells you which structural conditions mattered for that specific country-year.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>预测国家政治抗议的模型的 SHAP 分析。对于 2019 年苏丹（抗议的真实案例），SHAP 显示："最近经济衰退最多推高预测 (+0.4)，但压制水平推低 (-0.15)，民主制度略推低 (-0.08)。净结果：抗议 72% 概率预测。"这告诉你该特定国家-年份哪些结构条件最重要。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Partial Dependence and ICE Plots</h3>
    <h3 data-lang="zh">部分依赖图和 ICE 图</h3>
    <p class="method-desc" data-lang="en"><strong>Partial Dependence Plot (PDP)</strong>: Hold all variables constant except one, vary that variable over its range, and see how the predicted value changes. Shows the marginal effect of a variable (averaged over all other variables). If the curve is flat, the variable has no effect on predictions. If it's monotonic, higher values consistently raise or lower predictions.</p>
    <p class="method-desc" data-lang="zh"><strong>部分依赖图 (PDP)</strong>：保持所有变量不变除了一个，改变该变量在其范围内，看预测值如何变化。显示变量的边际效应（对所有其他变量平均）。如果曲线平坦，变量对预测无效应。如果单调，高值一致性地提高或降低预测。</p>
    <p class="method-desc" data-lang="en"><strong>Individual Conditional Expectation (ICE) plots</strong> are similar but show the relationship for each observation separately. Instead of one averaged curve, you see hundreds of curves (one per observation). This reveals heterogeneity: "Variable X increases predictions for 80% of cases, but decreases predictions for 20% of cases." ICE plots catch nonlinearities and interactions that PDPs might average away.</p>
    <p class="method-desc" data-lang="zh"><strong>个体条件期望 (ICE) 图</strong>类似但分别显示每个观测的关系。不是一条平均曲线，而看到数百条曲线（每个观测一条）。揭示异质性："变量 X 对 80% 案例增加预测，但对 20% 降低预测。"ICE 图捕捉 PDP 可能平均掉的非线性和交互。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Model-Agnostic: LIME and Beyond</h3>
    <h3 data-lang="zh">模型无关：LIME 及其他</h3>
    <p class="method-desc" data-lang="en"><strong>LIME</strong> (Local Interpretable Model-agnostic Explanations) works on any model: fit a simple, interpretable model (logistic regression) to explain the predictions of your complex model in a local region. For a single prediction, it answers: "Which features were most important for this specific decision?" Works with tree models, neural nets, anything.</p>
    <p class="method-desc" data-lang="zh"><strong>LIME</strong>（局部可解释模型无关解释）适用于任何模型：用简单可解释的模型（逻辑回归）解释复杂模型在局部区域的预测。对于单个预测回答："哪些特征对这个特定决定最重要？"适用于树模型、神经网络、任何东西。</p>
    <div class="method-when" data-lang="en"><strong>When to use:</strong> SHAP for comprehensive local and global explanations. PDPs/ICE for understanding marginal relationships. LIME for quick local explanations. All three are compatible with black-box models and make social science research more defensible.</div>
    <div class="method-when" data-lang="zh"><strong>何时用：</strong>SHAP 用于综合的局部和全局解释。PDP/ICE 用于理解边际关系。LIME 用于快速局部解释。三者都与黑箱模型兼容，使社会科学研究更可防守。</div>
  </div>
</div>

<hr class="section-divider">
<!-- GUIDES -->
<div class="section" id="ml-guides">
  <h2 data-lang="en">Guides</h2>
  <h2 data-lang="zh">配套指南</h2>
  <div class="m-list">
    <a class="m-card" href="/methods/guides/reg-ml-biasvar.html">
      <div class="m-num">▶</div>
      <div class="m-info">
        <div class="m-title" data-lang="en">Bias-Variance Tradeoff Explorer</div>
        <div class="m-title" data-lang="zh">偏差-方差权衡可视化</div>
        <div class="m-desc" data-lang="en">Polynomial degree slider shows underfitting/overfitting; regularization paths with glmnet.</div>
        <div class="m-desc" data-lang="zh">多项式次数滑块展示欠拟合/过拟合；glmnet 正则化路径可视化。</div>
      </div>
      <div class="m-arrow">→</div>
    </a>
    <a class="m-card" href="/methods/guides/reg-ml-crossval.html">
      <div class="m-num">▶</div>
      <div class="m-info">
        <div class="m-title" data-lang="en">Cross-Validation in Practice</div>
        <div class="m-title" data-lang="zh">交叉验证实战</div>
        <div class="m-desc" data-lang="en">K-fold CV visualizer, caret and tidymodels workflows, and social science edge cases.</div>
        <div class="m-desc" data-lang="zh">K 折 CV 可视化，caret 与 tidymodels 工作流，以及社会科学特殊情形。</div>
      </div>
      <div class="m-arrow">→</div>
    </a>
  </div>
</div>

<hr class="section-divider">
<!-- RESOURCES -->
<div class="section" id="ml-resources">
  <h2 data-lang="en">Resources</h2>
  <h2 data-lang="zh">资源</h2>

  <div class="method-section">
    <h3 data-lang="en">Key References</h3>
    <h3 data-lang="zh">关键参考</h3>
    <ul style="font-size:14.5px;line-height:1.8;color:var(--ink-faded);margin-left:20px">
      <li>Mullainathan, S., &amp; Spiess, J. (2017). Machine learning: An applied econometric approach. <em>Journal of Economic Perspectives</em>, 31(2), 87–106.</li>
      <li>Chernozhukov, V., Escanciano, J. C., Ichimura, H., et al. (2018). Double/debiased machine learning for treatment and structural parameters. <em>Econometrics Journal</em>, 21(1), C1–C68.</li>
      <li>Breiman, L. (2001). Random forests. <em>Machine Learning</em>, 45(1), 5–32.</li>
      <li>Lundberg, S. M., &amp; Lee, S.-I. (2017). A unified approach to interpreting model predictions. <em>NIPS</em>, 30, 4765–4774.</li>
      <li>Molnar, C. (2020). <em>Interpretable Machine Learning: A Guide for Making Black Box Models Explainable</em>. Available free at christophm.github.io/interpretable-ml-book.</li>
    </ul>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Software Tools</h3>
    <h3 data-lang="zh">软件工具</h3>
    <ul style="font-size:14.5px;line-height:1.8;color:var(--ink-faded);margin-left:20px">
      <li><strong>Python:</strong> scikit-learn (Lasso, Ridge, Random Forest), XGBoost, shap (SHAP values)</li>
      <li><strong>R:</strong> glmnet (Lasso/Ridge), ranger (Random Forest), xgboost, shap, iml (interpretability)</li>
      <li><strong>Jupyter/RMarkdown:</strong> For reproducible ML workflows with cross-validation pipelines</li>
    </ul>
  </div>
</div>

<!-- PAGE NAV -->
<div class="page-nav">
  <a class="pn-link pn-prev" href="/methods/reg-sem.html">
    <span class="pn-arrow">&larr;</span>
    <span><span class="pn-title">Structural Equation Models</span></span>
  </a>
  <a class="pn-link pn-next" href="/methods/reg-text.html">
    <span><span class="pn-title">Text as Data</span></span>
    <span class="pn-arrow">&rarr;</span>
  </a>
</div>
