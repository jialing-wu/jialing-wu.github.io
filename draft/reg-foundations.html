---
layout: methods-course
title: "Statistical Foundations"
breadcrumb: "Statistics"
bilingual: true
prev:
  url: theoretical-modeling.html
  title: "Theoretical Modeling"
next:
  url: reg-dataviz.html
  title: "Data Visualization"
---

<style>
.problem-index{margin:0 0 8px;padding:16px 20px;border:1px solid var(--parchment);border-radius:4px;background:var(--warm)}
.problem-index-title{font-family:var(--sans);font-size:10px;font-weight:700;letter-spacing:.12em;text-transform:uppercase;color:var(--gold);margin-bottom:12px}
.problem-index a{display:block;font-size:14.5px;line-height:2;color:var(--ink-faded);text-decoration:none;transition:color .2s}
.problem-index a:hover{color:var(--red)}
.problem-index a .pi-arrow{font-family:var(--sans);font-size:11px;color:var(--gold);margin-left:6px}
.paradigm-table{border-collapse:collapse;width:100%;font-size:13.5px;line-height:1.6}
.paradigm-table th{background:var(--gold);color:var(--white);padding:10px;text-align:left;font-weight:700}
.paradigm-table td{border:1px solid var(--parchment);padding:8px 10px}
.paradigm-table tr:nth-child(even){background:var(--white)}
.paradigm-table tr:nth-child(odd){background:var(--light)}
</style>

<!-- HEADER -->
<div class="method-header">
  <h1>Statistical Foundations</h1>
  <div class="method-meta">Statistics &middot; Foundations 01</div>
</div>

<!-- INTRO CARDS -->
<div class="intro-cards">
  <div class="intro-card">
    <div class="card-label" data-lang="en">What Is This?</div>
    <div class="card-label" data-lang="zh">这一页讲什么？</div>
    <div data-lang="en"><p>You have data — but what does it tell you? This page covers the foundations every quantitative researcher needs: describing distributions, making inferences from samples, testing hypotheses, and understanding the relationship between two variables.</p></div>
    <div data-lang="zh"><p>你有数据——但它说明了什么？本页介绍每位量化研究者都需要的基础：描述分布、从样本推断总体、检验假设，以及理解两个变量之间的关系。</p></div>
  </div>
  <div class="intro-card">
    <div class="card-label" data-lang="en">Prerequisites</div>
    <div class="card-label" data-lang="zh">前置知识</div>
    <div data-lang="en"><p>No prerequisites. This is the starting point.</p></div>
    <div data-lang="zh"><p>无前置要求。这是起点。</p></div>
  </div>
  <div class="intro-card">
    <div class="card-label" data-lang="en">Software &amp; Tools</div>
    <div class="card-label" data-lang="zh">软件工具</div>
    <div data-lang="en"><p>R or Stata. All examples use base R.</p></div>
    <div data-lang="zh"><p>R 或 Stata。所有示例使用 base R。</p></div>
  </div>
</div>

<!-- PROBLEM INDEX -->
<div class="problem-index">
  <div class="problem-index-title" data-lang="en">What problem are you facing?</div>
  <div class="problem-index-title" data-lang="zh">你遇到了什么问题？</div>
  <a href="#rf-s1" data-lang="en">I have a bunch of data — how do I describe and summarize it? <span class="pi-arrow">&rarr; &sect;1</span></a>
  <a href="#rf-s1" data-lang="zh">我有一堆数据，怎么描述和概括它？<span class="pi-arrow">&rarr; &sect;1</span></a>
  <a href="#rf-s2" data-lang="en">How do I make inferences about a population from a sample? <span class="pi-arrow">&rarr; &sect;2</span></a>
  <a href="#rf-s2" data-lang="zh">怎么从样本推断总体？<span class="pi-arrow">&rarr; &sect;2</span></a>
  <a href="#rf-s3" data-lang="en">Are the differences I see real, or just noise? <span class="pi-arrow">&rarr; &sect;3</span></a>
  <a href="#rf-s3" data-lang="zh">我看到的差异是真实的，还是只是噪声？<span class="pi-arrow">&rarr; &sect;3</span></a>
  <a href="#rf-s4" data-lang="en">How do two variables relate to each other? <span class="pi-arrow">&rarr; &sect;4</span></a>
  <a href="#rf-s4" data-lang="zh">两个变量之间有什么关系？<span class="pi-arrow">&rarr; &sect;4</span></a>
  <a href="#rf-s5" data-lang="en">What kind of data do I have, and why does it matter? <span class="pi-arrow">&rarr; &sect;5</span></a>
  <a href="#rf-s5" data-lang="zh">我的数据是什么类型的，为什么这很重要？<span class="pi-arrow">&rarr; &sect;5</span></a>
  <a href="#rf-s6" data-lang="en">How do I think about probability and uncertainty? <span class="pi-arrow">&rarr; &sect;6</span></a>
  <a href="#rf-s6" data-lang="zh">怎样理解概率和不确定性？<span class="pi-arrow">&rarr; &sect;6</span></a>
  <a href="#rf-s7" data-lang="en">Are these two groups actually different? <span class="pi-arrow">&rarr; &sect;7</span></a>
  <a href="#rf-s7" data-lang="zh">这两组之间真的有差别吗？<span class="pi-arrow">&rarr; &sect;7</span></a>
</div>

<hr class="section-divider">

<!-- SECTION 1 -->
<div class="section" id="rf-s1">
  <h2 data-lang="en">Describing Data: Center, Spread, and Shape</h2>
  <h2 data-lang="zh">描述数据：中心、分散与形态</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You collect survey responses on income from 500 voters, or education levels from a national census. A pile of numbers tells you nothing. You need to describe what these data look like: Where is the center? How much do values vary? Is the distribution symmetric or lopsided? These descriptions determine what statistical methods you can use later.</p>
    <p data-lang="zh"><strong>问题：</strong>你收集了500个选民的收入调查数据，或国家普查的教育水平数据。一堆数字说不出什么。你需要描述这些数据的样子：中心在哪里？数值变化多大？分布是对称还是偏斜的？这些描述决定了之后能用什么统计方法。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Measures of Center: Mean, Median, and Mode</h3>
    <h3 data-lang="zh">中心度量：平均数、中位数与众数</h3>
    <p class="method-desc" data-lang="en">The mean is the arithmetic average — sum all values and divide by the count. The median is the middle value when data are sorted. The mode is the most frequent value. Each answers a different question about where the "typical" observation lies.</p>
    <p class="method-desc" data-lang="zh">平均数是所有数值的算术平均——把所有值加起来除以个数。中位数是排序后的中间值。众数是最频繁出现的值。每个都从不同角度回答"典型"观察值在哪里这个问题。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> A weather report tells you "the average temperature is 15°C," but if it was 5°C all morning then 25°C in the afternoon, that average is misleading. The median temperature tells you what half the day was cooler and half was warmer. The mode tells you which hour was most common. You need all three to know what the day actually felt like.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>天气报告说"平均气温15°C"，但如果上午一直是5°C，下午跳到25°C，这个平均数就很误导。中位数告诉你有一半时间更冷，一半时间更热。众数告诉你哪个小时最常见。你需要这三个指标才能知道这一天实际感受。</div>
    <p class="method-desc" data-lang="en">The mean is sensitive to extreme values (outliers). If your data include one billionaire in a survey of 99 teachers, the mean income skyrockets while the median stays low. The median is resistant to outliers and often better for describing skewed data. Mode matters most for categorical data (the most common religion) or identifying natural clusters.</p>
    <p class="method-desc" data-lang="zh">平均数对极端值（异常值）很敏感。如果99名教师的调查中包含1个亿万富翁，平均收入会飙升而中位数仍然很低。中位数对异常值有抵抗力，通常更适合描述偏斜数据。众数对分类数据（最常见的宗教）或识别自然聚类最重要。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use the mean when data are roughly symmetric and you're ready to do modeling (regression assumes a mean). Use the median when data are skewed or you're describing what a "typical" person experiences. Avoid reporting only the mean for income, wealth, or other right-skewed variables without also mentioning the median. Report mode for categorical data or when you want to know the most common category.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>当数据大致对称且准备建模时用平均数（回归假设一个平均值）。当数据偏斜或想描述"典型"人的经历时用中位数。避免仅报告收入、财富等右偏变量的平均数，不提中位数。对分类数据或想知道最常见类别时报告众数。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> In a study of political trust, researchers surveyed 1000 citizens on trust in government (0–100 scale). The mean was 52, but the median was 68. This tells you the distribution is left-skewed: most people are moderately trusting, but a tail of very distrustful citizens pulls the mean down. A naive summary using only the mean would miss that most voters actually trust institutions.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>政治信任研究中，研究者调查1000名公民对政府信任度（0-100分）。平均数是52，但中位数是68。这告诉你分布左偏：大多数人适度信任，但一条不信任公民的尾部拉低了平均数。只用平均数的简单总结会遗漏大多数选民其实信任机构这一事实。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Measures of Spread: Variance, Standard Deviation, and Range</h3>
    <h3 data-lang="zh">分散度量：方差、标准差与极差</h3>
    <p class="method-desc" data-lang="en">The range is the distance from minimum to maximum. Variance is the average squared distance from the mean. Standard deviation (SD) is the square root of variance, measured in the same units as the original data. These all measure how spread out your data are.</p>
    <p class="method-desc" data-lang="zh">极差是从最小值到最大值的距离。方差是离平均值距离的平方的平均。标准差（SD）是方差的平方根，单位与原数据相同。这些都衡量数据有多分散。</p>
    <p class="method-desc" data-lang="en">The range is crude — it depends only on the two most extreme values. One outlier can make it huge. Variance and SD measure spread using all data points, and SD is especially useful because it's in the same units as your original variable. If income is measured in thousands of dollars, SD is too. This makes SD intuitive: if the mean is $50k and SD is $15k, you know a lot of people deviate from the mean by roughly $15k.</p>
    <p class="method-desc" data-lang="zh">极差很粗糙——仅依赖两个极端值。一个异常值会让它很大。方差和SD用所有数据点衡量分散，SD特别有用因为它与原变量的单位相同。如果收入以千美元计，SD也是。这使SD直观：如果平均收入5万美元，SD是1.5万美元，你就知道很多人偏离平均值约1.5万美元。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always report both the mean and SD together (or median with the interquartile range for skewed data). Range is useful only for noting min/max, never as your main spread measure. High SD relative to the mean suggests heterogeneity; low SD suggests homogeneity. Use this to judge whether a single mean tells the whole story.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>总是一起报告平均数和SD（或对偏斜数据用中位数和四分位距）。极差仅适合注明最小/最大值，不能作为主要分散度量。相对于平均数的高SD表明异质性；低SD表明同质性。用这个判断单一平均数是否讲了全部故事。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> Two countries have the same mean life expectancy (75 years) but different SDs. Country A has SD=2 years (most people live 73–77 years). Country B has SD=15 years (some live to 60, others to 90). Same average, very different inequality. SD reveals this. A policy maker in Country B would rightly worry about vulnerability even though the average looks good.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>两个国家有相同的平均寿命（75岁），但SD不同。A国SD=2年（大多数人活73-77岁）。B国SD=15年（有人60岁，有人90岁）。平均数相同，不平等程度非常不同。SD揭示了这点。B国的政策制定者尽管平均数看起来不错，仍应该担心脆弱性。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Distribution Shape: Symmetry and Skewness</h3>
    <h3 data-lang="zh">分布形态：对称性与偏度</h3>
    <p class="method-desc" data-lang="en">A symmetric distribution has values balanced around the center. Mean and median are close. Skewness measures asymmetry. Right-skewed (positively skewed) distributions have a tail on the right: some very high values pull the mean above the median. Left-skewed distributions have a tail on the left, pulling the mean below the median.</p>
    <p class="method-desc" data-lang="zh">对称分布的值围绕中心平衡。平均数和中位数接近。偏度衡量不对称性。右偏（正偏）分布右边有尾：一些很高的值将平均数拉到中位数上方。左偏分布左边有尾，把平均数拉到中位数下方。</p>
    <p class="method-desc" data-lang="en">Common distributions in social science and their real-world examples:</p>
    <p class="method-desc" data-lang="zh">社会科学中的常见分布及其真实例子：</p>
    <div data-lang="en" style="overflow-x:auto;margin:16px 0;">
      <table class="paradigm-table">
        <tr>
          <th>Distribution Shape</th>
          <th>Characteristics</th>
          <th>Common Social Science Examples</th>
          <th>What It Looks Like</th>
        </tr>
        <tr>
          <td><strong>Normal (Bell-Shaped)</strong></td>
          <td>Symmetric; mean = median; symmetric tails</td>
          <td>Test scores, IQ, height, measurement error</td>
          <td>Classic bell curve; peaks in middle</td>
        </tr>
        <tr>
          <td><strong>Right-Skewed (Positive)</strong></td>
          <td>Long tail on right; mean > median</td>
          <td>Income, wealth, house prices, page views, crime rates by neighborhood</td>
          <td>Hump on left, long tail extending right</td>
        </tr>
        <tr>
          <td><strong>Left-Skewed (Negative)</strong></td>
          <td>Long tail on left; mean < median</td>
          <td>Test scores in easy exams, age at retirement, education in developed countries, grades</td>
          <td>Hump on right, long tail extending left</td>
        </tr>
        <tr>
          <td><strong>Bimodal (Two Peaks)</strong></td>
          <td>Two distinct clusters; two modes</td>
          <td>Partisan ideology (polarization), height split by gender, voting patterns in divided societies</td>
          <td>Two separate humps; deep valley between</td>
        </tr>
        <tr>
          <td><strong>Uniform</strong></td>
          <td>Flat; equal density across range</td>
          <td>Rare in nature; maybe survey responses split evenly between alternatives</td>
          <td>Flat line across range</td>
        </tr>
      </table>
    </div>
    <div data-lang="zh" style="overflow-x:auto;margin:16px 0;">
      <table class="paradigm-table">
        <tr>
          <th>分布形态</th>
          <th>特征</th>
          <th>常见社会科学例子</th>
          <th>看起来像什么</th>
        </tr>
        <tr>
          <td><strong>正态（钟形）</strong></td>
          <td>对称；平均数 = 中位数；对称尾</td>
          <td>测试分数、IQ、身高、测量误差</td>
          <td>经典钟形曲线；峰值在中间</td>
        </tr>
        <tr>
          <td><strong>右偏（正偏）</strong></td>
          <td>右边长尾；平均数 > 中位数</td>
          <td>收入、财富、房价、页面浏览、社区犯罪率</td>
          <td>左边隆起，右边长尾延伸</td>
        </tr>
        <tr>
          <td><strong>左偏（负偏）</strong></td>
          <td>左边长尾；平均数 < 中位数</td>
          <td>简单考试分数、退休年龄、发达国家教育、成绩</td>
          <td>右边隆起，左边长尾延伸</td>
        </tr>
        <tr>
          <td><strong>双峰（两个峰）</strong></td>
          <td>两个不同聚类；两个众数</td>
          <td>党派意识形态（两极分化）、按性别分的身高、分裂社会投票模式</td>
          <td>两个独立隆起；深谷在中间</td>
        </tr>
        <tr>
          <td><strong>均匀</strong></td>
          <td>平坦；整个范围密度相等</td>
          <td>自然中很少；也许调查回答在选项间均匀分裂</td>
          <td>整个范围的平坦线</td>
        </tr>
      </table>
    </div>
    <p class="method-desc" data-lang="en">Why does this matter? Many statistical tests assume the data are roughly normal (symmetric and bell-shaped). If your data are heavily skewed, those tests may not work well. Income is always right-skewed: most people earn moderate amounts, a few earn huge amounts, nobody earns negative income. Education, when measured as years, is often left-skewed in developed countries: most people finish high school or college, but few don't finish elementary school.</p>
    <p class="method-desc" data-lang="zh">为什么这重要？许多统计检验假设数据大致正态（对称、钟形）。如果数据严重偏斜，这些检验可能不起作用。收入总是右偏：大多数人赚取中等收入，少数赚取巨额，没人赚负收入。教育，按年数计，在发达国家通常左偏：大多数人完成高中或大学，但几乎没人没完成小学。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always visualize your data's shape (histogram or density plot). If it's heavily skewed, consider transformations (log, square root) or using median-based tests. Kurtosis (how heavy the tails are) also matters for some tests, though it's less critical than skewness. Report skewness as a number if it's relevant to your conclusions, but don't obsess over small departures from normality.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>总是可视化数据形态（直方图或密度图）。如果严重偏斜，考虑转换（对数、平方根）或用中位数检验。峰度（尾部有多重）对某些检验也重要，尽管不如偏度关键。如果偏度与结论相关就报告数值，但别过度关注与正态的小偏差。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher studying wealth inequality collects data on household net worth. The data are heavily right-skewed: the top 1% owns far more than median households. Reporting only the mean ($500k) misleads. The median is $100k. A log transformation reveals the shape better, because on a log scale, skewed data compress and become easier to see. The heavily right-skewed raw distribution hides the bulk of variation among non-wealthy households.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>研究财富不平等的研究者收集家庭净资产数据。数据严重右偏：最富的1%拥有远多于中位家庭的财富。仅报告平均值（50万美元）会误导。中位数是10万美元。对数变换更好地揭示形态，因为在对数尺度上，偏斜数据会压缩并更易看清。严重右偏的原始分布掩盖了非富有家庭间的大部分变异。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 2 -->
<div class="section" id="rf-s2">
  <h2 data-lang="en">Inference: From Sample to Population</h2>
  <h2 data-lang="zh">推断：从样本到总体</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You cannot interview all 200 million voters in a country. You draw a sample of 1,500 and ask their opinion. Your sample mean is 55%, but the true population mean is unknown. How close is your estimate? How confident can you be? Sampling theory and the Central Limit Theorem tell you why a modest random sample gives you powerful information about an entire population.</p>
    <p data-lang="zh"><strong>问题：</strong>你无法采访一个国家的全部2亿选民。你抽取1500人的样本并问他们的意见。样本平均值是55%，但真实总体平均值未知。你的估计有多接近？你能有多自信？抽样理论和中心极限定理告诉你为什么一个适度的随机样本能给你关于整个总体的强大信息。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Sampling Distributions and the Standard Error</h3>
    <h3 data-lang="zh">抽样分布与标准误</h3>
    <p class="method-desc" data-lang="en">Imagine taking your sample over and over, each time calculating a mean. Those means vary slightly. The distribution of all possible sample means is called the sampling distribution. The standard error (SE) is the standard deviation of the sampling distribution — it tells you how much sample means typically vary from the true population mean.</p>
    <p class="method-desc" data-lang="zh">想象一遍遍抽取样本，每次计算平均数。这些平均数略有变化。所有可能样本平均数的分布叫做抽样分布。标准误（SE）是抽样分布的标准差——它告诉你样本平均数通常偏离真实总体平均值多少。</p>
    <p class="method-desc" data-lang="en">The standard error is smaller when you have more data. A sample of 10,000 has a smaller SE than a sample of 100, assuming the same underlying population SD. This is why larger samples are more precise. The formula is SE = SD / √n, where n is sample size. Double your sample size, and SE shrinks by 1/√2.</p>
    <p class="method-desc" data-lang="zh">当数据更多时，标准误更小。假设相同的总体SD，10000样本的SE小于100的样本。这就是为什么更大样本更精确。公式是SE = SD / √n，n是样本大小。加倍样本大小，SE缩小1/√2。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> Drawing marbles from a jar. If you draw 5 marbles, the average color value might be 4.2. Draw 5 different marbles, and you get 3.8. Draw 500 marbles, and you'll get something like 4.0 every time. The larger your sample, the more stable your estimate. SE quantifies this stability.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>从罐子里抽玻璃珠。如果你抽5个珠子，平均颜色值可能是4.2。抽5个不同珠子，你得到3.8。抽500个珠子，你每次都会得到约4.0。样本越大，估计越稳定。SE量化了这种稳定性。</div>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always report SE or confidence intervals when presenting sample estimates. Never report a point estimate alone. The SE tells readers how much sampling variability they should expect. For large samples (n &gt; 30), the sampling distribution is nearly normal even if the population is not, thanks to the Central Limit Theorem — a game changer for inference.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>呈现样本估计时总是报告SE或置信区间。从不单独报告点估计。SE告诉读者应该期望多少抽样变异。对于大样本（n &gt; 30），由于中心极限定理，即使总体不正态，抽样分布也几乎正态——这改变了推断的游戏规则。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A political pollster surveys 1,200 voters and finds 52% support for a ballot measure. The SD of the population is roughly 50% (binary response). SE = 50% / √1200 ≈ 1.4%. So the true support is likely between 49.6% and 54.4% (roughly 52% ± 2 × SE). Reporting "52%" without the margin of error obscures the uncertainty. Reporting "52% ± 1.4%" tells the full story.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>政治民调员调查1200名选民，发现52%支持某议案。总体的SD大约50%（二元回答）。SE = 50% / √1200 ≈ 1.4%。所以真实支持度可能在49.6%到54.4%之间（大约52% ± 2×SE）。仅报告"52%"而不提及误差范围隐蔽了不确定性。报告"52% ± 1.4%"讲述了完整故事。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Confidence Intervals: Quantifying Uncertainty</h3>
    <h3 data-lang="zh">置信区间：量化不确定性</h3>
    <p class="method-desc" data-lang="en">A confidence interval (CI) is a range of values likely to contain the true population parameter. A 95% CI means: if we repeated our sampling many times and calculated a CI each time, about 95% of those intervals would contain the true parameter. It is not a probability statement about one interval (the true value is either in it or not), but a long-run frequency statement.</p>
    <p class="method-desc" data-lang="zh">置信区间（CI）是可能包含真实总体参数的值范围。95% CI意思是：如果我们多次重复抽样并每次计算CI，那么大约95%的这些区间会包含真实参数。这不是关于某个区间的概率陈述（真值要么在里面，要么不在），而是长期频率陈述。</p>
    <p class="method-desc" data-lang="en">For a sample mean, the 95% CI is approximately: estimate ± (1.96 × SE). The 1.96 comes from the normal distribution; 95% of values in a normal distribution fall within 1.96 standard deviations of the mean. Wider CIs indicate more uncertainty (smaller samples, higher variability). Narrower CIs indicate more precision (larger samples, less variability).</p>
    <p class="method-desc" data-lang="zh">对于样本平均数，95% CI大约是：估计 ± (1.96 × SE)。1.96来自正态分布；正态分布中95%的值在平均值的1.96个标准差内。更宽的CI表示更多不确定性（较小样本、高变异性）。更窄的CI表示更高精度（更大样本、低变异性）。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always report CIs when you are estimating population parameters from a sample. A 95% CI is standard in social science, but 90% or 99% CIs are defensible depending on the cost of errors. Do not interpret a CI as "there is a 95% chance the true value is in this interval." That interpretation is technically wrong (frequentist) or trivially true (Bayesian). The correct interpretation is harder to state but more accurate: "This interval was constructed by a procedure that captures the true value 95% of the time in repeated sampling."</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>从样本估计总体参数时总是报告CI。95% CI在社会科学中是标准的，但取决于误差成本可以用90%或99%的CI。不要解释CI为"真值在这个区间的概率是95%"。那个解释在技术上是错的（频率主义）或平凡真（贝叶斯）。正确解释更难表述但更准确："这个区间由一个在重复抽样中95%时间捕捉真值的程序构建。"</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher estimates the average years of education in a city. Sample mean is 13.2 years, SE is 0.3 years. The 95% CI is 13.2 ± (1.96 × 0.3) = [12.6, 13.8]. The researcher can report: "The average education is 13.2 years (95% CI: 12.6–13.8)." This conveys both the point estimate and the precision. A 0.2-year CI would suggest a larger, more efficient sample.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>研究者估计一个城市的平均教育年数。样本平均值13.2年，SE 0.3年。95% CI是13.2 ± (1.96 × 0.3) = [12.6, 13.8]。研究者可以报告："平均教育是13.2年（95% CI: 12.6–13.8）。"这既传达了点估计又传达了精度。一个0.2年的CI会暗示一个更大、更高效的样本。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 3 -->
<div class="section" id="rf-s3">
  <h2 data-lang="en">Hypothesis Testing: Signal or Noise?</h2>
  <h2 data-lang="zh">假设检验：信号还是噪声？</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You observe a difference between two groups. Women's average income is 5% lower than men's in your sample. Is this difference real (a signal of actual inequality) or just random noise from sampling variability? Hypothesis testing is the formal framework for answering this question. But it is widely misused and misunderstood in social science.</p>
    <p data-lang="zh"><strong>问题：</strong>你观察到两个组之间的差异。女性在你的样本中的平均收入比男性低5%。这个差异是真实的（真实不平等的信号）还是仅仅来自抽样变异的随机噪声？假设检验是正式回答这个问题的框架。但它在社会科学中被广泛误用和误解。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">The Null Hypothesis and P-Values</h3>
    <h3 data-lang="zh">零假设与P值</h3>
    <p class="method-desc" data-lang="en">The null hypothesis (H₀) is the assumption that there is no effect, no difference, no relationship. The alternative hypothesis (H₁) says there is an effect. You calculate a test statistic (like a t-statistic or chi-square) that measures how far your observed data deviate from what H₀ predicts. The p-value is the probability of observing data as extreme as (or more extreme than) what you actually saw, assuming H₀ is true.</p>
    <p class="method-desc" data-lang="zh">零假设（H₀）是说没有效应、没有差异、没有关系。备择假设（H₁）则说存在某种效应。你计算一个检验统计量（比如t统计或卡方），用来衡量你观察到的数据与零假设预测的有多大差异。P值是指在零假设为真的前提下，看到与你实际观察到的数据一样极端（或更极端）的数据的概率。</p>
    <p class="method-desc" data-lang="en">A p-value of 0.03 does not mean: "There is a 3% chance the null hypothesis is true" or "There is a 97% chance my hypothesis is correct." Those statements are false. The correct meaning is: "If the null hypothesis were true, there would be only a 3% chance of seeing data this extreme due to random sampling alone." Small p-values (p &lt; 0.05) suggest the null is unlikely, but they say nothing about the size or practical importance of an effect.</p>
    <p class="method-desc" data-lang="zh">P值0.03不是说："零假设为真的概率是3%"或者"我的假设正确的概率是97%"。这些都是错误的理解。正确的含义是："如果零假设为真，仅仅由于随机抽样就看到这样极端数据的概率只有3%。"小的P值（p &lt; 0.05）表明零假设不太可能成立，但它们对效应的大小或实际意义一无所知。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> A court trial tests H₀ = "defendant is innocent" versus H₁ = "defendant is guilty." Evidence that is inconsistent with innocence (p &lt; 0.05) leads to conviction. But statistical p &lt; 0.05 is not "beyond a reasonable doubt" in the legal sense. In fact, p &lt; 0.05 in social science often means "unlikely if nothing is happening," but it doesn't mean the effect is large, repeatable, or socially significant. The analogy breaks down because courts care about effect size and social impact; statistics alone do not.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>法庭审判检验H₀="被告无罪"对比H₁="被告有罪"。与无罪相悖的证据（p &lt; 0.05）会导致定罪。但统计意义上的p &lt; 0.05不等于法律意义上的"毫无合理怀疑"。实际上，社会科学中的p &lt; 0.05只是说"如果什么都没发生的话，看到这样的数据不太可能"，但这并不意味着效应很大、可以重复或在社会上有显著影响。类比在此处破裂了，因为法庭关心的是效应的大小和社会影响；而统计学本身则不关心。</div>
    <p class="method-desc" data-lang="en">There are two ways to be wrong: Type I error (false positive: rejecting H₀ when it is actually true) and Type II error (false negative: failing to reject H₀ when it is false). The p-value controls Type I error at the rate you choose (usually 5%). But it does not control Type II error, which depends on sample size and effect size.</p>
    <p class="method-desc" data-lang="zh">犯错误有两种方式：第一类错误（假正，即当零假设实际为真时却拒绝了它）和第二类错误（假负，即当零假设为假时却没有拒绝它）。P值通过你选定的速率（通常是5%）来控制第一类错误。但它不能控制第二类错误，第二类错误的大小取决于样本大小和效应大小。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use p-values when you genuinely have a null hypothesis to test (e.g., "Does this intervention have any effect?"). Avoid using p &lt; 0.05 as the gold standard for truth. A p-value of 0.051 is not meaningfully different from 0.049. Social science is drowning in p-value worship: researchers hunt for p &lt; 0.05 through multiple testing, data dredging, and questionable practices, leading to a replication crisis. Always pair p-values with effect sizes and confidence intervals. Report effect size — the actual magnitude of the difference or relationship — because it tells readers whether the difference, however statistically significant, actually matters.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>当你确实有零假设要检验时才用P值（比如"这个干预有任何效应吗？"）。不要把p &lt; 0.05当成判断真理的黄金标准。P值0.051与0.049之间没有实质性的区别。社会科学陷入了对P值的崇拜：研究者通过多重检验、数据挖掘和可疑的操作方式来寻找p &lt; 0.05，导致了复制危机。一定要把P值与效应大小和置信区间配对报告。报告效应大小——差异或关系的实际幅度——因为它能告诉读者，某个差异即使在统计上显著，是否在实际中有意义。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A study of voter turnout compares a treatment group (receives reminder texts) and a control group (no reminder). Turnout: treatment = 41%, control = 40%, p = 0.04. The p-value is small, so researchers might claim "the treatment works!" But the effect size is only 1 percentage point. If the study cost $50,000 to increase turnout by 1%, the p-value is irrelevant—the real question is whether that 1% gain is worth the cost. Effect size matters more than p-values.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>一项投票率研究比较处理组（收到提醒短信）和对照组（无提醒）。投票率结果：处理组=41%，对照组=40%，p=0.04。P值很小，研究者可能会声称"处理有效！"但实际的效应大小只有1个百分点。如果花费了5万美元的研究经费才将投票率提高了1%，那P值就无关紧要了——真正的问题是那1%的提升是否值得这笔成本。效应大小比P值更重要。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Statistical Versus Practical Significance</h3>
    <h3 data-lang="zh">统计显著与实际显著</h3>
    <p class="method-desc" data-lang="en">A result can be statistically significant (p &lt; 0.05) but not practically significant. With a huge sample size, tiny effects become statistically significant. A correlation of 0.05 between two variables might have p &lt; 0.01 if n = 10,000, but r = 0.05 explains only 0.25% of variance — practically negligible.</p>
    <p class="method-desc" data-lang="zh">一个结果可以在统计上显著（p &lt; 0.05），但在实际上不重要。有非常大的样本时，微小的效应也会变得统计显著。比如两个变量之间只有0.05的相关，但如果n=10000，可能会有p&lt;0.01，但r=0.05仅解释了0.25%的方差——这在实际中可以忽略不计。</p>
    <p class="method-desc" data-lang="en">Conversely, a result can be practically large but not statistically significant if you have a small sample. A job training program that increases annual earnings by $5,000 is practically important. But if your sample has only 50 people and high variance, the p-value might be 0.10, and you cannot confidently claim the effect is real.</p>
    <p class="method-desc" data-lang="zh">反过来说，如果样本很小，一个结果也可能在实际上很大，但在统计上不显著。一个能每年增加收入5000美元的工作培训计划在现实中显然很重要。但如果样本只有50人且方差很大，P值可能是0.10，这时你就无法确信这个效应是真实存在的。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always ask "Does this effect size matter to real people?" before celebrating p &lt; 0.05. Report effect sizes in standardized units (correlation, Cohen's d, odds ratios) so readers can compare across studies. A study with p = 0.001 and a tiny effect size is less informative than a study with p = 0.10 and a medium effect size. Journals increasingly demand effect sizes alongside p-values. Use power analysis before running studies to ensure your sample is large enough to detect effects of practical importance.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>在为p &lt; 0.05庆祝之前，一定要问自己"这个效应大小对真实的人来说重要吗？"要用标准化的单位来报告效应大小（比如相关、Cohen's d、比值比），这样读者才能跨研究进行比较。一项p=0.001但效应很微小的研究，信息量反而不如p=0.10但效应中等的研究。期刊现在越来越要求在报告P值的同时也报告效应大小。在进行研究之前，要使用幂分析来确保样本足够大，能够检测到实际重要的效应。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A large survey (n=5,000) finds that living in an urban area is associated with a 2 percentage point higher voting rate, p = 0.001. Statistically significant, yes. But a 2% difference is small—other factors surely matter far more for explaining voting behavior. A smaller study (n=300) finds that being a poll worker increases voting among election staff by 15 percentage points, p = 0.07. Not statistically significant at the 0.05 level, but the effect size is large and practically meaningful. The second study is more valuable for understanding what really moves voting behavior.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>一项大型调查（n=5000）发现住在城市地区与投票率高2个百分点相关，p=0.001。统计上是显著的。但2%的差异很小——其他因素肯定对解释投票行为的影响大得多。而一项较小的研究（n=300）发现当选举工作人员做投票工作者时，他们的投票率增加了15个百分点，p=0.07。这个结果在0.05的水平上不算统计显著，但效应大小很大且实际有意义。第二项研究对理解什么因素真正推动投票行为的价值要大得多。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Multiple Testing and False Discoveries</h3>
    <h3 data-lang="zh">多重检验与虚假发现</h3>
    <p class="method-desc" data-lang="en">If you run 20 tests at p &lt; 0.05, you expect one false positive by chance alone. Researchers who test many hypotheses without correction are likely to find spurious effects. This is the multiple comparisons problem. Solutions include Bonferroni correction (divide 0.05 by the number of tests), pre-registration (commit to one hypothesis before seeing data), and being honest about exploratory analysis (results that are not pre-registered are suggestive, not confirmatory).</p>
    <p class="method-desc" data-lang="zh">如果你进行20次p &lt; 0.05的检验，仅仅由于随机机会，就有可能出现一个假正。那些测试许多假设却不进行纠正的研究者，很容易找到虚假的效应。这就是多重比较问题。解决方案包括Bonferroni纠正（把0.05除以检验的总数），预注册（在看数据之前就承诺一个假设），以及坦诚地对待探索性分析（非预注册的结果是暗示性的，而不是确认性的）。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Pre-register your hypotheses whenever possible. If you are doing exploratory analysis (asking "what relationships exist?" rather than "does this specific relationship exist?"), use lower thresholds (p &lt; 0.01 or even p &lt; 0.001), apply Bonferroni or other corrections, or clearly label results as exploratory. Do not report p-values for exploratory findings as if they were confirmatory.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>尽可能预注册你的假设。如果你是在进行探索性分析（问"存在什么关系？"而不是"这个特定的关系存在吗？"），应该使用更严格的阈值（p &lt; 0.01甚至p &lt; 0.001），应用Bonferroni或其他类似的纠正，或者清楚地标记结果为探索性的。不要把探索性发现的P值报告得好像是确认性的一样。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher tests whether 30 demographic variables predict political party affiliation. By chance, about 1–2 of these 30 tests will be "significant" at p &lt; 0.05, even if no true relationships exist. The correct approach: pre-register the 5 hypotheses you care most about, test those, and label the other 25 as exploratory. Or apply Bonferroni: 0.05/30 = 0.0017, so only test results with p &lt; 0.0017 count as significant. This avoids mining data for spurious patterns.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>一位研究者测试30个人口统计变量是否能预测政治党派。由于纯粹的随机机会，这30个测试中大约有1-2个会在p &lt; 0.05"显著"，即使根本不存在任何真实关系。正确的做法是：预注册你最关心的5个假设，测试那些，把其他25个标记为探索性。或者使用Bonferroni纠正：0.05/30=0.0017，所以只有p &lt; 0.0017的测试结果才计为显著。这样可以避免为了寻找虚假模式而对数据进行挖掘。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 4 -->
<div class="section" id="rf-s4">
  <h2 data-lang="en">Bivariate Relationships: Correlation and Association</h2>
  <h2 data-lang="zh">双变量关系：相关与关联</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You have data on two variables: education level and income, or temperature and ice cream sales. Do they move together? How strongly? Correlation measures the strength and direction of linear relationships between continuous variables. Chi-square tests association between categorical variables. But finding a strong correlation does not prove causation — a critical mistake in social science.</p>
    <p data-lang="zh"><strong>问题：</strong>你有两个变量的数据：教育水平和收入，或温度和冰淇淋销量。它们一起变动吗？有多强？相关衡量连续变量间线性关系的强度和方向。卡方检验分类变量间的关联。但发现强相关不证明因果——社会科学中的关键错误。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Pearson Correlation and Spearman's Rank Correlation</h3>
    <h3 data-lang="zh">皮尔逊相关与斯皮尔曼秩相关</h3>
    <p class="method-desc" data-lang="en">Pearson correlation (r) ranges from −1 (perfect negative relationship) to +1 (perfect positive relationship), with 0 indicating no linear relationship. It measures how closely two continuous variables move together in a straight-line pattern. Spearman's rank correlation (ρ) does the same thing but for ranked data, making it robust to outliers and monotonic (not necessarily linear) relationships.</p>
    <p class="method-desc" data-lang="zh">皮尔逊相关（r）的范围从−1（完美负相关）到+1（完美正相关），0表示没有线性关系。它衡量的是两个连续变量一起变动有多紧密。斯皮尔曼秩相关（ρ）的原理类似，但用于排序数据，对异常值更稳健，也能捕捉单调的（但不一定是线性的）关系。</p>
    <p class="method-desc" data-lang="en">An r = 0.7 indicates a strong positive correlation: as one variable increases, the other tends to increase. But r does not tell you the slope or the magnitude of change. Correlation is scale-free: r of 0.7 looks the same whether you measure height in meters or feet. This makes correlation useful for comparing relationships across different units. However, correlation can hide important patterns: a relationship might be perfectly nonlinear (e.g., U-shaped), producing r ≈ 0 even though the relationship is very strong.</p>
    <p class="method-desc" data-lang="zh">r=0.7表示强正相关：一个变量增加时，另一个也倾向于增加。但r不会告诉你斜率有多大或变化的幅度如何。相关是无单位的：不管你用米还是英尺来测量高度，r=0.7看起来都一样。这让相关特别适合用来比较不同单位的关系。然而，相关也会隐藏重要的模式：关系可能完全是非线性的（比如U形），导致r≈0，即使关系很强。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> Two musicians play simultaneously. Pearson correlation is like asking "Do they start and stop together? Do louder passages align?" If they do, correlation is high. But correlation doesn't ask "Does one cause the other to play?" Maybe both are following a conductor. Spearman correlation is useful when you only care about whether one is "higher" than the other in a monotonic sense, not the precise agreement.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>两个音乐家同时演奏。皮尔逊相关像是问"他们一起开始和停止吗？更响亮的段落是否对齐？"如果对齐，相关就高。但相关不会问"一个导致另一个演奏吗？"也许他们都在跟随指挥。斯皮尔曼相关在你只关心一个是否在单调的意义上"高于"另一个时很有用，而不需要精确的一致性。</div>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use Pearson r for continuous data that are roughly linear and normally distributed. Use Spearman ρ for ordinal data or when you suspect outliers or nonlinearity. Do not use correlation alone to measure relationships — always visualize with a scatter plot. A strong correlation tells you two variables move together, nothing more. To claim causation, you need theory, experimental design, or causal inference methods (like instrumental variables or regression discontinuity).</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>对大致呈线性和正态的连续数据，使用皮尔逊r。对于有序数据，或者当你怀疑有异常值或非线性关系时，使用斯皮尔曼ρ。不要只用相关来衡量关系——一定要用散点图把数据可视化。强相关只告诉你两个变量一起变动，仅此而已。要声称因果关系，你需要理论依据、实验设计或因果推断方法（比如工具变量或回归断点）。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher finds a correlation of r = 0.6 between years of education and annual income. This is a moderate positive relationship: more education tends to associate with higher income. But this correlation does not prove education causes higher income. Confounding variables could be at work: wealthier families both have more educated parents (who model education) and have more resources for college. An experiment that randomly assigns education to some people and not others would provide causal evidence, but that is infeasible for education. Instead, researchers use methods like regression with control variables to try to isolate education's causal effect.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>一位研究者发现教育年数与年收入之间的相关为 r = 0.6。这表示中等强度的正相关：教育程度越高，收入越倾向于更高。但相关并不能证明教育导致了更高收入。可能有混淆变量在起作用：较富裕的家庭既有受教育程度更高的父母（他们本身就重视教育），也有更多送孩子上大学的资源。一项随机为某些人分配教育而其他人不分配的实验可以提供因果证据，但对教育来说这种实验不可行。因此，研究者使用带控制变量的回归等方法，来尽量隔离教育本身的因果效应。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Correlation Is Not Causation: The Ice Cream and Drowning Example</h3>
    <h3 data-lang="zh">相关不是因果：冰淇淋与溺水的例子</h3>
    <p class="method-desc" data-lang="en">Ice cream sales and drowning deaths are strongly correlated (both increase in summer). But ice cream does not cause drowning. A third variable — warm weather — causes both. This is confounding. A correlation can exist because (a) X causes Y, (b) Y causes X, (c) a third variable Z causes both, (d) X and Y influence each other in feedback loops, or (e) it is pure coincidence. Correlation alone cannot distinguish these cases.</p>
    <p class="method-desc" data-lang="zh">冰淇淋销量和溺水死亡强相关（两者都在夏季增加）。但冰淇淋不导致溺水。第三变量——温暖天气——导致两者。这是混淆。相关可以存在因为(a)X导致Y，(b)Y导致X，(c)第三变量Z导致两者，(d)X和Y在反馈循环中相互影响，或(e)纯巧合。相关单独不能区分这些情况。</p>
    <p class="method-desc" data-lang="en">Social science relationships are almost always confounded. Does heavy TV watching make children aggressive? Or do aggressive children prefer aggressive shows? Or do both stem from parenting quality? Researchers control for confounders by including them in regression models, but they can only control for variables they measure. Unmeasured confounding is a persistent threat. Randomized experiments (where you randomly assign a treatment) and natural experiments (where randomization happens "naturally") can break confounding, but they are often impractical or unethical in social science.</p>
    <p class="method-desc" data-lang="zh">社会科学关系几乎总是混淆的。看重电视使孩子好斗吗？还是好斗孩子喜欢好斗节目？还是两者源于养育质量？研究者通过在回归模型中包含它们来控制混淆，但只能控制他们测量的变量。未测量混淆是持久威胁。随机实验（你随机分配处理）和自然实验（随机化"自然"发生）能打破混淆，但在社会科学中通常不实用或不道德。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Never claim causation from observational correlation without very strong theoretical justification and careful control for plausible confounders. If a large body of evidence points in the same direction (via many studies, different designs, different contexts), you can be more confident. But even strong correlations are consistent with multiple causal stories. Be explicit about what you can and cannot conclude from observational data.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>没有很强的理论理由和对潜在混淆变量的仔细控制，不要从观察性的相关中声称因果关系。如果大量证据从不同方向汇聚指向相同结论（多项研究、不同设计、不同情境），你可以更有信心。但即使是很强的相关，也可能与多种因果解释一致。一定要明确说明从观察数据能够和不能够得出什么结论。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> Research finds that countries with more religious citizens have higher crime rates. Correlation might be positive. But this reflects confounding: wealthier, more developed nations have lower religiosity (secularization) and also lower crime rates for reasons unrelated to religion (stronger institutions, police, courts). Controlling for development level, the "religion causes crime" relationship may vanish. The initial correlation was real but misleading about causation. This is why researchers must think carefully about what confounders matter before collecting data.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>研究发现宗教公民更多的国家有更高犯罪率。相关可能正。但这反映混淆：更富有、更发达的国家有较低宗教（世俗化）且因与宗教无关的原因也有更低犯罪率（更强机构、警察、法院）。控制发展水平，"宗教导致犯罪"关系可能消失。初始相关是真实但对因果误导。这是研究者必须在收集数据前仔细思考什么混淆重要的原因。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Chi-Square Tests for Categorical Data</h3>
    <h3 data-lang="zh">分类数据的卡方检验</h3>
    <p class="method-desc" data-lang="en">When both variables are categorical (religion, party affiliation, employment status), Pearson correlation is inappropriate. Instead, use a chi-square test to assess whether the distribution of one variable differs across levels of the other. The test compares observed counts in a cross-tabulation to the counts you would expect if the variables were independent. A large chi-square statistic (small p-value) suggests the variables are associated.</p>
    <p class="method-desc" data-lang="zh">当两个变量都是分类变量（宗教、政党、就业状态），皮尔逊相关就不适用了。这时应该用卡方检验来评估一个变量的分布是否在另一个变量的不同水平上有所不同。检验会比较交叉表中观察到的计数与在变量独立情况下预期的计数。较大的卡方统计值（即小的P值）表明这两个变量之间存在关联。</p>
    <p class="method-desc" data-lang="en">Chi-square assumes you have large enough sample sizes (typically at least 5 observed counts in each cell of the table). If samples are too small, use Fisher's exact test instead. Chi-square tells you whether an association exists, but not the strength. For effect size with categorical data, use Cramér's V (ranges 0 to 1) or the odds ratio (how many times more likely an outcome is in one group versus another).</p>
    <p class="method-desc" data-lang="zh">卡方检验假设样本足够大（通常表中每个单元格至少有5个观察计数）。如果样本太小，应该改用Fisher精确检验。卡方告诉你关联是否存在，但不能告诉你强度有多大。对于分类数据的效应大小，可以用Cramér's V（范围0到1）或比值比（一个群体相比另一个群体，某个结果的发生概率要高多少倍）。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use chi-square for categorical variables. Always report effect size (Cramér's V or odds ratios), not just the p-value. Be careful with small sample sizes: the test becomes unreliable. If many cells have small counts, you may need to collapse categories, but this sacrifices information. Document your decisions.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>对分类变量使用卡方检验。一定要报告效应大小（Cramér's V或比值比），而不是仅仅报告P值。要小心处理样本大小：当样本太小时，检验的可靠性就会下降。如果许多单元格的计数很小，可能需要合并一些类别，但这样做会损失信息。一定要记录你所做的决定。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher tests whether political party affiliation (Democrat, Republican, Independent) is associated with opinion on climate policy (supports, opposes, undecided). They construct a 3×3 table and run a chi-square test. χ² = 45.2, p &lt; 0.001. The association is statistically significant. But what is the effect size? Cramér's V = 0.25, indicating a small-to-moderate association. This nuance — that the association exists but is not enormous — is lost if only the p-value is reported.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>一位研究者测试政治党派归属（民主党、共和党、独立人士）是否与对气候政策的意见（支持、反对、未定）相关联。他们构建了一个 3×3 的列联表并进行卡方检验。χ² = 45.2，p &lt; 0.001。这个关联在统计上显著。但效应大小是多少呢？Cramér's V = 0.25，表示小到中等程度的关联。如果仅报告 P 值，这种细微差别——关联存在但并不非常强——就会丧失。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 5 -->
<div class="section" id="rf-s5">
  <h2 data-lang="en">Variables and Measurement: What Kind of Data Do You Have?</h2>
  <h2 data-lang="zh">变量与测量：你的数据是什么类型的？</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> Before running any analysis, you need to know what kind of data you are working with. A variable that records "religion" (Catholic, Protestant, Muslim, None) is fundamentally different from one that records "income in dollars." The type of variable determines what statistics you can compute, what graphs make sense, and which models are appropriate. Misidentifying variable types is one of the most common beginner mistakes — and it leads to nonsensical analyses.</p>
    <p data-lang="zh"><strong>问题：</strong>在进行任何分析之前，你需要知道自己面对的是什么类型的数据。记录"宗教信仰"（天主教、新教、伊斯兰教、无）的变量与记录"收入（美元）"的变量有本质区别。变量类型决定了你能计算什么统计量、什么图表有意义、以及什么模型是合适的。搞错变量类型是初学者最常见的错误之一——它会导致毫无意义的分析结果。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">The Four Levels of Measurement</h3>
    <h3 data-lang="zh">测量的四个层级</h3>
    <p class="method-desc" data-lang="en">Variables fall into four levels, from least to most informative:</p>
    <p class="method-desc" data-lang="zh">变量分为四个层级，从信息量最少到最多：</p>
    <div data-lang="en" style="overflow-x:auto;margin:16px 0;">
      <table class="paradigm-table">
        <tr><th>Level</th><th>What It Records</th><th>Examples</th><th>Valid Operations</th></tr>
        <tr><td><strong>Nominal</strong></td><td>Categories with no order</td><td>Religion, race, country, party affiliation</td><td>Counts, mode, chi-square</td></tr>
        <tr><td><strong>Ordinal</strong></td><td>Categories with meaningful order</td><td>Education level (HS/BA/MA/PhD), Likert scale (1–5), social class</td><td>Median, percentiles, Spearman ρ</td></tr>
        <tr><td><strong>Interval</strong></td><td>Equal spacing, arbitrary zero</td><td>Temperature (°C), calendar year, standardized test scores</td><td>Mean, SD, Pearson r, t-tests</td></tr>
        <tr><td><strong>Ratio</strong></td><td>Equal spacing, true zero</td><td>Income ($), age, population, distance</td><td>All operations including ratios ("twice as much")</td></tr>
      </table>
    </div>
    <div data-lang="zh" style="overflow-x:auto;margin:16px 0;">
      <table class="paradigm-table">
        <tr><th>层级</th><th>记录什么</th><th>示例</th><th>可用的运算</th></tr>
        <tr><td><strong>定类（Nominal）</strong></td><td>无顺序的类别</td><td>宗教、种族、国家、政党归属</td><td>计数、众数、卡方检验</td></tr>
        <tr><td><strong>定序（Ordinal）</strong></td><td>有意义顺序的类别</td><td>教育层级（高中/本科/硕士/博士）、李克特量表（1–5）、社会阶层</td><td>中位数、百分位数、Spearman ρ</td></tr>
        <tr><td><strong>定距（Interval）</strong></td><td>等距但零点任意</td><td>温度（°C）、日历年、标准化测验分数</td><td>平均数、标准差、Pearson r、t 检验</td></tr>
        <tr><td><strong>定比（Ratio）</strong></td><td>等距且有真正零点</td><td>收入（$）、年龄、人口、距离</td><td>所有运算，包括比率（"两倍多"）</td></tr>
      </table>
    </div>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> Think of jersey numbers on a basketball team. The number 23 is not "better" than 11 — they are just labels (nominal). Now think of class rankings: 1st, 2nd, 3rd have order, but the gap between 1st and 2nd may be huge while 2nd and 3rd are nearly tied (ordinal). Temperature in Celsius has equal intervals: the difference between 10°C and 20°C equals the difference between 20°C and 30°C, but 0°C doesn't mean "no temperature" (interval). Income in dollars has a true zero: $0 means no income, and $60k is genuinely twice $30k (ratio).</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>想想篮球球衣号码。23 号并不比 11 号"好"——它们只是标签（定类）。再想想班级排名：第 1、第 2、第 3 有顺序，但第 1 和第 2 之间的差距可能很大，而第 2 和第 3 几乎并列（定序）。摄氏温度的间距是等的：10°C 到 20°C 的差距等于 20°C 到 30°C，但 0°C 不意味着"没有温度"（定距）。美元收入有真正的零点：$0 意味着没有收入，$60k 确实是 $30k 的两倍（定比）。</div>
    <p class="method-desc" data-lang="en">A critical practical consequence: computing the mean of a nominal variable is meaningless. If you code religion as 1 = Catholic, 2 = Protestant, 3 = Muslim, the "average religion" of 1.7 tells you nothing. Yet this mistake appears in published research when researchers treat ordinal Likert scales as interval data. Whether this is defensible depends on the number of categories and the assumed spacing — it is a judgment call that you should acknowledge explicitly.</p>
    <p class="method-desc" data-lang="zh">一个关键的实际后果：对定类变量计算平均数毫无意义。如果你把宗教编码为 1=天主教、2=新教、3=伊斯兰教，"平均宗教"1.7 什么都说明不了。然而这种错误在已发表的研究中也会出现——当研究者把有序的李克特量表当作定距数据来处理时就是如此。这样做是否合理取决于类别数量和假设的间距，这是一个需要你明确承认的判断性决定。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always identify the measurement level of every variable before choosing methods. Use frequency tables and bar charts for nominal data. Use medians and box plots for ordinal data. Use means, SDs, and histograms for interval/ratio data. If you treat ordinal as interval (e.g., computing means of Likert responses), state this assumption explicitly and justify it. Many social science debates — including how to analyze survey scales — hinge on this question.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>在选择方法之前，一定要先确定每个变量的测量层级。对定类数据使用频率表和条形图。对定序数据使用中位数和箱线图。对定距/定比数据使用平均数、标准差和直方图。如果你把定序数据当定距来处理（比如对李克特量表计算平均数），要明确说明这个假设并给出理由。社会科学中许多方法论争论——包括如何分析调查量表——都围绕这个问题展开。</div>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A survey asks respondents to rate their satisfaction with democracy on a 1–7 scale. Is this ordinal or interval? If ordinal, you should use median and nonparametric tests. If interval, you can use mean and regression. Most political scientists treat it as interval — arguing that 7 categories with labeled endpoints behave "close enough" to interval for practical purposes. But a researcher studying a 3-point scale (dissatisfied / neutral / satisfied) should think twice before computing means. The fewer the categories, the harder the interval assumption is to defend.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>一项调查请受访者在 1–7 的量表上评价对民主的满意度。这是定序还是定距？如果是定序，应该使用中位数和非参数检验。如果是定距，可以使用平均数和回归。大多数政治学者将其当作定距处理——理由是 7 个类别加上标注端点的量表在实际中"足够接近"定距。但如果研究者面对的是一个只有 3 个选项的量表（不满意 / 中立 / 满意），在计算平均数之前就需要三思了。类别越少，定距假设越难成立。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Sampling: How You Collect Data Shapes What You Can Conclude</h3>
    <h3 data-lang="zh">抽样：数据的收集方式决定了你能得出什么结论</h3>
    <p class="method-desc" data-lang="en">A sample is only useful if it represents the population you care about. A simple random sample (SRS) gives every member of the population an equal chance of being selected — this is the gold standard. But in practice, researchers often use convenience samples (whoever is easiest to reach), stratified samples (divide the population into groups, then sample within each group), or cluster samples (randomly select groups, then survey everyone in selected groups).</p>
    <p class="method-desc" data-lang="zh">样本只有在能代表你关心的总体时才有用。简单随机抽样（SRS）让总体中每个成员被选中的机会相等——这是黄金标准。但在实际中，研究者常使用便利样本（最容易接触到的人）、分层抽样（把总体分成若干组，在每组中抽样）或整群抽样（随机选择若干群体，调查选中群体的所有人）。</p>
    <p class="method-desc" data-lang="en">Selection bias occurs when your sample systematically excludes certain types of people. Online surveys miss people without internet. Phone polls miss those who screen calls. College student samples (common in psychology) are overwhelmingly young, educated, and Western — what Henrich et al. (2010) called WEIRD (Western, Educated, Industrialized, Rich, and Democratic). Findings from WEIRD samples may not generalize to humanity as a whole. Always ask: "Who is missing from my sample, and could that change my conclusions?"</p>
    <p class="method-desc" data-lang="zh">当样本系统性地排除了某些类型的人时，就会出现选择偏差。网络调查漏掉了没有网络的人。电话调查漏掉了屏蔽来电的人。大学生样本（心理学中很常见）绝大多数是年轻、受过高等教育的西方人——Henrich 等人（2010）称之为 WEIRD（西方的、受过教育的、工业化的、富裕的、民主的）群体。来自 WEIRD 样本的发现未必适用于全人类。一定要问自己："谁不在我的样本中？这会改变我的结论吗？"</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always describe your sampling method and discuss its limitations. If using a convenience sample, do not make sweeping generalizations about "all Americans" or "people in general." Stratified sampling improves precision for subgroup comparisons (e.g., oversampling minorities to get reliable estimates). Cluster sampling is cheaper but increases standard errors. Know the trade-offs and report them honestly.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>一定要描述你的抽样方法并讨论其局限。如果使用便利样本，不要对"所有美国人"或"一般人"做笼统的推广。分层抽样能提高子群体比较的精度（比如过采样少数族裔以获得可靠估计）。整群抽样更便宜但会增大标准误。要了解这些取舍并如实报告。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 6 -->
<div class="section" id="rf-s6">
  <h2 data-lang="en">Probability Thinking: The Language of Uncertainty</h2>
  <h2 data-lang="zh">概率思维：不确定性的语言</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You hear that 1% of a population has a disease, and a test for it is 95% accurate. If you test positive, what is the probability you actually have the disease? Most people answer "95%" — and they are badly wrong. The actual answer is about 16%. Understanding probability, conditional probability, and Bayes' rule is essential for interpreting statistical results correctly. Without it, you will misread p-values, confidence intervals, and diagnostic tests.</p>
    <p data-lang="zh"><strong>问题：</strong>你听说某人群中有 1% 的人患有某种疾病，相关检测的准确率是 95%。如果你的检测结果是阳性，你真正患病的概率是多少？大多数人回答"95%"——这是严重的错误。真实答案大约是 16%。理解概率、条件概率和贝叶斯法则对于正确解读统计结果至关重要。不理解它们，你就会误读 p 值、置信区间和诊断测试。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Basic Probability Rules</h3>
    <h3 data-lang="zh">基本概率规则</h3>
    <p class="method-desc" data-lang="en">Probability ranges from 0 (impossible) to 1 (certain). Three key rules: (1) The complement rule: P(not A) = 1 − P(A). If a 30% chance of rain, there is a 70% chance of no rain. (2) The addition rule: for mutually exclusive events, P(A or B) = P(A) + P(B). If 40% of voters are Democrats and 35% are Republicans, 75% belong to one of these two parties. (3) The multiplication rule: for independent events, P(A and B) = P(A) × P(B). The probability of flipping two heads in a row is 0.5 × 0.5 = 0.25.</p>
    <p class="method-desc" data-lang="zh">概率的范围从 0（不可能）到 1（确定）。三条关键规则：(1) 互补规则：P(非A) = 1 − P(A)。如果下雨概率 30%，不下雨就是 70%。(2) 加法规则：对于互斥事件，P(A或B) = P(A) + P(B)。如果 40% 的选民是民主党、35% 是共和党，那么 75% 属于这两个政党之一。(3) 乘法规则：对于独立事件，P(A且B) = P(A) × P(B)。连续两次抛硬币都是正面的概率是 0.5 × 0.5 = 0.25。</p>
    <p class="method-desc" data-lang="en">Independence is crucial and often violated. If knowing that event A happened changes the probability of event B, they are not independent. Knowing someone is a college graduate changes the probability that they earn above $80k. Knowing it rained yesterday changes the probability of rain today. In social science, variables are almost never independent — which is precisely why we study their relationships.</p>
    <p class="method-desc" data-lang="zh">独立性这个概念至关重要，而且经常被违反。如果知道事件 A 发生了会改变事件 B 的概率，那么它们就不是独立的。知道某人是大学毕业生会改变他年收入超过 8 万美元的概率。知道昨天下了雨会改变今天下雨的概率。在社会科学中，变量几乎从不独立——这恰恰就是我们研究它们之间关系的原因。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Conditional Probability and Bayes' Rule</h3>
    <h3 data-lang="zh">条件概率与贝叶斯法则</h3>
    <p class="method-desc" data-lang="en">Conditional probability — P(A|B), read "the probability of A given B" — is the probability of one event occurring given that another has already occurred. P(employed | college degree) is different from P(college degree | employed). The order matters enormously. Confusing these two is called the "prosecutor's fallacy" or "base rate neglect," and it underlies many errors in reasoning.</p>
    <p class="method-desc" data-lang="zh">条件概率——P(A|B)，读作"在 B 发生的条件下 A 的概率"——是指在另一个事件已经发生的情况下，某事件发生的概率。P(有工作|大学学位) 和 P(大学学位|有工作) 是不同的。顺序极其重要。把这两者混淆叫做"检察官谬误"或"基础率忽视"，许多推理错误都源于此。</p>
    <p class="method-desc" data-lang="en">Bayes' rule connects these: P(A|B) = P(B|A) × P(A) / P(B). In the disease testing example: P(disease | positive test) depends on three things — the test accuracy (sensitivity), the base rate of disease in the population, and the false positive rate. When the disease is rare (1%), even a good test (95% accurate) produces many false positives among the 99% of healthy people. That is why P(disease | positive) ≈ 16%, not 95%. This insight is fundamental for interpreting any kind of screening — medical tests, criminal profiling, fraud detection, or statistical significance tests.</p>
    <p class="method-desc" data-lang="zh">贝叶斯法则将它们联系起来：P(A|B) = P(B|A) × P(A) / P(B)。在疾病检测的例子中：P(患病|阳性) 取决于三个因素——检测的准确率（灵敏度）、疾病在人群中的基础率以及假阳性率。当疾病很罕见（1%）时，即使是好的检测（95% 准确）也会在 99% 的健康人中产生大量假阳性。这就是为什么 P(患病|阳性) ≈ 16%，而不是 95%。这个洞见对于理解任何筛查都是基础性的——无论是医学检测、犯罪画像、欺诈检测，还是统计显著性检验。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> Imagine a smoke alarm that goes off 95% of the time when there is a fire, but also has a 5% chance of going off when there is no fire. If fires happen in only 1 out of every 10,000 hours, and the alarm goes off, the chance of an actual fire is tiny — most alarms are false positives. The base rate (how rare the event is) dominates. This is exactly the logic of Bayes' rule, and it applies directly to interpreting p-values: a "significant" result in a field where most hypotheses are false is more likely to be a false positive than you think.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>想象一个烟雾报警器，有火灾时 95% 会响，但没有火灾时也有 5% 的概率误报。如果火灾每 10000 小时才发生 1 次，那么当报警器响了的时候，真正着火的概率极小——大多数警报都是假阳性。基础率（事件有多罕见）起主导作用。这正是贝叶斯法则的逻辑，它也直接适用于解读 p 值：在一个大多数假设都不成立的领域中，一个"显著"结果是假阳性的可能性比你以为的要大得多。</div>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always think about base rates when interpreting conditional probabilities. A 95% accurate classifier is useless if the event is rare enough that false positives swamp true positives. This applies to interpreting statistical significance (most tested hypotheses are probably false, so many "significant" findings are false positives), criminal justice (most people are not criminals, so profiling based on weak predictors catches mostly innocents), and medical screening (low base rates mean high false positive rates). Bayes' rule is not just a formula — it is a way of thinking.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>在解读条件概率时，一定要考虑基础率。如果事件足够罕见以至于假阳性淹没了真阳性，那么 95% 准确率的分类器就没什么用了。这适用于解读统计显著性（大多数被检验的假设可能本来就不成立，所以许多"显著"发现是假阳性），刑事司法（大多数人不是罪犯，所以基于弱预测因素的画像主要抓到的是无辜的人），以及医学筛查（低基础率意味着高假阳性率）。贝叶斯法则不只是一个公式——它是一种思维方式。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">The Normal Distribution and the Central Limit Theorem</h3>
    <h3 data-lang="zh">正态分布与中心极限定理</h3>
    <p class="method-desc" data-lang="en">The normal distribution (bell curve) is symmetric around its mean, with 68% of values within 1 SD, 95% within 2 SD, and 99.7% within 3 SD. Many natural phenomena approximate it: heights, test scores, measurement errors. But many social science variables are not normal — income is skewed, counts are discrete, proportions are bounded.</p>
    <p class="method-desc" data-lang="zh">正态分布（钟形曲线）以均值为中心对称，68% 的值在 1 个标准差以内，95% 在 2 个标准差以内，99.7% 在 3 个标准差以内。许多自然现象近似正态：身高、测验分数、测量误差。但很多社会科学变量并不正态——收入是偏斜的，计数是离散的，比例是有界的。</p>
    <p class="method-desc" data-lang="en">The Central Limit Theorem (CLT) is the most important theorem in statistics. It says: regardless of the population's shape, the sampling distribution of the sample mean approaches a normal distribution as sample size increases. This is why inference works: even if individual incomes are wildly skewed, the average income across many random samples of n=500 will be approximately normally distributed. The CLT justifies using normal-based confidence intervals and hypothesis tests for large samples, even when the underlying data are not normal.</p>
    <p class="method-desc" data-lang="zh">中心极限定理（CLT）是统计学中最重要的定理。它说的是：不管总体的分布是什么形状，样本均值的抽样分布随着样本量增加会趋近于正态分布。这就是推断能成立的原因：即使个体收入分布严重偏斜，许多个随机抽取的 n=500 样本的平均收入也会近似正态分布。CLT 使得我们在大样本情况下可以使用基于正态分布的置信区间和假设检验，即使原始数据本身并非正态分布。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> The CLT kicks in at around n ≥ 30 for most distributions, but heavily skewed or heavy-tailed distributions may require n ≥ 100 or more. Do not assume the CLT applies with very small samples. For small samples with non-normal data, use nonparametric methods (rank tests, permutation tests) or bootstrap methods that do not rely on normality assumptions.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>对于大多数分布，CLT 大约在 n ≥ 30 时开始生效，但严重偏斜或重尾分布可能需要 n ≥ 100 甚至更多。不要在很小的样本中假设 CLT 适用。对于小样本的非正态数据，使用非参数方法（秩检验、置换检验）或不依赖正态性假设的 bootstrap 方法。</div>
  </div>
</div>

<hr class="section-divider">

<!-- SECTION 7 -->
<div class="section" id="rf-s7">
  <h2 data-lang="en">Comparing Two Groups: t-Tests and Beyond</h2>
  <h2 data-lang="zh">比较两组：t 检验及其扩展</h2>

  <div class="challenge-overview">
    <p data-lang="en"><strong>The problem:</strong> You want to know whether men and women differ in political trust, or whether a treatment group scored higher than a control group. The difference in sample means is 3.2 points — but is this a real difference or just sampling noise? The t-test is the workhorse of social science for comparing two groups. But it comes in several flavors, each with different assumptions, and choosing the wrong one gives misleading results.</p>
    <p data-lang="zh"><strong>问题：</strong>你想知道男性和女性在政治信任上是否有差异，或者实验组的得分是否高于对照组。样本均值的差异是 3.2 分——但这是真实差异，还是只是抽样噪声？t 检验是社会科学中比较两组的基本工具。但它有好几个版本，各自有不同的假设，选错了会给出误导性的结果。</p>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Independent Samples t-Test</h3>
    <h3 data-lang="zh">独立样本 t 检验</h3>
    <p class="method-desc" data-lang="en">The independent samples t-test compares the means of two separate groups. The null hypothesis is that the population means are equal (μ₁ = μ₂). The test calculates how many standard errors the observed difference is from zero. A large t-statistic (far from zero) means the observed difference is unlikely under the null.</p>
    <p class="method-desc" data-lang="zh">独立样本 t 检验比较两个独立群体的均值。零假设是两个总体均值相等（μ₁ = μ₂）。检验计算的是观察到的差异距离零有多少个标准误。t 统计量越大（远离零），意味着在零假设下观察到如此差异的可能性越小。</p>
    <p class="method-desc" data-lang="en">Key assumptions: (1) Observations are independent — each person belongs to only one group. (2) The dependent variable is approximately normally distributed in each group (or sample sizes are large enough for CLT). (3) Equal variances in both groups (the "pooled" t-test) — or use Welch's t-test, which does not assume equal variances and is generally preferred. If these assumptions are badly violated, consider the nonparametric Mann-Whitney U test, which compares the ranks of observations rather than their means.</p>
    <p class="method-desc" data-lang="zh">关键假设：(1) 观测值是独立的——每人只属于一组。(2) 因变量在每组中近似正态（或样本量大到 CLT 生效）。(3) 两组方差相等（"合并" t 检验）——或者使用 Welch t 检验，它不需要等方差假设，通常更推荐使用。如果这些假设严重被违反，考虑使用非参数的 Mann-Whitney U 检验，它比较的是观测值的秩（排名）而不是均值。</p>
    <div class="method-example" data-lang="en"><strong>Social science example:</strong> A researcher compares political knowledge scores (0–20) between voters who watch cable news (n=200, mean=12.4, SD=3.1) and those who do not (n=250, mean=10.8, SD=3.5). Welch's t = 5.1, p &lt; 0.001, 95% CI for the difference: [1.0, 2.2]. The difference of 1.6 points is statistically significant. But is it practically meaningful? Cohen's d = 0.49 (a medium effect). The researcher should report both the significance and the effect size, noting that cable news viewers score moderately higher but that the groups overlap substantially.</div>
    <div class="method-example" data-lang="zh"><strong>社会科学例子：</strong>一位研究者比较看有线电视新闻的选民（n=200，均值=12.4，SD=3.1）和不看的选民（n=250，均值=10.8，SD=3.5）的政治知识得分（0–20）。Welch t = 5.1，p &lt; 0.001，差异的 95% CI：[1.0, 2.2]。1.6 分的差异在统计上显著。但在实际上有意义吗？Cohen's d = 0.49（中等效应）。研究者应该同时报告显著性和效应大小，指出有线新闻观众的得分中等程度地更高，但两组有大量重叠。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Paired Samples t-Test</h3>
    <h3 data-lang="zh">配对样本 t 检验</h3>
    <p class="method-desc" data-lang="en">When the same individuals are measured twice (before and after a treatment, or under two different conditions), use a paired t-test. Instead of comparing two group means, it computes the difference for each person, then tests whether the average difference is zero. This eliminates between-person variability, making the test more powerful.</p>
    <p class="method-desc" data-lang="zh">当同一批人被测量两次（处理前后，或不同条件下），使用配对 t 检验。它不是比较两组均值，而是计算每个人的差异，然后检验平均差异是否为零。这消除了个体间的变异，使检验更有效力。</p>
    <div class="method-analogy" data-lang="en"><strong>Analogy:</strong> Imagine comparing two diets for weight loss. Independent design: give Diet A to 50 people and Diet B to 50 different people, then compare average weight loss. Paired design: give each of 50 people Diet A for a month, measure weight loss, then Diet B for a month, and measure again. The paired design is more powerful because each person serves as their own control — you remove the "noise" of different body types, metabolisms, and starting weights.</div>
    <div class="method-analogy" data-lang="zh"><strong>类比：</strong>想象比较两种减肥饮食。独立设计：给 50 人吃饮食 A，另外 50 人吃饮食 B，然后比较平均减重量。配对设计：让同一批 50 人先吃一个月饮食 A、测量减重，再吃一个月饮食 B、再测量。配对设计更有效力，因为每个人都做自己的对照——你消除了不同体型、新陈代谢和起始体重带来的"噪声"。</div>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Use the paired t-test when observations are naturally paired: same person at two time points, same district under two policies, two judges rating the same essays. Do not use the independent t-test for paired data — it ignores the pairing and wastes statistical power. Do not use the paired t-test for independent groups — the resulting "differences" would be meaningless. When the normality assumption is questionable, use the Wilcoxon signed-rank test (the nonparametric equivalent of the paired t-test).</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>当观测值天然成对时使用配对 t 检验：同一个人在两个时间点、同一个地区在两种政策下、两位评委对同一篇论文评分。不要对配对数据使用独立 t 检验——它忽略了配对关系，浪费统计效力。不要对独立群体使用配对 t 检验——算出来的"差异"毫无意义。当正态性假设可疑时，使用 Wilcoxon 符号秩检验（配对 t 检验的非参数等价方法）。</div>
  </div>

  <div class="method-section">
    <h3 data-lang="en">Effect Size: Cohen's d</h3>
    <h3 data-lang="zh">效应大小：Cohen's d</h3>
    <p class="method-desc" data-lang="en">Cohen's d measures the standardized difference between two group means: d = (mean₁ − mean₂) / pooled SD. It tells you how many standard deviations apart the two groups are, regardless of sample size. Conventional benchmarks: d ≈ 0.2 is small, d ≈ 0.5 is medium, d ≈ 0.8 is large. But these are rough guidelines — what counts as "large" depends on the substantive context.</p>
    <p class="method-desc" data-lang="zh">Cohen's d 衡量的是两组均值的标准化差异：d = (均值₁ − 均值₂) / 合并标准差。它告诉你两组之间相距多少个标准差，不受样本量影响。常规基准：d ≈ 0.2 为小效应，d ≈ 0.5 为中效应，d ≈ 0.8 为大效应。但这些只是粗略指南——"大"的含义取决于具体的研究背景。</p>
    <div class="method-when" data-lang="en"><strong>When to use / not use:</strong> Always compute and report effect sizes alongside t-tests. A study with p = 0.001 and d = 0.1 found a tiny effect that happened to reach significance because of a huge sample. A study with p = 0.08 and d = 0.6 found a meaningful effect that might have been significant with a slightly larger sample. Power analysis before data collection uses expected effect size to determine the sample size needed — this should be standard practice in research design.</div>
    <div class="method-when" data-lang="zh"><strong>何时用/不用：</strong>一定要在 t 检验旁边计算并报告效应大小。一项 p = 0.001 且 d = 0.1 的研究发现了一个微小的效应，之所以"显著"仅仅是因为样本量非常大。一项 p = 0.08 且 d = 0.6 的研究发现了一个有意义的效应，如果样本量稍大一些可能就显著了。在数据收集之前进行幂分析，利用预期效应大小来确定所需的样本量——这应该成为研究设计的标准步骤。</div>
  </div>
</div>

<hr class="section-divider">
<!-- GUIDES -->
<div class="section" id="rf-guides">
  <h2 data-lang="en">Guides</h2>
  <h2 data-lang="zh">配套指南</h2>
  <div class="m-list">
    <a class="m-card" href="/methods/guides/reg-found-sampling.html">
      <div class="m-num">▶</div>
      <div class="m-info">
        <div class="m-title" data-lang="en">Central Limit Theorem Simulator</div>
        <div class="m-title" data-lang="zh">中心极限定理模拟器</div>
        <div class="m-desc" data-lang="en">Watch the sampling distribution converge as you increase N — interactive CLT explorer.</div>
        <div class="m-desc" data-lang="zh">拖动样本量滑块，观察抽样分布如何收敛——交互式 CLT 演示。</div>
      </div>
      <div class="m-arrow">→</div>
    </a>
    <a class="m-card" href="/methods/guides/reg-found-inference.html">
      <div class="m-num">▶</div>
      <div class="m-info">
        <div class="m-title" data-lang="en">Hypothesis Testing Step by Step</div>
        <div class="m-title" data-lang="zh">假设检验：一步一步来</div>
        <div class="m-desc" data-lang="en">Interactive p-value and power visualizer with worked political science example.</div>
        <div class="m-desc" data-lang="zh">互动 p 值与检验效能可视化，含政治学真实案例演示。</div>
      </div>
      <div class="m-arrow">→</div>
    </a>
  </div>
</div>

<hr class="section-divider">
<!-- RESOURCES -->
<div class="section" id="rf-resources">
  <h2 data-lang="en">Resources</h2>
  <h2 data-lang="zh">资源</h2>
  <h3 data-lang="en">Key References</h3>
  <h3 data-lang="zh">关键参考</h3>
  <ul class="resource-list">
    <li data-lang="en"><strong>Agresti, A. (2018).</strong> <em>Statistical Methods for the Social Sciences (5th ed.)</em>. Pearson. — The standard introductory textbook covering descriptive statistics, probability, inference, and bivariate methods. Chapters 1–10 align closely with this page.</li>
    <li data-lang="zh"><strong>Agresti, A. (2018).</strong>《社会科学统计方法（第五版）》Pearson出版。——涵盖描述统计、概率、推断和双变量方法的标准入门教材。第1–10章与本页内容紧密对应。</li>
    <li data-lang="en"><strong>Gelman, A., & Stern, H. (2006).</strong> "The Difference Between 'Significant' and 'Not Significant' is not Itself Statistically Significant." <em>The American Statistician</em>, 60(4), 328–331.</li>
    <li data-lang="zh"><strong>Gelman, A. &amp; Stern, H. (2006)。</strong>"'显著'与'不显著'之差本身并非统计显著。"《美国统计学家》，60(4)，328–331。</li>
    <li data-lang="en"><strong>Henrich, J., Heine, S. J., & Norenzayan, A. (2010).</strong> "The Weirdest People in the World?" <em>Behavioral and Brain Sciences</em>, 33(2–3), 61–83. — The landmark paper on WEIRD sampling bias in social science.</li>
    <li data-lang="zh"><strong>Henrich, J., Heine, S. J. &amp; Norenzayan, A. (2010)。</strong>"世界上最奇怪的人？"《行为与脑科学》，33(2–3)，61–83。——关于社会科学中 WEIRD 抽样偏差的标志性论文。</li>
    <li data-lang="en"><strong>Wasserstein, R. L., & Lazar, N. A. (2016).</strong> "The ASA Statement on p-Values: Context, Process, and Purpose." <em>The American Statistician</em>, 70(2), 129–133. — The American Statistical Association's formal statement on the proper use and interpretation of p-values.</li>
    <li data-lang="zh"><strong>Wasserstein, R. L. &amp; Lazar, N. A. (2016)。</strong>"ASA关于p值的声明：背景、过程与目的。"《美国统计学家》，70(2)，129–133。——美国统计协会关于正确使用和解释 p 值的正式声明。</li>
    <li data-lang="en"><strong>Cohen, J. (1992).</strong> "A Power Primer." <em>Psychological Bulletin</em>, 112(1), 155–159. — The classic guide to effect sizes and statistical power.</li>
    <li data-lang="zh"><strong>Cohen, J. (1992)。</strong>"统计检验效能入门。"《心理学通报》，112(1)，155–159。——关于效应大小和统计效能的经典指南。</li>
    <li data-lang="en"><strong>Tukey, J. W. (1977).</strong> <em>Exploratory Data Analysis.</em> Addison-Wesley.</li>
    <li data-lang="zh"><strong>Tukey, J. W. (1977)。</strong>《探索性数据分析》Addison-Wesley出版。</li>
  </ul>
</div>

<!-- PAGE NAV -->
<div class="page-nav">
  <a class="pn-link pn-prev" href="/methods/theoretical-modeling.html">
    <span class="pn-arrow">&larr;</span>
    <span><span class="pn-title">Theoretical Modeling</span></span>
  </a>
  <a class="pn-link pn-next" href="/methods/reg-dataviz.html">
    <span><span class="pn-title">Data Visualization</span></span>
    <span class="pn-arrow">&rarr;</span>
  </a>
</div>
