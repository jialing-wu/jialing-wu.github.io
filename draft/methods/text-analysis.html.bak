<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Text as Data — Research Methods Notebook</title>
<link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,300;0,400;0,500;0,600;1,300;1,400;1,500&family=EB+Garamond:ital,wght@0,400;0,500;1,400&family=Caveat:wght@400;500&family=IBM+Plex+Sans:wght@300;400;500&family=IBM+Plex+Mono:wght@400;500&family=Noto+Serif+SC:wght@300;400;500;600&family=Noto+Sans+SC:wght@300;400;500&display=swap" rel="stylesheet">
<link rel="stylesheet" href="style.css">
<style>
/* ── TA-specific callout ────────────────────────────── */
.method-when{margin:12px 0;padding:10px 14px;border-radius:4px;background:rgba(90,122,107,.05);border:1px solid rgba(90,122,107,.2);font-size:14.5px;line-height:1.65;color:var(--ink-faded)}
.method-when strong{color:var(--leather);font-style:normal}
.formula{font-family:var(--mono);font-size:12.5px;color:var(--ink-soft);background:rgba(30,24,15,.04);padding:8px 12px;border-radius:3px;margin:8px 0;overflow-x:auto;white-space:nowrap;border:1px solid var(--parchment);display:block}

/* ── Pipeline diagram ───────────────────────────────── */
.pipeline{display:flex;align-items:stretch;gap:0;margin:20px 0;overflow-x:auto}
.pipe-step{flex:1;text-align:center;padding:16px 10px;border:1px solid var(--parchment);background:var(--paper);position:relative;min-width:110px}
.pipe-step:first-child{border-radius:4px 0 0 4px}
.pipe-step:last-child{border-radius:0 4px 4px 0}
.pipe-step:not(:last-child){border-right:none}
.pipe-step.active{background:var(--ink);border-color:var(--ink)}
.pipe-num{font-family:var(--sans);font-size:10px;font-weight:600;letter-spacing:.1em;color:var(--gold);margin-bottom:4px}
.pipe-title{font-family:var(--sans);font-size:11px;font-weight:600;color:var(--ink);line-height:1.3}
.pipe-step.active .pipe-title{color:var(--paper)}
.pipe-desc{font-size:11px;color:var(--ink-ghost);margin-top:4px;line-height:1.4}
.pipe-step.active .pipe-desc{color:rgba(248,244,236,.6)}
@media(max-width:860px){.pipeline{flex-wrap:wrap}.pipe-step{min-width:auto;border-radius:4px!important;border:1px solid var(--parchment)!important;margin:3px}}

/* ── Compare grid (TA light footer override) ────────── */
.compare-grid{display:grid;grid-template-columns:1fr 1fr;gap:0;margin:16px 0;border:1px solid var(--parchment);border-radius:4px;overflow:hidden}
.compare-col{padding:18px;background:var(--paper)}
.compare-col.alt{background:var(--warm)}
.compare-label{font-family:var(--sans);font-size:10px;font-weight:700;letter-spacing:.1em;text-transform:uppercase;color:var(--red);margin-bottom:12px}
.compare-footer{grid-column:1/-1;padding:12px 18px;background:rgba(194,153,61,.05);border-top:1px solid var(--parchment);font-size:13px;color:var(--ink-faded);font-style:italic}
.compare-col p{font-size:14.5px;line-height:1.65;color:var(--ink-faded);margin-bottom:8px}
@media(max-width:860px){.compare-grid{grid-template-columns:1fr}}
</style>
</head>
<body class="zh">
<div class="layout">
  <aside class="sidebar" id="sidebar">
    <a class="sb-brand" href="index.html"><h2>Methods <span>Notebook</span></h2><div class="sb-sub">Jialing Wu</div></a>
    <div class="sb-cat">Person-Centered Quantitative Methods</div>
    <a class="sb-link" href="lpa.html"><span class="sb-num">01</span> Latent Profile Analysis</a>
    <div class="sb-cat">Computational Social Science</div>
    <div class="sb-subcat">Foundations</div>
    <a class="sb-link" href="machine-learning.html" style="display:none"><span class="sb-num">01</span> Machine Learning</a>
    <a class="sb-link" href="llm.html" style="display:none"><span class="sb-num">02</span> LLM &amp; NLP</a>
    <a class="sb-link active" href="text-analysis.html"><span class="sb-num">03</span> Text as Data</a>
    <a class="sb-link" href="theoretical-modeling.html"><span class="sb-num">04</span> Theoretical Modeling</a>
    <div class="sb-cat">Statistics</div>
    <div class="sb-subcat">Foundations</div>
    <a class="sb-link" href="empirical-modeling.html"><span class="sb-num">01</span> Empirical Modeling</a>
    <div class="sb-footer"><a href="https://jialing-wu.github.io">&larr; My Website</a></div>
  </aside>
  <div class="sidebar-overlay" id="overlay" onclick="document.getElementById('sidebar').classList.toggle('open');document.getElementById('overlay').classList.toggle('show')"></div>
  <div class="main">
    <div class="topbar">
      <button class="menu-toggle" onclick="document.getElementById('sidebar').classList.toggle('open');document.getElementById('overlay').classList.toggle('show')"><span></span></button>
      <div class="breadcrumb">Computational Social Science<span class="sep">/</span>Foundations<span class="sep">/</span>Text as Data</div>
      <div class="topbar-lang">
        <button class="lang-btn" id="btn-zh" onclick="setLang('zh')">中文</button>
        <button class="lang-btn" id="btn-en" onclick="setLang('en')">EN</button>
      </div>
    </div>
    <div class="content method-page">

      <!-- HEADER -->
      <div class="method-header">
        <h1>Text as Data</h1>
        <div class="method-meta">Computational Social Science &middot; Foundations 03</div>
        <div data-lang="en"><p class="subtitle">Notes from ICPSR 2024 "Data Science &amp; Text Analysis", University of Michigan &middot; <a href="https://www.polisci.pitt.edu/people/yaoyao-dai" target="_blank" style="color:var(--red);border-bottom:1px solid var(--red)">Prof. Yaoyao Dai</a></p></div>
        <div data-lang="zh"><p class="subtitle">笔记整理自 ICPSR 2024「Data Science &amp; Text Analysis」, University of Michigan &middot; <a href="https://www.polisci.pitt.edu/people/yaoyao-dai" target="_blank" style="color:var(--red);border-bottom:1px solid var(--red)">Prof. Yaoyao Dai</a></p></div>
      </div>

      <!-- INTRO CARDS -->
      <div class="intro-cards">
        <div class="intro-card">
          <div class="card-label" data-lang="en">What Is This Course?</div>
          <div class="card-label" data-lang="zh">这门课是什么？</div>
          <div data-lang="en"><p>Text analysis transforms unstructured text — documents, social media, speeches — into quantitative data for research. We cover the full pipeline from raw text to statistical analysis: preprocessing, tokenization, document-term matrices, topic models, sentiment analysis, and classification.</p></div>
          <div data-lang="zh"><p>文本分析将非结构化文本——文档、社交媒体、演讲——转化为定量研究数据。我们涵盖从原始文本到统计分析的完整流程：预处理、分词、文档-词项矩阵、主题模型、情感分析和分类。</p></div>
        </div>
        <div class="intro-card">
          <div class="card-label" data-lang="en">Prerequisites</div>
          <div class="card-label" data-lang="zh">先修课程</div>
          <div data-lang="en"><p>Basic statistics and comfort with data manipulation. Some programming experience helpful (R or Python). No linguistics background needed — we explain text processing concepts from the ground up.</p></div>
          <div data-lang="zh"><p>基础统计学和数据处理基础。有编程经验最好（R 或 Python）。不需要语言学背景——我们从基础开始讲解文本处理概念。</p></div>
        </div>
        <div class="intro-card">
          <div class="card-label" data-lang="en">Software</div>
          <div class="card-label" data-lang="zh">软件工具</div>
          <div data-lang="en"><p>R with quanteda, tidytext, and stm packages; Python with scikit-learn, gensim, and spaCy. Both ecosystems are well-supported for text analysis in social science.</p></div>
          <div data-lang="zh"><p>R 配合 quanteda、tidytext 和 stm 包；Python 配合 scikit-learn、gensim 和 spaCy。两个生态系统都能很好支持社会科学文本分析。</p></div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ===== PIPELINE OVERVIEW ===== -->
      <div class="section" id="ta-pipeline">
        <h2 data-lang="en">The Text Analysis Framework</h2>
        <h2 data-lang="zh">文本分析框架</h2>

        <div class="challenge-overview">
          <div data-lang="en"><p>The core challenge: text is the richest data source in the social sciences — yet computers cannot read it. Before any analysis, we must answer three questions: <strong>How do we turn words into numbers?</strong> (Representation) <strong>What patterns do we want to find?</strong> (Supervised vs. unsupervised) <strong>How do we know if our results are valid?</strong> (Measurement and ethics). These questions organize the four modules below.</p></div>
          <div data-lang="zh"><p>核心挑战：文本是社会科学中最丰富的数据来源——但计算机无法直接阅读它。在任何分析之前，我们必须回答三个问题：<strong>如何把文字转化为数字？</strong>（表示）<strong>我们想找到什么规律？</strong>（有监督 vs. 无监督）<strong>如何知道结果是否有效？</strong>（测量与伦理）。这三个问题贯穿以下四个模块。</p></div>
        </div>

        <div data-lang="en"><p>Every text analysis project, regardless of method, follows the same five-step pipeline. The complexity differs — a dictionary count takes minutes; fine-tuning a language model takes days — but the logical flow is always the same.</p></div>
        <div data-lang="zh"><p>每个文本分析项目，不论使用哪种方法，都遵循相同的五步流程。复杂程度不同——词典计数只需几分钟，微调语言模型需要几天——但逻辑顺序始终一样。</p></div>

        <div class="pipeline">
          <div class="pipe-step">
            <div class="pipe-num">01</div>
            <div class="pipe-title" data-lang="en">Collect</div>
            <div class="pipe-title" data-lang="zh">数据收集</div>
            <div class="pipe-desc" data-lang="en">APIs, scraping, corpora</div>
            <div class="pipe-desc" data-lang="zh">API、爬虫、语料库</div>
          </div>
          <div class="pipe-step active">
            <div class="pipe-num">02</div>
            <div class="pipe-title" data-lang="en">Preprocess</div>
            <div class="pipe-title" data-lang="zh">预处理</div>
            <div class="pipe-desc" data-lang="en">Tokenize, clean, normalize</div>
            <div class="pipe-desc" data-lang="zh">分词、清洗、标准化</div>
          </div>
          <div class="pipe-step">
            <div class="pipe-num">03</div>
            <div class="pipe-title" data-lang="en">Represent</div>
            <div class="pipe-title" data-lang="zh">特征表示</div>
            <div class="pipe-desc" data-lang="en">BoW, TF-IDF, embeddings</div>
            <div class="pipe-desc" data-lang="zh">词袋、TF-IDF、词嵌入</div>
          </div>
          <div class="pipe-step">
            <div class="pipe-num">04</div>
            <div class="pipe-title" data-lang="en">Analyze</div>
            <div class="pipe-title" data-lang="zh">分析建模</div>
            <div class="pipe-desc" data-lang="en">Classify, cluster, scale</div>
            <div class="pipe-desc" data-lang="zh">分类、聚类、量表化</div>
          </div>
          <div class="pipe-step">
            <div class="pipe-num">05</div>
            <div class="pipe-title" data-lang="en">Validate</div>
            <div class="pipe-title" data-lang="zh">验证评估</div>
            <div class="pipe-desc" data-lang="en">Evaluate, interpret</div>
            <div class="pipe-desc" data-lang="zh">评价、解读</div>
          </div>
        </div>

        <div data-lang="en"><p>This course addresses four fundamental challenges in text analysis, organized into four modules:</p></div>
        <div data-lang="zh"><p>本课程围绕文本分析的四个根本挑战展开，组织为四个模块：</p></div>

        <div class="modules-overview">
          <div class="module-card">
            <h4 data-lang="en">Module 1: From Text to Numbers</h4>
            <h4 data-lang="zh">模块 1：从文字到数字</h4>
            <p data-lang="en">Challenge 1: How do we convert raw, messy human language into numerical representations a computer can analyze? Preprocessing, Bag of Words, TF-IDF, and word embeddings.</p>
            <p data-lang="zh">挑战 1：如何将杂乱的人类语言转化为计算机可分析的数字表示？预处理、词袋模型、TF-IDF、词嵌入。</p>
          </div>
          <div class="module-card">
            <h4 data-lang="en">Module 2: Unsupervised Discovery</h4>
            <h4 data-lang="zh">模块 2：无监督发现</h4>
            <p data-lang="en">Challenge 2: What if you have thousands of texts but no labels? Dictionary methods, topic models (LDA, STM), and text scaling (Wordscores, Wordfish).</p>
            <p data-lang="zh">挑战 2：如果你有成千上万的文本但没有标签怎么办？词典方法、主题模型（LDA、STM）、文本量表化（Wordscores、Wordfish）。</p>
          </div>
          <div class="module-card">
            <h4 data-lang="en">Module 3: Supervised Classification</h4>
            <h4 data-lang="zh">模块 3：有监督分类</h4>
            <p data-lang="en">Challenge 3: Given labeled training data, how do we teach a model to categorize new text? Random Forest, neural networks, BERT, GPT, and evaluation metrics.</p>
            <p data-lang="zh">挑战 3：有标注训练数据时，如何教模型对新文本分类？随机森林、神经网络、BERT、GPT、评估指标。</p>
          </div>
          <div class="module-card">
            <h4 data-lang="en">Module 4: Research Design &amp; Validity</h4>
            <h4 data-lang="zh">模块 4：研究设计与效度</h4>
            <p data-lang="en">Challenge 4: How do we ensure our text analysis is valid, reliable, and ethical? Annotation, inter-rater agreement, active learning, ethics, and method selection.</p>
            <p data-lang="zh">挑战 4：如何确保文本分析有效、可靠且合乎伦理？标注、评分者间信度、主动学习、伦理、方法选择。</p>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ===== MODULE 1: FROM TEXT TO NUMBERS ===== -->
      <div class="section" id="ta-module1">
        <h2 data-lang="en">Module 1: From Text to Numbers</h2>
        <h2 data-lang="zh">模块 1：从文字到数字</h2>

        <div class="challenge-overview">
          <div data-lang="en"><p>Computers only understand numbers, not words. Before any analysis is possible, we must <strong>clean</strong> raw text (preprocessing), then <strong>convert</strong> it into numerical form (representation). The representation you choose shapes everything that follows: what patterns are visible, what distinctions are possible, what nuances are lost.</p></div>
          <div data-lang="zh"><p>计算机只懂数字，不懂文字。在进行任何分析之前，我们必须先<strong>清洗</strong>原始文本（预处理），再<strong>转化</strong>为数字形式（表示）。你选择的表示方式决定了一切：什么规律可见、什么区别可辨、什么细节丢失。</p></div>
        </div>

        <!-- Preprocessing -->
        <div class="method-section">
          <h3 data-lang="en">Text Preprocessing</h3>
          <h3 data-lang="zh">文本预处理</h3>
          <div data-lang="en">
            <p class="method-desc">Think of raw text like vegetables fresh from the market — before cooking, you need to wash, peel, and chop them. Text preprocessing is similar: we clean and standardize raw text so the computer can work with it effectively. The main steps are: <strong>tokenization</strong> (chopping a sentence into individual words), <strong>lowercasing</strong> ("The" and "the" become the same word), <strong>removing stop words</strong> (common words like "the," "is," "and" that carry little meaning), and <strong>stemming/lemmatization</strong> (reducing words to their root form, so "running," "ran," and "runs" all become "run").</p>
            <div class="method-example">Denny &amp; Spirling (2018): These preprocessing choices matter a lot — different preprocessing can lead to completely different substantive conclusions. Always test your choices systematically before committing to them.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">把原始文本想象成刚从菜市场买回来的蔬菜——做菜之前要洗净、削皮、切好。文本预处理也是如此：我们清洗和标准化原始文本，让计算机能有效处理。主要步骤包括：<strong>分词</strong>（把一句话切成一个个词语）、<strong>小写化</strong>（"The"和"the"统一成同一个词）、<strong>去除停用词</strong>（"the""is""and"这类没有实际含义的常见词）、<strong>词干提取/词形还原</strong>（把词还原到词根形式，让"running""ran""runs"都变成"run"）。</p>
            <div class="method-example">Denny &amp; Spirling (2018)：这些预处理选择非常重要——不同的预处理方式可能导致完全不同的实质性结论。在确定方案之前，务必系统地测试各种选择。</div>
          </div>

          <div class="compare-grid">
            <div class="compare-col">
              <div class="compare-label" data-lang="en">Stemming</div>
              <div class="compare-label" data-lang="zh">词干提取 (Stemming)</div>
              <div data-lang="en">
                <p><strong>Method:</strong> Rule-based suffix stripping (e.g., Porter Stemmer)</p>
                <p><strong>Example:</strong> "running" &rarr; "run", "studies" &rarr; "studi"</p>
                <p><strong>Pro:</strong> Fast, simple, language-independent</p>
                <p><strong>Con:</strong> Can produce non-words ("studi") — may hurt interpretability</p>
              </div>
              <div data-lang="zh">
                <p><strong>方法：</strong>基于规则的后缀截断（如 Porter Stemmer）</p>
                <p><strong>示例：</strong>"running" &rarr; "run", "studies" &rarr; "studi"</p>
                <p><strong>优点：</strong>速度快、简单、语言无关</p>
                <p><strong>缺点：</strong>可能产生非词形式（"studi"）——降低可解释性</p>
              </div>
            </div>
            <div class="compare-col alt">
              <div class="compare-label" data-lang="en">Lemmatization</div>
              <div class="compare-label" data-lang="zh">词形还原 (Lemmatization)</div>
              <div data-lang="en">
                <p><strong>Method:</strong> Dictionary-based reduction to canonical form</p>
                <p><strong>Example:</strong> "running" &rarr; "run", "better" &rarr; "good"</p>
                <p><strong>Pro:</strong> Produces real words, context-aware, better interpretability</p>
                <p><strong>Con:</strong> Slower, requires part-of-speech (POS) tagging</p>
              </div>
              <div data-lang="zh">
                <p><strong>方法：</strong>基于词典还原为标准词形</p>
                <p><strong>示例：</strong>"running" &rarr; "run", "better" &rarr; "good"</p>
                <p><strong>优点：</strong>产生真实词汇、考虑上下文、可解释性更好</p>
                <p><strong>缺点：</strong>较慢，需要词性标注</p>
              </div>
            </div>
            <div class="compare-footer" data-lang="en">Golden rule: test both on your specific corpus. For social science texts, lemmatization is usually preferred — the words remain human-readable.</div>
            <div class="compare-footer" data-lang="zh">黄金法则：在你的具体语料库上同时测试。对于社会科学文本，通常优先选择词形还原——词语保持人类可读性。</div>
          </div>
          <p data-lang="en"><a class="sim-link" href="guides/ta-preprocessing.html">▶ Interactive Lab: Text Preprocessing</a></p>
          <p data-lang="zh"><a class="sim-link" href="guides/ta-preprocessing.html">▶ 互动实验室：文本预处理</a></p>
        </div>

        <!-- Bag of Words & TF-IDF -->
        <div class="method-section">
          <h3 data-lang="en">Bag of Words &amp; TF-IDF</h3>
          <h3 data-lang="zh">词袋模型与 TF-IDF</h3>
          <div data-lang="en">
            <p class="method-desc"><strong>Bag of Words (BoW)</strong> is the simplest idea: throw all the words of a document into a "bag," shake it up (forget the order), and just count how many times each word appears. The result is a big table called a <strong>Document-Term Matrix (DTM)</strong> — each row is a document, each column is a word, each cell is a word count.</p>
            <div class="method-analogy">Analogy: Imagine dumping all the words of an essay onto a table and sorting them into piles. You know what words were used and how often, but you've lost the order they appeared in — "dog bites man" and "man bites dog" look identical.</div>
            <p class="method-desc"><strong>TF-IDF</strong> improves on raw word counts by asking: "Is this word special to THIS document, or does it appear everywhere?" Words that appear in almost every document (like "the" or "is") get downweighted, while words unique to a few documents get boosted. This helps surface the words that truly distinguish one document from another.</p>
            <code class="formula">TF-IDF(t, d) = TF(t, d) &times; log(N / DF(t))</code>
            <p class="method-desc">TF = how often word t appears in document d. IDF = log(total documents / documents containing t) — rarer words get higher IDF. Words that are common in THIS document but rare everywhere else get the highest TF-IDF scores.</p>
            <div class="method-when"><strong>When to use:</strong> A great starting point for most text projects. Works well for document classification and keyword extraction. Key limitation: treats words as independent — doesn't understand that "happy" and "joyful" are similar.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc"><strong>词袋模型 (BoW)</strong> 是最简单的思路：把一篇文档的所有词丢进一个"袋子"，摇一摇（忘掉顺序），然后数每个词出现了几次。结果是一张大表格叫<strong>文档-词项矩阵（DTM）</strong>——每一行是一篇文档，每一列是一个词，每个格子是词频。</p>
            <div class="method-analogy">类比：想象把一篇文章的所有字词倒在桌上，按词分堆。你知道用了哪些词、用了几次，但丢失了它们出现的顺序——"狗咬人"和"人咬狗"看起来完全一样。</div>
            <p class="method-desc"><strong>TF-IDF</strong> 在原始词频的基础上多问了一个问题："这个词是这篇文档独有的，还是到处都有？"几乎每篇文档都出现的词被降权，而只在少数文档中出现的词被升权。这样就能找出真正让一篇文档区别于其他文档的关键词。</p>
            <code class="formula">TF-IDF(t, d) = TF(t, d) &times; log(N / DF(t))</code>
            <p class="method-desc">TF = 词 t 在文档 d 中出现的次数。IDF = log(总文档数 / 包含 t 的文档数)——越稀有的词 IDF 越高。在本文档常见但在其他文档稀有的词，TF-IDF 得分最高。</p>
            <div class="method-when"><strong>适用场景：</strong>大多数文本项目的绝佳起点。适合文档分类和关键词提取。主要局限：把每个词视为独立的——不理解"开心"和"高兴"是近义词。</div>
          </div>
          <p data-lang="en"><a class="sim-link" href="guides/ta-tfidf.html">▶ Interactive Explorer: TF-IDF &amp; Document-Term Matrix</a></p>
          <p data-lang="zh"><a class="sim-link" href="guides/ta-tfidf.html">▶ 互动探索：TF-IDF 与文档-词项矩阵</a></p>
        </div>

        <!-- Word Embeddings -->
        <div class="method-section">
          <h3 data-lang="en">Word Embeddings (Word2Vec, GloVe)</h3>
          <h3 data-lang="zh">词嵌入（Word2Vec、GloVe）</h3>
          <div data-lang="en">
            <p class="method-desc">BoW treats every word as completely unrelated — but we know "happy" and "joyful" are similar! Word embeddings fix this by representing each word as a list of numbers (a "vector") where similar words have similar numbers. The core idea is beautifully simple: <strong>"you shall know a word by the company it keeps"</strong> (Firth, 1957). If "cat" and "dog" often appear near the same words ("pet," "feed," "cute"), they must mean similar things.</p>
            <div class="method-analogy">Analogy: Think of words as people at a party. If two people always hang out in the same social circles, they probably have similar interests — even if they've never met each other directly.</div>
            <p class="method-desc"><strong>Word2Vec</strong> (Mikolov et al., 2013) learns these vectors by training a simple neural network: either predict a word from its neighbors (CBOW) or predict neighbors from a word (Skip-gram). The famous result: <em>vec("king") − vec("man") + vec("woman") ≈ vec("queen")</em> — the model learned gender relationships just from reading text!</p>
            <p class="method-desc"><strong>GloVe</strong> (Pennington et al., 2014) takes a different approach: instead of looking at local word windows, it analyzes overall co-occurrence statistics across the entire corpus. Both methods produce 100–300 dimensional vectors where geometric distance captures semantic similarity.</p>
            <div class="method-when"><strong>When to use:</strong> When you need the model to understand word similarity — e.g., measuring semantic change over time, detecting bias in historical text, or as input features for more complex classifiers. Not ideal when interpretability ("which words caused this?") matters most.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">词袋模型把每个词都当作完全无关的——但我们知道"开心"和"高兴"是近义词！词嵌入解决了这个问题：把每个词表示为一串数字（"向量"），意思相近的词，向量也相近。核心思想非常优美：<strong>"通过一个词的伙伴来了解它"</strong>（Firth, 1957）。如果"猫"和"狗"经常出现在相同的词旁边（"宠物""喂""可爱"），它们的意思一定很接近。</p>
            <div class="method-analogy">类比：把词想象成派对上的人。如果两个人总在同一个社交圈里出现，他们大概有相似的兴趣——即使他们从未直接见过面。</div>
            <p class="method-desc"><strong>Word2Vec</strong>（Mikolov et al., 2013）通过训练简单神经网络学习向量：要么从邻居词预测中心词（CBOW），要么从中心词预测邻居词（Skip-gram）。著名结果：<em>vec("king") − vec("man") + vec("woman") ≈ vec("queen")</em>——仅靠阅读文本就学会了性别关系！</p>
            <p class="method-desc"><strong>GloVe</strong>（Pennington et al., 2014）采用不同方法：不看局部词窗口，而是分析整个语料库的全局共现统计。两种方法都生成 100–300 维向量，向量空间的几何距离捕获语义相似性。</p>
            <div class="method-when"><strong>适用场景：</strong>需要模型理解词义相似时——如测量词义随时间的变化、检测历史文本中的偏见，或作为更复杂分类器的输入特征。当可解释性（"是哪些词导致的？"）最重要时，不是首选。</div>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ===== MODULE 2: UNSUPERVISED DISCOVERY ===== -->
      <div class="section" id="ta-module2">
        <h2 data-lang="en">Module 2: Unsupervised Discovery</h2>
        <h2 data-lang="zh">模块 2：无监督发现</h2>

        <div class="challenge-overview">
          <div data-lang="en"><p>What if you have thousands of documents but no labels — nobody has told you which category each one belongs to? <strong>Unsupervised methods let the data speak for itself.</strong> They discover hidden patterns, topics, and dimensions without any labeled training data. The key question shifts from "is this positive or negative?" to "what's actually in here?"</p></div>
          <div data-lang="zh"><p>如果你有成千上万的文档，但没有标签——没人告诉你每篇属于什么类别怎么办？<strong>无监督方法让数据自己"说话"。</strong>它们在没有任何标注训练数据的情况下发现隐藏的模式、主题和维度。关键问题从"这是正面还是负面？"变成了"这里面到底有什么？"</p></div>
        </div>

        <!-- Dictionary Methods -->
        <div class="method-section">
          <h3 data-lang="en">Dictionary Methods &amp; Sentiment Analysis</h3>
          <h3 data-lang="zh">词典方法与情感分析</h3>
          <div data-lang="en">
            <p class="method-desc">The simplest text analysis you can do: make a word list, then count. For example, a sentiment dictionary might say "happy" = +1, "terrible" = −1, "okay" = 0. To score a document, just add up the scores of all its words. Popular dictionaries include LIWC (psychological processes), AFINN (sentiment), and Hu &amp; Liu (opinion mining).</p>
            <div class="method-analogy">Analogy: It's like grading an essay by counting how many "good" words vs. "bad" words it uses — crude, but surprisingly useful as a first pass when you have clear, domain-relevant word lists.</div>
            <p class="method-desc"><strong>Strengths:</strong> Transparent (you can see exactly why a document got its score), reproducible, and requires zero training data. <strong>Limitations:</strong> Can't handle negation — it thinks "not good" is positive (it sees "good"!), misses sarcasm entirely, and the same word can mean different things in different domains ("sick" is negative in healthcare but positive in slang). Always validate against human-coded ground truth before trusting dictionary scores.</p>
            <div class="method-when"><strong>When to use:</strong> When you have a clear construct that maps onto known word lists — classic sentiment, psychological categories (LIWC), or domain-specific concepts. A great first pass before investing in more complex methods. Do NOT use when the language is domain-specific, sarcastic, or when negation is common.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">最简单的文本分析：建个词表，然后数数。比如，一个情感词典可能规定"开心"= +1，"糟糕"= −1，"一般"= 0。给一篇文档打分，就是把所有词的分数加起来。常见词典包括 LIWC（心理过程）、AFINN（情感）和 Hu &amp; Liu（意见挖掘）。</p>
            <div class="method-analogy">类比：就像通过数一篇文章里有多少"好词"和"坏词"来打分——粗糙，但当你有清晰、与领域相关的词表时，作为初步分析效果出奇地好。</div>
            <p class="method-desc"><strong>优势：</strong>透明（你能清楚看到为什么一篇文档得了这个分数）、可复现、完全不需要训练数据。<strong>局限：</strong>不处理否定——它会认为"不好"是正面的（因为它看到了"好"！），完全忽略讽刺，而且同一个词在不同领域含义不同（"有毒"在化学里是危险的，在网络用语里可能是"太搞笑了"）。使用前务必对照人工编码的黄金标准验证。</p>
            <div class="method-when"><strong>适用场景：</strong>当你研究的概念能清晰映射到已知词表时——经典情感分析、心理类别（LIWC）或领域特定概念。更复杂方法前的良好起点。不要在语言具有领域特异性、讽刺性或否定用法普遍时使用。</div>
          </div>
        </div>

        <!-- Topic Models LDA -->
        <div class="method-section">
          <h3 data-lang="en">Topic Models — LDA</h3>
          <h3 data-lang="zh">主题模型——LDA</h3>
          <div data-lang="en">
            <p class="method-desc">"What are people talking about?" — that's the question topic models answer. <strong>Latent Dirichlet Allocation (LDA)</strong> (Blei et al., 2003) imagines that every document was generated by mixing a few hidden "topics," and every topic is defined by a cluster of words that tend to appear together. LDA's job: given the documents you see, reverse-engineer the topics that could have produced them.</p>
            <div class="method-analogy">Analogy: Imagine each article is a cocktail mixed from a few flavor concentrates. Each concentrate (topic) has its own characteristic blend of ingredients (words). LDA finds the flavor concentrates by tasting the cocktails — it never directly observes the concentrates, only the resulting mixture.</div>
            <p class="method-desc">The researcher must choose how many topics <em>K</em> to look for — there's no single right answer. Common tools for choosing K: held-out perplexity (does the model generalize?), topic coherence scores (do top words co-occur in the corpus?), and interpretability checks ("do these topics make sense to a human?"). The <em>validate in both directions</em> principle: topics should be statistically coherent AND meaningfully interpretable.</p>
            <div class="method-when"><strong>When to use:</strong> You have a large collection of texts and want to discover what themes they cover — without reading them all yourself. Great for exploratory content analysis, agenda-setting research, and any project where the categories are unknown in advance.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">"大家都在讨论什么？"——这就是主题模型要回答的问题。<strong>潜在狄利克雷分配（LDA）</strong>（Blei et al., 2003）假设每篇文档由几个隐藏的"主题"混合生成，每个主题由一组常一起出现的词来定义。LDA 的任务：给定你看到的文档，反向推理出可能产生它们的主题。</p>
            <div class="method-analogy">类比：想象每篇文章是由几种浓缩口味混合而成的鸡尾酒。每种浓缩液（主题）有其特有的成分组合（词语）。LDA 通过品尝鸡尾酒来找浓缩液——它从未直接观察浓缩液，只看到最终的混合物。</div>
            <p class="method-desc">研究者需要选择寻找多少个主题 <em>K</em>——没有唯一正确的答案。常用工具：留出困惑度（模型是否能泛化？）、主题连贯性分数（高频词是否在语料库中共现？）、可解释性检查（"这些主题对人类有意义吗？"）。<em>双向验证</em>原则：主题应该统计上连贯，同时在实质上可解读。</p>
            <div class="method-when"><strong>适用场景：</strong>你有大量文本，想知道它们涵盖了哪些主题——不用自己全部读完。非常适合探索性内容分析、议程设置研究，以及任何事先不知道类别的项目。</div>
          </div>
        </div>

        <!-- STM -->
        <div class="method-section">
          <h3 data-lang="en">Structural Topic Model (STM)</h3>
          <h3 data-lang="zh">结构主题模型（STM）</h3>
          <div data-lang="en">
            <p class="method-desc">Regular LDA discovers topics but can't tell you <em>why</em> topics vary across documents. <strong>STM</strong> (Roberts et al., 2014) is LDA's smarter cousin: it lets you plug in metadata about each document — who wrote it, when, which platform — and the model tells you how topic prevalence and topic content (the specific words used) differ across those covariates.</p>
            <div class="method-example">Example: Feed STM a collection of Congressional speeches with party labels. STM can tell you not just what topics are discussed, but that Democrats discuss healthcare 3× more than Republicans, AND when both parties discuss "economy" they use systematically different vocabulary — even within the same topic.</div>
            <p class="method-desc">Two types of covariate effects: <strong>prevalence</strong> (how much does party predict the proportion of each topic?) and <strong>content</strong> (do parties use the same topic differently?). This makes STM the closest bridge between unsupervised topic discovery and theory-driven hypothesis testing.</p>
            <div class="method-when"><strong>When to use:</strong> When you have metadata (party, time, source, author gender) and want to know how topics or language vary across groups or over time. The go-to tool for social scientists doing text analysis — it connects the data-driven approach of LDA with meaningful covariates.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">普通 LDA 能发现主题，但没法告诉你主题<em>为什么</em>在不同文档间变化。<strong>STM</strong>（Roberts et al., 2014）是 LDA 的"升级版"：它允许你加入每篇文档的元数据——谁写的、什么时候写的、发布在哪个平台——然后模型告诉你主题出现频率和主题内容（使用的具体词汇）如何随这些协变量变化。</p>
            <div class="method-example">例子：把一批国会演讲和政党标签一起输入 STM。STM 不仅能发现讨论了哪些话题，还能告诉你民主党讨论医疗的频率是共和党的 3 倍，而且两党讨论同一个"经济"主题时使用的词汇系统性地不同。</div>
            <p class="method-desc">两种协变量效应：<strong>出现频率</strong>（党派能在多大程度上预测每个主题的比例？）和<strong>内容</strong>（两党使用同一主题的方式不同吗？）。这让 STM 成为无监督主题发现和理论驱动假设检验之间最接近的桥梁。</p>
            <div class="method-when"><strong>适用场景：</strong>当你有元数据（党派、时间、来源、作者性别）并想知道主题或语言如何在群体间或随时间变化时。社会科学家进行文本分析的首选工具——它将 LDA 的数据驱动方法与有意义的协变量连接起来。</div>
          </div>
        </div>

        <!-- Text Scaling -->
        <div class="method-section">
          <h3 data-lang="en">Text Scaling: Wordscores &amp; Wordfish</h3>
          <h3 data-lang="zh">文本量表化：Wordscores 与 Wordfish</h3>
          <div data-lang="en">
            <p class="method-desc">Sometimes you don't want topics — you want to know <em>where</em> someone stands on a dimension. Text scaling places documents (or their authors) on a spectrum based purely on word choices. The classic application: estimating party positions on a left–right ideological scale from political texts.</p>
            <div class="method-analogy">Analogy: If someone keeps saying "freedom," "market," and "deregulation," they're probably on the right. If they say "equality," "welfare," and "public investment," they're probably on the left. Text scaling automates this intuition mathematically — without needing you to decide which words signal which position.</div>
            <p class="method-desc"><strong>Wordscores</strong> (Laver et al., 2003) needs reference texts with known positions (e.g., a clearly left-wing and a clearly right-wing manifesto). It maps each reference word to a score, then scores new texts by the average score of the words they share with references. Intuitive but sensitive to reference text choice.</p>
            <p class="method-desc"><strong>Wordfish</strong> (Slapin &amp; Proksch, 2008) requires no reference texts. It discovers the latent ideological dimension purely from how word frequencies vary across documents — assuming that a single dimension explains most of the cross-document variation in word use. More principled, but assumes unidimensionality.</p>
            <div class="method-when"><strong>When to use:</strong> Political science applications — estimating party positions from manifestos, legislative speeches, or policy documents. Best when the dimension of interest can be assumed to be approximately unidimensional and captured by word frequency patterns.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">有时候你关心的不是主题，而是想知道某人在某个维度上<em>站在哪里</em>。文本量表化根据用词选择把文档（或作者）放在一条光谱上。经典应用：从政治文本中估计政党在左右意识形态轴上的位置。</p>
            <div class="method-analogy">类比：如果一个人总说"自由""市场""放松管制"，他大概偏右。如果总说"平等""福利""公共投资"，大概偏左。文本量表化把这种直觉数学化——无需你事先决定哪些词代表哪个立场。</div>
            <p class="method-desc"><strong>Wordscores</strong>（Laver et al., 2003）需要已知立场的参考文本（如一篇明确左翼和一篇明确右翼的宣言）。它把每个参考词映射为一个分数，然后根据新文本与参考文本共享词汇的平均分数来打分。直观但对参考文本的选择很敏感。</p>
            <p class="method-desc"><strong>Wordfish</strong>（Slapin &amp; Proksch, 2008）完全不需要参考文本。它纯粹从词频在文档间的差异中发现潜在意识形态维度——假设单一维度能解释文档间词汇使用差异的大部分。更有原则性，但假设单维性。</p>
            <div class="method-when"><strong>适用场景：</strong>政治学应用——从宣言、立法演讲或政策文件中估计政党位置。当感兴趣的维度可以假设近似单维，且能被词频模式捕获时效果最好。</div>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ===== MODULE 3: SUPERVISED CLASSIFICATION ===== -->
      <div class="section" id="ta-module3">
        <h2 data-lang="en">Module 3: Supervised Classification</h2>
        <h2 data-lang="zh">模块 3：有监督分类</h2>

        <div class="challenge-overview">
          <div data-lang="en"><p>Supervised methods need a "teacher" — a set of documents that humans have already labeled (e.g., "positive" / "negative," or "about healthcare" / "about economy"). The model learns the mapping from text features to labels, then predicts labels for new, unseen documents. <strong>The fundamental trade-off:</strong> more complex models need more labeled data, take longer to train, and are harder to interpret — but can capture subtler patterns.</p></div>
          <div data-lang="zh"><p>有监督方法需要一个"老师"——一批人类已经标好标签的文档（如"正面"/"负面"，或"关于医疗"/"关于经济"）。模型学习从文本特征到标签的映射，然后预测新文档的标签。<strong>基本权衡：</strong>更复杂的模型需要更多标注数据、训练时间更长、更难解释——但能捕捉更微妙的模式。</p></div>
        </div>

        <!-- Random Forest -->
        <div class="method-section">
          <h3 data-lang="en">Random Forest</h3>
          <h3 data-lang="zh">随机森林</h3>
          <div data-lang="en">
            <p class="method-desc">Imagine asking 100 people to classify a document, but each person only sees a random portion of the words. Each person makes an imperfect judgment, but when you take a majority vote, the crowd is surprisingly accurate. That's Random Forest: it builds hundreds of decision trees, each trained on a random sample of documents and looking at a random subset of features, then aggregates their predictions.</p>
            <div class="method-analogy">Analogy: One quiz based on a single question is unreliable. But average the scores of 100 quizzes, each with different random questions, and you get a very reliable assessment — errors in individual trees cancel each other out.</div>
            <p class="method-desc">A key bonus: Random Forest reports <strong>feature importance</strong> — which words contributed most to the predictions. This makes it partially interpretable: you can inspect whether the model is using theoretically meaningful signals or spurious correlations in your training set.</p>
            <div class="method-when"><strong>When to use:</strong> An excellent, robust baseline for any text classification task. Works well with TF-IDF features and limited labeled data (~500+ examples). Choose Random Forest before trying neural networks — if a simpler model works, use it.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">想象让 100 个人给一篇文档分类，但每个人只看到随机一部分词。每个人的判断都不完美，但投票表决后，群体的准确率出奇地高。这就是随机森林：它构建几百棵决策树，每棵树在随机采样的文档和随机特征子集上训练，然后综合它们的预测。</p>
            <div class="method-analogy">类比：一道题的随堂测验不可靠。但把 100 次测验（每次随机出不同题）的成绩平均，你就能得到非常可靠的评估——单棵树的错误相互抵消。</div>
            <p class="method-desc">关键优点：随机森林报告<strong>特征重要性</strong>——哪些词对预测贡献最大。这让它部分可解释：你能检查模型是否在使用理论上有意义的信号，还是只是抓住了训练集中的虚假相关。</p>
            <div class="method-when"><strong>适用场景：</strong>任何文本分类任务的出色稳健基线。配合 TF-IDF 特征和有限标注数据效果很好（约 500+ 样本）。尝试神经网络之前先用随机森林——如果简单模型够用，就用它。</div>
          </div>
        </div>

        <!-- Neural Networks -->
        <div class="method-section">
          <h3 data-lang="en">Neural Networks for Text</h3>
          <h3 data-lang="zh">用于文本的神经网络</h3>
          <div data-lang="en">
            <p class="method-desc">Neural networks don't need you to specify features manually — they learn them from the data. Three architectures matter for text, each suited to different patterns:</p>
            <p class="method-desc"><strong>CNNs (Convolutional Neural Networks)</strong> — Like a sliding magnifying glass scanning text for useful local patterns. Good at spotting short, discriminative phrases like "not good" or "highly recommended." Fast and effective for sentence-level classification.</p>
            <p class="method-desc"><strong>RNNs / LSTMs (Recurrent Neural Networks / Long Short-Term Memory)</strong> — Read text word by word, maintaining a "memory" of what came before. Like a person reading a book from start to finish, keeping track of the narrative. LSTMs are the improved version that can remember dependencies from earlier in the text without the vanishing gradient problem.</p>
            <p class="method-desc"><strong>Transformers</strong> — The architecture behind modern LLMs. Instead of reading left-to-right, transformers use <em>attention</em>: every word attends to every other word simultaneously, weighting how relevant each is for understanding the current position. This allows capturing long-range dependencies that RNNs struggle with. (See the <a href="llm.html" style="color:var(--red)">LLM &amp; NLP page</a> for details.)</p>
            <div class="method-when"><strong>When to use:</strong> When you have large labeled datasets (thousands to millions of examples) and need higher accuracy than Random Forest provides. CNN/LSTM: good with ~5K+ examples; Transformers: typically need fine-tuning pre-trained models to be practical with less data.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">神经网络不需要你手动指定特征——它自己从数据中学习。三种架构对文本最重要，各自适合不同的模式：</p>
            <p class="method-desc"><strong>CNN（卷积神经网络）</strong>——像一个滑动的放大镜，扫描文本寻找有用的局部模式。擅长发现判别性短语，如"not good"或"强烈推荐"。速度快，适合句子级分类。</p>
            <p class="method-desc"><strong>RNN / LSTM（循环神经网络/长短期记忆网络）</strong>——逐词阅读文本，保持对之前内容的"记忆"。就像一个人从头到尾读一本书，跟踪叙事进展。LSTM 是改进版，能记住文本中更早出现的依赖关系，避免了梯度消失问题。</p>
            <p class="method-desc"><strong>Transformer</strong>——现代 LLM 背后的架构。不是从左到右阅读，而是使用<em>注意力机制</em>：每个词同时关注所有其他词，对每个词与当前位置的相关性进行加权。这使其能捕捉 RNN 难以处理的长距离依赖。（详见 <a href="llm.html" style="color:var(--red)">LLM &amp; NLP 页面</a>。）</p>
            <div class="method-when"><strong>适用场景：</strong>当你有大量标注数据集（数千到数百万样本）且需要比随机森林更高的准确率时。CNN/LSTM：适合约 5K+ 样本；Transformer：通常需要微调预训练模型才能在较少数据下实用。</div>
          </div>
        </div>

        <!-- LLMs -->
        <div class="method-section">
          <h3 data-lang="en">Large Language Models (BERT, GPT)</h3>
          <h3 data-lang="zh">大语言模型（BERT、GPT）</h3>
          <div data-lang="en">
            <p class="method-desc">LLMs have read billions of web pages during pre-training, so they already "understand" language before you give them any task-specific data. Two key paradigms for text analysis:</p>
            <p class="method-desc"><strong>Fine-tuning (BERT)</strong> — BERT reads text in both directions (attending to context on both sides of every token). Give it a few hundred labeled examples and add a classification head: it quickly learns your specific task. Strong empirical performance with relatively little labeled data, but you need GPU resources and the model is not interpretable.</p>
            <p class="method-desc"><strong>Prompting (GPT / ChatGPT)</strong> — You describe the task in natural language and the model responds. Zero-shot (no examples), few-shot (a handful of examples), or chain-of-thought (step-by-step reasoning instructions). No training required, extremely flexible — but non-deterministic, expensive at scale, and harder to systematically validate.</p>
            <div class="method-example">For text-as-data research: Use GPT to pre-label thousands of documents cheaply (zero/few-shot), use human experts to verify a sample, then fine-tune BERT on the verified subset. This "pipeline" approach combines LLM flexibility with BERT's scalability and predictability.</div>
            <div class="method-when"><strong>When to use:</strong> When you need state-of-the-art accuracy or have complex, nuanced classification tasks (beyond simple sentiment). GPT zero-shot: great first pass to see if the task is feasible. Fine-tuned BERT: when you need reproducibility, high accuracy, and can invest in 100–1000 labeled examples.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">LLM 在预训练阶段已经读过了数十亿网页，所以在你给它任何特定任务数据之前，它就已经"理解"语言了。文本分析中的两种关键范式：</p>
            <p class="method-desc"><strong>微调（BERT）</strong>——BERT 双向阅读文本（在每个词的两侧都有上下文关注）。给它几百个标注样本并加一个分类头：它能快速学会你的特定任务。用相对少的标注数据就能实现强大的实证表现，但需要 GPU 资源且模型不可解释。</p>
            <p class="method-desc"><strong>提示词（GPT / ChatGPT）</strong>——用自然语言描述任务，模型给出回应。零样本（无例子）、少样本（少量例子）或思维链（逐步推理指令）。不需要训练，极为灵活——但非确定性、大规模成本高，且系统性验证更难。</p>
            <div class="method-example">文本即数据研究中的实践方案：用 GPT 低成本地对数千文档进行零/少样本预标注，用人类专家验证抽样，然后在验证后的子集上微调 BERT。这种"流水线"方法结合了 GPT 的灵活性与 BERT 的可扩展性和可预测性。</div>
            <div class="method-when"><strong>适用场景：</strong>当你需要最先进的准确率，或面对复杂、细微的分类任务（超出简单情感分析）时。GPT 零样本：先快速验证任务是否可行。微调 BERT：当你需要可复现性、高准确率，且能投入 100–1000 个标注样本时。</div>
          </div>
        </div>

        <!-- Evaluation -->
        <div class="challenge-overview" style="border-left-color:var(--red);background:rgba(181,55,42,.03);">
          <div data-lang="en">
            <p><strong>How Do We Know If It's Working? — Evaluation Metrics</strong></p>
            <p><strong>Accuracy</strong> = how many did you get right overall? Simple but misleading if your data is imbalanced (99% accuracy is easy if 99% of documents are in one class). <strong>Precision</strong> = "of the documents you labeled positive, how many actually were?" (avoiding false alarms). <strong>Recall</strong> = "of all the actual positives, how many did you catch?" (avoiding misses). <strong>F1</strong> = harmonic mean of precision and recall — the balance between the two. Always report multiple metrics, use cross-validation, and compare against a sensible baseline (e.g., majority-class predictor).</p>
          </div>
          <div data-lang="zh">
            <p><strong>怎么知道模型好不好？——评估指标</strong></p>
            <p><strong>准确率</strong> = 总共答对了多少？简单但在数据不平衡时会误导（如果 99% 的文档属于同一类，99% 的准确率很容易达到）。<strong>精确率</strong> ="你标为正面的文档中，有多少真的是正面？"（避免误报）。<strong>召回率</strong> ="所有真正的正面文档中，你抓到了多少？"（避免遗漏）。<strong>F1</strong> = 精确率和召回率的调和平均——两者之间的平衡。务必报告多个指标，使用交叉验证，并与合理的基线对比（如多数类预测器）。</p>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ===== MODULE 4: RESEARCH DESIGN & VALIDITY ===== -->
      <div class="section" id="ta-module4">
        <h2 data-lang="en">Module 4: Research Design &amp; Validity</h2>
        <h2 data-lang="zh">模块 4：研究设计与效度</h2>

        <div class="challenge-overview">
          <div data-lang="en"><p>Methods without careful research design produce impressive-looking but unreliable results. This module addresses the "measurement" side of text analysis: <strong>how do we know our labels are right?</strong> (annotation), <strong>how do we collect them efficiently?</strong> (active learning), <strong>what are the ethical responsibilities?</strong> (ethics), and <strong>how do we choose among all these methods?</strong> (decision guide).</p></div>
          <div data-lang="zh"><p>没有仔细研究设计的方法会产生看起来漂亮但不可靠的结果。本模块关注文本分析的"测量"层面：<strong>如何知道标签是否正确？</strong>（标注）<strong>如何高效收集标签？</strong>（主动学习）<strong>有哪些伦理责任？</strong>（伦理）以及<strong>如何在所有方法中做选择？</strong>（决策指南）。</p></div>
        </div>

        <!-- Annotation -->
        <div class="method-section">
          <h3 data-lang="en">Annotation &amp; Inter-rater Agreement</h3>
          <h3 data-lang="zh">标注与评分者间信度</h3>
          <div data-lang="en">
            <p class="method-desc">Supervised learning is only as good as its labels — "garbage in, garbage out." Good annotation requires a clear codebook (what does each category mean, with edge cases), multiple annotators per item (to catch ambiguity), and rigorous agreement measurement before scaling up. Annotators should be calibrated together before independent annotation.</p>
          </div>
          <div data-lang="zh">
            <p class="method-desc">有监督学习的效果取决于标签质量——"垃圾进，垃圾出"。好的标注需要清晰的编码手册（每个类别的含义及边界情况）、每条数据多名标注者（捕捉歧义）、在大规模标注前进行严格的一致性测量。标注者应在独立标注前一起进行校准。</p>
          </div>

          <div class="compare-grid">
            <div class="compare-col">
              <div class="compare-label" data-lang="en">Cohen's Kappa (κ)</div>
              <div class="compare-label" data-lang="zh">Cohen's Kappa (κ)</div>
              <div data-lang="en">
                <p>Measures agreement between <em>two</em> annotators, correcting for chance. Two people flipping coins would agree 50% of the time — Kappa subtracts this chance agreement.</p>
                <p><strong>κ > .80</strong> = strong agreement (publish-ready)</p>
                <p><strong>κ .61–.80</strong> = moderate agreement (acceptable with caveats)</p>
                <p><strong>κ &lt; .40</strong> = poor (revise codebook before proceeding)</p>
              </div>
              <div data-lang="zh">
                <p>测量<em>两名</em>标注者之间的一致性，校正了随机因素。两人随机猜测有 50% 一致——Kappa 减去了这种随机一致性。</p>
                <p><strong>κ > .80</strong> = 强一致性（可发表）</p>
                <p><strong>κ .61–.80</strong> = 中等一致性（附说明可接受）</p>
                <p><strong>κ &lt; .40</strong> = 差（先修改编码手册）</p>
              </div>
            </div>
            <div class="compare-col alt">
              <div class="compare-label" data-lang="en">Krippendorff's Alpha (α)</div>
              <div class="compare-label" data-lang="zh">Krippendorff's Alpha (α)</div>
              <div data-lang="en">
                <p>More flexible than Kappa: handles <em>multiple</em> annotators, missing data, and ordinal/interval labels (not just categorical). The recommended choice for most research projects.</p>
                <p><strong>α > .80</strong> = reliable (solid foundation for analysis)</p>
                <p><strong>α .67–.80</strong> = tentative conclusions only</p>
                <p><strong>α &lt; .67</strong> = do not proceed; recode</p>
              </div>
              <div data-lang="zh">
                <p>比 Kappa 更灵活：处理<em>多名</em>标注者、缺失数据和有序/连续标签（不限于类别变量）。大多数研究项目的推荐选择。</p>
                <p><strong>α > .80</strong> = 可靠（分析的坚实基础）</p>
                <p><strong>α .67–.80</strong> = 只能得出初步结论</p>
                <p><strong>α &lt; .67</strong> = 不要继续；重新编码</p>
              </div>
            </div>
            <div class="compare-footer" data-lang="en">LLMs as annotators: GPT-4 can match or exceed crowd-worker quality on many tasks and labels thousands of documents overnight. But always validate against expert human labels, carefully report the exact prompt and model version, and check for systematic biases — LLMs are not neutral.</div>
            <div class="compare-footer" data-lang="zh">LLM 作为标注者：GPT-4 在许多任务上能达到甚至超过众包工人的质量，一晚上可标注数千文档。但务必对照专家人工标签验证，仔细报告确切提示词和模型版本，并检查系统性偏见——LLM 并不中立。</div>
          </div>
        </div>

        <!-- Active Learning -->
        <div class="method-section">
          <h3 data-lang="en">Active Learning</h3>
          <h3 data-lang="zh">主动学习</h3>
          <div data-lang="en">
            <p class="method-desc">Labeling data is expensive and slow. <strong>Active learning</strong> is a clever shortcut: instead of randomly picking documents to label, let the model tell you which documents it's <em>most uncertain</em> about — then label those first. Every label you add teaches the model the most, dramatically reducing the total labels needed to reach target accuracy.</p>
            <div class="method-analogy">Analogy: Studying for an exam by focusing on the questions you got wrong — not reviewing what you already know. Your limited study time has maximum impact.</div>
            <p class="method-desc">Common uncertainty sampling strategies: <strong>least confidence</strong> (label documents where the model's top prediction has the lowest probability), <strong>margin sampling</strong> (smallest difference between top-two class probabilities), and <strong>entropy sampling</strong> (highest entropy across all class probabilities). In practice, combining active learning with an LLM to pre-label uncertain cases can stretch your labeling budget even further.</p>
            <div class="method-when"><strong>When to use:</strong> Any supervised classification project where labeling is expensive. Best when you start with a small seed set (~100 labeled examples), train an initial model, then iteratively select uncertain examples to label next. Most effective when classes are imbalanced — active learning can find rare positive examples faster than random sampling.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">标注数据既贵又慢。<strong>主动学习</strong>是一个聪明的捷径：不随机选文档来标注，而是让模型告诉你它<em>最不确定</em>的是哪些文档——先标注那些。每一个标签都能让模型学到最多，大幅减少达到目标准确率所需的总标注量。</p>
            <div class="method-analogy">类比：备考时专注做错题——而不是复习已经会的内容。有限的学习时间产生最大的效果。</div>
            <p class="method-desc">常见的不确定性采样策略：<strong>最低置信度</strong>（标注模型最高预测概率最低的文档）、<strong>边际采样</strong>（前两个类别概率差最小）、<strong>熵采样</strong>（所有类别概率的熵最高）。实践中，将主动学习与 LLM 结合对不确定案例进行预标注，可以进一步延伸你的标注预算。</p>
            <div class="method-when"><strong>适用场景：</strong>任何标注代价高昂的有监督分类项目。最佳做法：从小型种子集开始（约 100 个标注样本），训练初始模型，然后迭代选择最不确定的样本进行标注。在类别不平衡时最有效——主动学习比随机采样更快地找到稀有正例。</div>
          </div>
        </div>

        <!-- Ethics -->
        <div class="method-section">
          <h3 data-lang="en">Ethics in Text Analysis</h3>
          <h3 data-lang="zh">文本分析中的伦理</h3>
          <div data-lang="en">
            <p class="method-desc">Just because you <em>can</em> analyze text doesn't mean you always <em>should</em> — or that it's safe to do so carelessly. Text data raises three recurring ethical concerns that researchers must address from the start, not as an afterthought.</p>
            <div class="method-example"><strong>Privacy:</strong> Text often reveals who people are — names, locations, writing style. Just because a tweet is public doesn't mean the author consented to be studied. Even "anonymized" text can be re-identified through writing style fingerprinting. When in doubt, aggregate and never identify individuals.</div>
            <div class="method-example"><strong>Bias:</strong> Models learn from human-generated text, which reflects historical biases — and then amplify them. Word embeddings encode stereotypes: "doctor" closer to "man," "nurse" closer to "woman." Sentiment tools often rate African American Vernacular English (AAVE) as more negative. Always audit your model's predictions for disparate error rates across demographic groups.</div>
            <div class="method-example"><strong>Reproducibility:</strong> Share your code and (when possible) data. Record every choice: which model version, which random seed, which preprocessing pipeline. LLM outputs change between API versions — always report the exact prompt and model version (e.g., "GPT-4-turbo, January 2024"). Irreproducible results cannot be built upon.</div>
          </div>
          <div data-lang="zh">
            <p class="method-desc">你<em>能</em>分析文本，不代表你总<em>应该</em>这么做——也不代表可以粗心大意。文本数据研究带来三个反复出现的伦理问题，研究者必须从一开始就考虑，而不是事后补救。</p>
            <div class="method-example"><strong>隐私：</strong>文本常常暴露身份——姓名、地点、写作风格。一条推文是公开的，不代表发布者同意被纳入你的研究。即使"匿名化"了也可能通过写作风格指纹被重新识别。有疑问时，只分析汇总数据，永远不要识别个人。</div>
            <div class="method-example"><strong>偏见：</strong>模型从人类产生的文本中学习，这些文本反映了历史偏见——模型还会放大这些偏见。词嵌入编码了刻板印象："医生"离"男性"更近，"护士"离"女性"更近。情感分析工具常把非裔美国人俚语（AAVE）评为更负面。务必审计你的模型预测在不同人口群体中的错误率差异。</div>
            <div class="method-example"><strong>可重复性：</strong>共享代码和数据（可能时）。记录每个选择：哪个模型版本、哪个随机种子、哪种预处理流程。LLM 输出随 API 版本不同而变化——务必报告确切的提示词和模型版本（如"GPT-4-turbo, 2024年1月"）。不可复现的结果无法被后人继承。</div>
          </div>
        </div>

        <!-- Choosing a Method -->
        <div class="method-section">
          <h3 data-lang="en">Choosing a Method</h3>
          <h3 data-lang="zh">方法选择指南</h3>
          <div data-lang="en">
            <p class="method-desc">With so many methods, how do you pick? The biggest decision is often the simplest: <strong>do you have labeled data or not?</strong> Start simple — dictionaries and BoW + Random Forest solve more problems than people expect. Only escalate to complex methods when simpler ones fail.</p>
          </div>
          <div data-lang="zh">
            <p class="method-desc">这么多方法，怎么选？最大的决定往往也是最简单的：<strong>你有标注数据吗？</strong>从简单开始——词典和词袋 + 随机森林解决的问题比大多数人预想的多。只有在简单方法失败时才升级到复杂方法。</p>
          </div>

          <div class="compare-grid">
            <div class="compare-col">
              <div class="compare-label" data-lang="en">No Labeled Data</div>
              <div class="compare-label" data-lang="zh">无标注数据</div>
              <div data-lang="en">
                <p><strong>Dictionary methods</strong> — "I know what categories I want, just count the words" (simplest, highest interpretability)</p>
                <p><strong>Topic models (LDA/STM)</strong> — "What topics are hiding in this pile of text?" (exploratory)</p>
                <p><strong>Wordfish</strong> — "Where does each author stand on a left–right scale?" (unsupervised scaling)</p>
                <p><strong>LLM zero-shot</strong> — "Just ask ChatGPT to classify it" (quick first pass; validate before trusting)</p>
              </div>
              <div data-lang="zh">
                <p><strong>词典方法</strong>——"我知道想要什么类别，数词就行"（最简单、可解释性最高）</p>
                <p><strong>主题模型 (LDA/STM)</strong>——"这堆文本里藏着什么话题？"（探索性）</p>
                <p><strong>Wordfish</strong>——"每个作者在左右光谱上站在哪？"（无监督量表化）</p>
                <p><strong>LLM 零样本</strong>——"直接让 ChatGPT 分类"（快速初步验证；信任之前要核实）</p>
              </div>
            </div>
            <div class="compare-col alt">
              <div class="compare-label" data-lang="en">With Labeled Data</div>
              <div class="compare-label" data-lang="zh">有标注数据</div>
              <div data-lang="en">
                <p><strong>Wordscores</strong> — "I have reference texts with known positions" (supervised scaling)</p>
                <p><strong>Random Forest / SVM</strong> — "Give me a solid, interpretable baseline" (classic ML; great default)</p>
                <p><strong>Fine-tuned BERT</strong> — "I want the best accuracy possible and have GPU resources" (state-of-the-art)</p>
                <p><strong>LLM few-shot</strong> — "I only have a handful of labeled examples" (flexible, expensive at scale)</p>
              </div>
              <div data-lang="zh">
                <p><strong>Wordscores</strong>——"我有已知立场的参考文本"（有监督量表化）</p>
                <p><strong>随机森林 / SVM</strong>——"给我一个靠谱、可解释的基线"（经典 ML；好的默认选择）</p>
                <p><strong>微调 BERT</strong>——"我要最高的准确率，有 GPU 资源"（最先进）</p>
                <p><strong>LLM 少样本</strong>——"我只有几个标注样本"（灵活，大规模时成本高）</p>
              </div>
            </div>
            <div class="compare-footer" data-lang="en">Golden rule: always start simple, establish a baseline, report all metrics with confidence intervals, and compare against the simplest possible alternative. You'd be surprised how often a bag-of-words + Random Forest beats a fine-tuned BERT on small social science datasets.</div>
            <div class="compare-footer" data-lang="zh">黄金法则：永远从简单开始，建立基线，报告所有指标及置信区间，并与最简单的替代方案对比。你会惊讶地发现，在小型社会科学数据集上，词袋 + 随机森林有时胜过微调 BERT。</div>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ===== RESOURCES ===== -->
      <div class="section resources-section" id="ta-resources">
        <h2 data-lang="en">Resources</h2>
        <h2 data-lang="zh">资源</h2>

        <h3 data-lang="en">Key References</h3>
        <h3 data-lang="zh">关键参考</h3>
        <ul class="resource-list">
          <li>Grimmer, J., Roberts, M. E., &amp; Stewart, B. M. (2022). <em>Text as Data: A New Framework for Machine Learning and the Social Sciences.</em> Princeton University Press.</li>
          <li>Denny, M. J., &amp; Spirling, A. (2018). Text preprocessing for unsupervised learning: Why it matters, when it misleads, and what to do about it. <em>Political Analysis, 26</em>(2), 168–189.</li>
          <li>Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003). Latent Dirichlet allocation. <em>Journal of Machine Learning Research, 3</em>, 993–1022.</li>
          <li>Roberts, M. E., Stewart, B. M., Tingley, D., et al. (2014). Structural topic models for open-ended survey responses. <em>American Journal of Political Science, 58</em>(4), 1064–1082.</li>
          <li>Slapin, J. B., &amp; Proksch, S.-O. (2008). A scaling model for estimating time-series party positions from texts. <em>American Journal of Political Science, 52</em>(3), 705–722.</li>
          <li>Laver, M., Benoit, K., &amp; Garry, J. (2003). Extracting policy positions from political texts using words as data. <em>American Political Science Review, 97</em>(2), 311–331.</li>
          <li>Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). Efficient estimation of word representations in vector space. <em>arXiv:1301.3781</em>.</li>
          <li>Devlin, J., Chang, M.-W., Lee, K., &amp; Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. <em>NAACL-HLT</em>.</li>
        </ul>

        <h3 data-lang="en">Deep Dives &amp; Labs</h3>
        <h3 data-lang="zh">深入指南与实验室</h3>
        <ul class="resource-list" data-lang="en">
          <li><a class="sim-link" href="guides/ta-preprocessing.html">▶ Text Preprocessing Lab</a> — Step through tokenization, stopword removal, and stemming; compare how three preprocessing pipelines produce different top words from the same text.</li>
          <li><a class="sim-link" href="guides/ta-tfidf.html">▶ TF-IDF Explorer</a> — Compute TF-IDF scores across three editable documents and visualize the document-term matrix as an interactive heatmap.</li>
        </ul>
        <ul class="resource-list" data-lang="zh">
          <li><a class="sim-link" href="guides/ta-preprocessing.html">▶ 文本预处理实验室</a> — 分步演示分词、停用词去除与词干还原；对比三套预处理流程如何从同一文本产生不同高频词。</li>
          <li><a class="sim-link" href="guides/ta-tfidf.html">▶ TF-IDF 探索器</a> — 在三份可编辑文档上交互计算 TF-IDF 分数，以热力图形式可视化文档-词项矩阵。</li>
        </ul>

        <h3 data-lang="en">Software</h3>
        <h3 data-lang="zh">软件工具</h3>
          <div class="sw-row">
            <div class="sw-pill gold">
              <h4>Python — NLTK / spaCy</h4>
              <div data-lang="en"><p>Core NLP libraries. NLTK for learning, spaCy for production. Tokenization, POS tagging, named entity recognition, lemmatization.</p></div>
              <div data-lang="zh"><p>核心 NLP 库。NLTK 适合学习，spaCy 适合生产。分词、词性标注、命名实体识别、词形还原。</p></div>
            </div>
            <div class="sw-pill">
              <h4>Python — scikit-learn</h4>
              <div data-lang="en"><p>TF-IDF vectorizer, Random Forest, SVM, evaluation metrics, cross-validation. The machine learning workhorse for text classification.</p></div>
              <div data-lang="zh"><p>TF-IDF 向量化器、随机森林、支持向量机、评估指标、交叉验证。文本分类的机器学习主力工具。</p></div>
            </div>
            <div class="sw-pill">
              <h4>Python — Gensim</h4>
              <div data-lang="en"><p>Topic modeling (LDA), Word2Vec, Doc2Vec. Efficient for large corpora — can handle millions of documents.</p></div>
              <div data-lang="zh"><p>主题模型（LDA）、Word2Vec、Doc2Vec。大型语料库高效处理——可处理数百万文档。</p></div>
            </div>
          </div>
          <div class="sw-row">
            <div class="sw-pill">
              <h4>R — quanteda</h4>
              <div data-lang="en"><p>Text analysis in R. DTM construction, dictionary methods, Wordfish, Wordscores. Social science standard.</p></div>
              <div data-lang="zh"><p>R 中的文本分析。文档-词项矩阵构建、词典方法、Wordfish、Wordscores。社会科学标准工具。</p></div>
            </div>
            <div class="sw-pill">
              <h4>R — stm</h4>
              <div data-lang="en"><p>Structural Topic Models with covariate effects on prevalence and content. Roberts et al.'s official implementation.</p></div>
              <div data-lang="zh"><p>带协变量效应的结构主题模型（出现频率与内容）。Roberts et al. 的官方实现。</p></div>
            </div>
            <div class="sw-pill">
              <h4>HuggingFace Transformers</h4>
              <div data-lang="en"><p>Pre-trained BERT, GPT, and other LLMs. Fine-tuning, inference, and model hub. Python ecosystem; GPU recommended.</p></div>
              <div data-lang="zh"><p>预训练的 BERT、GPT 及其他 LLM。微调、推理和模型库。Python 生态；推荐使用 GPU。</p></div>
            </div>
          </div>
      </div>

      <!-- PAGE NAV -->
      <div class="page-nav">
        <a href="llm.html">
          <div class="nav-label">&larr; Previous</div>
          <div class="nav-title">LLM &amp; NLP</div>
        </a>
        <a class="next" href="theoretical-modeling.html">
          <div class="nav-label">Next &rarr;</div>
          <div class="nav-title">Theoretical Modeling</div>
        </a>
      </div>

    </div>
  </div>
</div>

<script>
function setLang(lang) {
  document.body.className = lang;
  document.getElementById('btn-en').style.fontWeight = (lang === 'en') ? '600' : '400';
  document.getElementById('btn-zh').style.fontWeight = (lang === 'zh') ? '600' : '400';
  document.getElementById('btn-en').style.color = (lang === 'en') ? 'var(--red)' : 'var(--ink-faded)';
  document.getElementById('btn-zh').style.color = (lang === 'zh') ? 'var(--red)' : 'var(--ink-faded)';
  localStorage.setItem('preferred-lang', lang);
}
window.addEventListener('load', function() {
  const saved = localStorage.getItem('preferred-lang') || 'zh';
  setLang(saved);
});

// ── Right-side TOC (auto-detects h2 + h3 headings) ───────
(function buildPageTOC() {
  const content = document.querySelector('.content');
  const mainEl  = document.querySelector('.main');
  if (!content || !mainEl) return;

  // Walk EN headings; pair with their ZH sibling
  const items = [];
  let autoId = 0;
  content.querySelectorAll('h2[data-lang="en"], h3[data-lang="en"]').forEach(hEn => {
    const zhSib = hEn.nextElementSibling;
    const enText = hEn.textContent.trim();
    const zhText = (zhSib && zhSib.dataset && zhSib.dataset.lang === 'zh')
                   ? zhSib.textContent.trim() : enText;
    const isH3  = hEn.tagName === 'H3';

    // Anchor: for h2 use the .section parent; for h3 use .method-section parent
    const anchorEl = isH3
      ? (hEn.closest('.method-section') || hEn.parentElement)
      : (hEn.closest('.section')        || hEn.parentElement);

    if (!anchorEl.id) anchorEl.id = 'toc-auto-' + (autoId++);
    items.push({ id: anchorEl.id, en: enText, zh: zhText, isH3 });
  });

  // Build nav element
  const nav = document.createElement('nav');
  nav.className = 'page-toc';
  const header = document.createElement('div');
  header.className = 'toc-header';
  header.textContent = 'Contents';
  nav.appendChild(header);

  const links = {};
  items.forEach(({ id, en, zh, isH3 }) => {
    const a = document.createElement('a');
    a.href = '#' + id;
    a.dataset.en = en; a.dataset.zh = zh;
    a.textContent = en;
    if (isH3) a.classList.add('toc-sub');
    links[id] = a;
    nav.appendChild(a);
  });
  mainEl.appendChild(nav);

  // Scroll-spy
  let current = null;
  const obs = new IntersectionObserver(entries => {
    entries.forEach(e => {
      if (e.isIntersecting) {
        if (current && links[current]) links[current].classList.remove('active');
        current = e.target.id;
        if (links[current]) links[current].classList.add('active');
      }
    });
  }, { rootMargin: '-8% 0px -68% 0px' });
  items.forEach(({ id }) => { const el = document.getElementById(id); if (el) obs.observe(el); });

  // Language sync
  function tocSetLang(lang) {
    header.textContent = lang === 'zh' ? '目录' : 'Contents';
    items.forEach(({ id, en, zh }) => { if (links[id]) links[id].textContent = lang === 'zh' ? zh : en; });
  }
  const _orig = window.setLang;
  window.setLang = function(lang) { _orig(lang); tocSetLang(lang); };
  tocSetLang(localStorage.getItem('preferred-lang') || 'zh');
})();
</script>
</body>
</html>
