<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>LLM &amp; NLP — Research Methods Notebook</title>
<link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:ital,wght@0,300;0,400;0,500;0,600;1,300;1,400;1,500&family=EB+Garamond:ital,wght@0,400;0,500;1,400&family=Caveat:wght@400;500&family=IBM+Plex+Sans:wght@300;400;500&family=IBM+Plex+Mono:wght@400;500&family=Noto+Serif+SC:wght@300;400;500;600&family=Noto+Sans+SC:wght@300;400;500&display=swap" rel="stylesheet">
<link rel="stylesheet" href="style.css">
<style>
.info-box{border:1px solid var(--parchment);border-radius:4px;padding:16px 18px;margin:16px 0;background:var(--warm)}
.info-box .label{font-family:var(--sans);font-size:10px;font-weight:600;letter-spacing:.1em;text-transform:uppercase;color:var(--red);margin-bottom:8px}
.info-box p{font-size:14px;line-height:1.7;color:var(--ink-faded);margin-bottom:0}
.sw-row{display:grid;grid-template-columns:repeat(3,1fr);gap:12px;margin:12px 0}
.sw-pill{border:1px solid var(--parchment);border-radius:4px;padding:14px;background:var(--paper)}
.sw-pill.gold{background:var(--ink);color:rgba(248,244,236,.85);border-color:var(--ink)}
.sw-pill h4{font-family:var(--sans);font-size:13px;font-weight:600;margin-bottom:4px}
.sw-pill.gold h4{color:var(--gold)}
.sw-pill p{font-size:12.5px;line-height:1.5;color:var(--ink-faded);margin:0}
.sw-pill.gold p{color:rgba(248,244,236,.7)}
/* method cards */
.method-card{border:1px solid var(--parchment);border-radius:4px;padding:20px;margin:10px 0;background:var(--paper);transition:all .2s}
.method-card:hover{border-color:var(--tea);background:var(--warm)}
.method-card h4{font-family:var(--sans);font-size:13px;font-weight:600;color:var(--ink);margin-bottom:6px}
.method-card .mc-tag{font-family:var(--sans);font-size:9px;font-weight:600;letter-spacing:.08em;text-transform:uppercase;padding:2px 8px;border-radius:10px;color:var(--paper);display:inline-block;margin-bottom:8px}
.mc-tag.rep{background:var(--leather)}
.mc-tag.arch{background:var(--red)}
.mc-tag.train{background:var(--gold)}
.mc-tag.app{background:#5a7a6b}
.mc-tag.ethics{background:var(--ink-ghost)}
.method-card p{font-size:13.5px;line-height:1.65;color:var(--ink-faded);margin-bottom:6px}
.method-card .formula{font-family:var(--mono);font-size:12px;color:var(--ink-soft);background:var(--warm);padding:8px 12px;border-radius:3px;margin:6px 0;line-height:1.5;overflow-x:auto;white-space:nowrap;border:1px solid rgba(222,212,192,.5)}
.method-card .when{font-family:var(--sans);font-size:12px;color:var(--gold);margin-top:8px;padding:6px 10px;background:rgba(194,153,61,.06);border-radius:3px;line-height:1.4}
.method-card .when strong{color:var(--leather)}
.method-card .analogy{margin:8px 0;padding:10px 14px;border-radius:4px;background:rgba(194,153,61,.06);border:1px solid rgba(194,153,61,.15);font-size:13px;line-height:1.65;color:var(--ink-faded);font-style:italic}
.method-card .eg{margin:8px 0;padding:10px 14px;border-radius:4px;background:rgba(181,55,42,.04);border:1px solid rgba(181,55,42,.1);font-size:13px;line-height:1.65;color:var(--ink-faded)}
.method-card .eg::before{content:'';display:inline-block;width:6px;height:6px;background:var(--red);border-radius:50%;margin-right:8px;vertical-align:middle}
/* evolution timeline */
.evo{display:flex;align-items:stretch;gap:0;margin:20px 0;overflow-x:auto}
.evo-step{flex:1;text-align:center;padding:14px 8px;border:1px solid var(--parchment);background:var(--paper);min-width:100px;position:relative}
.evo-step:first-child{border-radius:4px 0 0 4px}
.evo-step:last-child{border-radius:0 4px 4px 0}
.evo-step:not(:last-child){border-right:none}
.evo-step.now{background:var(--ink);border-color:var(--ink);color:var(--paper)}
.evo-year{font-family:var(--sans);font-size:10px;font-weight:600;letter-spacing:.08em;color:var(--gold);margin-bottom:3px}
.evo-name{font-family:var(--sans);font-size:11px;font-weight:600;color:var(--ink);line-height:1.3}
.evo-step.now .evo-name{color:var(--paper)}
.evo-desc{font-size:10px;color:var(--ink-ghost);margin-top:3px;line-height:1.3}
.evo-step.now .evo-desc{color:rgba(248,244,236,.6)}
@media(max-width:860px){
  .sw-row{grid-template-columns:1fr}
  .evo{flex-wrap:wrap}
  .evo-step{min-width:auto;border-radius:4px!important;border:1px solid var(--parchment)!important;margin:3px}
}
</style>
</head>
<body class="zh">
<div class="layout">
  <aside class="sidebar" id="sidebar">
    <a class="sb-brand" href="index.html"><h2>Methods <span>Notebook</span></h2><div class="sb-sub">Jialing Wu</div></a>
    <div class="sb-cat">Person-Centered Quantitative Methods</div>
    <a class="sb-link" href="lpa.html"><span class="sb-num">01</span> Latent Profile Analysis</a>
    <div class="sb-cat">Computational Social Science</div>
    <div class="sb-subcat">Foundations</div>
    <a class="sb-link" href="machine-learning.html"><span class="sb-num">01</span> Machine Learning</a>
    <a class="sb-link active" href="llm.html"><span class="sb-num">02</span> LLM &amp; NLP</a>
    <a class="sb-link" href="text-analysis.html"><span class="sb-num">03</span> Text as Data</a>
    <a class="sb-link" href="theoretical-modeling.html"><span class="sb-num">04</span> Theoretical Modeling</a>
    <div class="sb-cat">Statistics</div>
    <div class="sb-subcat">Foundations</div>
    <a class="sb-link" href="empirical-modeling.html"><span class="sb-num">01</span> Empirical Modeling</a>
    <div class="sb-footer"><a href="https://jialing-wu.github.io">&larr; My Website</a></div>
  </aside>
  <div class="sidebar-overlay" id="overlay" onclick="document.getElementById('sidebar').classList.toggle('open');document.getElementById('overlay').classList.toggle('show')"></div>
  <div class="main">
    <div class="topbar">
      <button class="menu-toggle" onclick="document.getElementById('sidebar').classList.toggle('open');document.getElementById('overlay').classList.toggle('show')"><span></span></button>
      <div class="breadcrumb">Computational Social Science<span class="sep">/</span> Foundations<span class="sep">/</span> LLM &amp; NLP</div>
      <div class="topbar-lang">
        <button class="lang-btn" id="btn-zh" onclick="setLang('zh')">中文</button>
        <button class="lang-btn" id="btn-en" onclick="setLang('en')">EN</button>
      </div>
    </div>
    <div class="content">

      <!-- HEADER -->
      <div class="method-header">
        <h1>LLM &amp; NLP</h1>
        <div class="method-meta">Computational Social Science &middot; Foundations 02</div>
        <div data-lang="en"><p class="subtitle">Notes from CSE 5525, The Ohio State University &middot; <a href="https://shocheen.github.io/cse-5525-fall-2025/lectures/" target="_blank" style="color:var(--red);border-bottom:1px solid var(--red)">Lecture Slides</a> &middot; <a href="https://sites.google.com/view/sachinkumar" target="_blank" style="color:var(--red);border-bottom:1px solid var(--red)">Prof. Sachin Kumar</a></p></div>
        <div data-lang="zh"><p class="subtitle">笔记整理自 CSE 5525, The Ohio State University &middot; <a href="https://shocheen.github.io/cse-5525-fall-2025/lectures/" target="_blank" style="color:var(--red);border-bottom:1px solid var(--red)">课程讲义</a> &middot; <a href="https://sites.google.com/view/sachinkumar" target="_blank" style="color:var(--red);border-bottom:1px solid var(--red)">Prof. Sachin Kumar</a></p></div>
      </div>


      <!-- INTRO -->
      <div class="section">
        <div data-lang="en">
          <p>Natural Language Processing (NLP) teaches machines to understand and generate human language. Large Language Models (LLMs) like ChatGPT have made this field mainstream — but how do they actually work? This page walks through the key ideas from the ground up: how text becomes numbers, how models learn language patterns, and how raw models become the AI assistants we use today.</p>
        </div>
        <div data-lang="zh">
          <p>自然语言处理（NLP）让机器学会理解和生成人类语言。大语言模型（LLM）如 ChatGPT 让这个领域走入大众视野——但它们到底是怎么工作的？这个页面从零开始讲解核心概念：文本如何变成数字、模型如何学习语言规律、以及原始模型如何变成我们今天使用的 AI 助手。</p>
        </div>
      </div>

      <!-- EVOLUTION TIMELINE -->
      <div class="section">
        <h2 data-lang="en">The Evolution of NLP</h2>
        <h2 data-lang="zh">NLP 的演化</h2>
        <div class="evo">
          <div class="evo-step">
            <div class="evo-year">~2013</div>
            <div class="evo-name">Rule-based</div>
            <div class="evo-desc" data-lang="en">Hand-written rules</div>
            <div class="evo-desc" data-lang="zh">人工规则</div>
          </div>
          <div class="evo-step">
            <div class="evo-year">2013</div>
            <div class="evo-name">Word2Vec</div>
            <div class="evo-desc" data-lang="en">Words as vectors</div>
            <div class="evo-desc" data-lang="zh">词变向量</div>
          </div>
          <div class="evo-step">
            <div class="evo-year">2017</div>
            <div class="evo-name">Transformer</div>
            <div class="evo-desc" data-lang="en">Attention mechanism</div>
            <div class="evo-desc" data-lang="zh">注意力机制</div>
          </div>
          <div class="evo-step">
            <div class="evo-year">2018</div>
            <div class="evo-name">BERT</div>
            <div class="evo-desc" data-lang="en">Pre-train + fine-tune</div>
            <div class="evo-desc" data-lang="zh">预训练+微调</div>
          </div>
          <div class="evo-step now">
            <div class="evo-year">2020+</div>
            <div class="evo-name">GPT / LLMs</div>
            <div class="evo-desc" data-lang="en">Scale + prompting</div>
            <div class="evo-desc" data-lang="zh">规模+提示词</div>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ========== PART I: TEXT → NUMBERS ========== -->

      <div class="section">
        <h2 data-lang="en">From Text to Numbers</h2>
        <h2 data-lang="zh">从文本到数字</h2>
        <div data-lang="en">
          <p>Computers only understand numbers. Before any NLP task, we must convert words into numerical form. This section covers three approaches: simple counting, learned vectors, and how to break text into pieces.</p>
        </div>
        <div data-lang="zh">
          <p>计算机只懂数字。在任何 NLP 任务之前，我们必须把文字转换成数字形式。这部分介绍三种方法：简单计数、学习出的向量，以及如何把文本拆成小单元。</p>
        </div>

        <!-- Text Classification -->
        <div class="method-card">
          <span class="mc-tag rep">Representation</span>
          <h4 data-lang="en">Text Classification: From Naive Bayes to Neural Networks</h4>
          <h4 data-lang="zh">文本分类：从朴素贝叶斯到神经网络</h4>
          <div data-lang="en">
            <p>"Is this email spam or not?" — that's text classification: assigning a category to a piece of text. The simplest approach is <strong>Naive Bayes</strong>: count how often each word appears in each category, then use Bayes' theorem to compute probabilities. Despite its "naive" assumption that words are independent (obviously "New" and "York" aren't!), it works surprisingly well as a quick baseline.</p>
            <div class="formula">P(spam | email) ∝ P(spam) &times; P("free"|spam) &times; P("win"|spam) &times; ...</div>
            <p><strong>Logistic Regression</strong> is the next step up: it learns a weight for each word (positive = more likely this category, negative = less likely). The weights are interpretable — you can see exactly which words push toward "spam."</p>
            <p><strong>Neural classifiers</strong> go further: instead of hand-designed features, they automatically learn which patterns matter. The modern approach is to use a pre-trained model like BERT, add a classification layer on top, and fine-tune with a small labeled dataset.</p>
            <div class="eg">Sentiment analysis: "This movie was absolutely brilliant!" → The words "absolutely" and "brilliant" push the prediction toward positive. A neural model can even understand that "not bad" is positive, which word-counting methods miss.</div>
          </div>
          <div data-lang="zh">
            <p>"这封邮件是垃圾邮件吗？"——这就是文本分类：给一段文本分配一个类别。最简单的方法是<strong>朴素贝叶斯</strong>：统计每个词在每个类别中出现的频率，然后用贝叶斯定理计算概率。尽管它"天真地"假设词与词之间是独立的（"纽"和"约"显然不独立！），但作为快速基线效果出奇地好。</p>
            <div class="formula">P(垃圾邮件 | 邮件) ∝ P(垃圾邮件) &times; P("免费"|垃圾邮件) &times; P("中奖"|垃圾邮件) &times; ...</div>
            <p><strong>逻辑回归</strong>更进一步：它为每个词学习一个权重（正数 = 更可能是这个类别，负数 = 更不可能）。权重是可解释的——你能看到哪些词把预测推向"垃圾邮件"。</p>
            <p><strong>神经网络分类器</strong>再进一步：不用手动设计特征，让模型自动学习哪些模式重要。现代做法是用预训练模型（如 BERT），在上面加一个分类层，然后用少量标注数据微调。</p>
            <div class="eg">情感分析："这部电影简直太精彩了！" → "简直"和"精彩"这些词把预测推向正面。神经网络甚至能理解"还不错"是正面的，而简单的词频统计方法做不到。</div>
          </div>
        </div>

        <!-- Word Vectors -->
        <div class="method-card">
          <span class="mc-tag rep">Representation</span>
          <h4 data-lang="en">Word Vectors &amp; Embeddings</h4>
          <h4 data-lang="zh">词向量与嵌入</h4>
          <div data-lang="en">
            <p>The simplest way to represent a word is <strong>one-hot encoding</strong>: if your vocabulary has 50,000 words, each word becomes a vector with 49,999 zeros and one 1. Problem: "cat" and "dog" look equally different from each other as "cat" and "refrigerator" — there's no sense of meaning.</p>
            <div class="analogy">Imagine giving every student a locker number. Locker #234 and #235 are next to each other, but that tells you nothing about whether those students are similar. One-hot encoding is like locker numbers — arbitrary labels with no meaning.</div>
            <p><strong>Word2Vec</strong> (Google, 2013) solved this with a brilliant insight: train a simple neural network to predict surrounding words from a center word (or vice versa). The byproduct? Each word gets a dense vector (typically 300 numbers) where <em>similar words are close together</em>.</p>
            <div class="formula">vec("king") &minus; vec("man") + vec("woman") &asymp; vec("queen")</div>
            <p>This "word arithmetic" works because the model has learned that gender is a consistent direction in the vector space. <strong>GloVe</strong> achieves similar results by analyzing how often words co-occur across an entire corpus.</p>
            <div class="eg">"Paris" is to "France" as "Tokyo" is to "Japan" — Word2Vec encodes the capital-country relationship as a geometric pattern in vector space.</div>
          </div>
          <div data-lang="zh">
            <p>表示一个词最简单的方式是 <strong>One-Hot 编码</strong>：如果词汇表有 50,000 个词，每个词变成一个有 49,999 个零和 1 个一的向量。问题是："猫"和"狗"看起来跟"猫"和"冰箱"一样不同——完全没有语义信息。</p>
            <div class="analogy">想象给每个学生分配一个储物柜号。234 号和 235 号挨着，但这完全不能说明这两个学生相似。One-Hot 编码就像储物柜号——没有含义的随机标签。</div>
            <p><strong>Word2Vec</strong>（Google, 2013）用一个巧妙的想法解决了这个问题：训练一个简单的神经网络，从中心词预测周围的词（或反过来）。副产品是什么？每个词得到一个稠密的向量（通常 300 个数字），<em>意思相近的词在向量空间中靠得很近</em>。</p>
            <div class="formula">vec("国王") &minus; vec("男人") + vec("女人") &asymp; vec("女王")</div>
            <p>这种"词汇算术"之所以成立，是因为模型学到了性别是向量空间中一个一致的方向。<strong>GloVe</strong> 通过分析整个语料库中词的共现频率，达到类似效果。</p>
            <div class="eg">"巴黎"之于"法国"就像"东京"之于"日本"——Word2Vec 把首都-国家关系编码成了向量空间中的几何模式。</div>
          </div>
        </div>

        <!-- Tokenization -->
        <div class="method-card">
          <span class="mc-tag rep">Representation</span>
          <h4 data-lang="en">Tokenization: Breaking Text into Pieces</h4>
          <h4 data-lang="zh">分词：把文本拆成小块</h4>
          <div data-lang="en">
            <p>Before a model can process text, it needs to break it into pieces called <strong>tokens</strong>. Split by words? Problem: new words like "ChatGPT" aren't in the dictionary. Split by characters? Every word becomes a very long sequence, making learning hard.</p>
            <p>The modern solution is <strong>subword tokenization</strong> (e.g., BPE — Byte Pair Encoding): start with individual characters, then repeatedly merge the most frequent pairs. Common words stay whole ("the", "and"), while rare words get split into meaningful pieces ("unbelievable" → "un" + "believ" + "able"). This means "un-" and "-able" can be shared across many words.</p>
            <div class="analogy">It's like how Chinese characters work: you don't memorize a unique symbol for every concept. Instead, you combine radicals — "木" (wood) appears in "林" (forest) and "桌" (table). Subword tokenization does the same for English.</div>
            <p>GPT uses BPE, BERT uses WordPiece (similar idea), and <strong>SentencePiece</strong> works for any language — including Chinese, Japanese, and Korean, which don't use spaces between words.</p>
          </div>
          <div data-lang="zh">
            <p>模型处理文本之前，需要先把它拆成叫做 <strong>token</strong> 的小块。按词拆？问题是："ChatGPT"这样的新词不在词典里。按字符拆？每个词变成很长的序列，学习非常困难。</p>
            <p>现代的解决方案是<strong>子词分词</strong>（如 BPE——字节对编码）：从单个字符开始，反复合并最频繁出现的相邻对。常见词保持完整（"the"、"and"），罕见词被拆成有意义的片段（"unbelievable" → "un" + "believ" + "able"）。这意味着"un-"和"-able"可以在多个词之间共享。</p>
            <div class="analogy">就像中文汉字的工作方式：你不需要为每个概念记一个独特的符号，而是组合偏旁部首——"木"（木头）出现在"林"（森林）和"桌"（桌子）中。子词分词对英语做了同样的事。</div>
            <p>GPT 使用 BPE，BERT 使用 WordPiece（类似思路），而 <strong>SentencePiece</strong> 适用于任何语言——包括中文、日语和韩语这些词之间不用空格的语言。</p>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ========== PART II: LANGUAGE MODELS ========== -->

      <div class="section">
        <h2 data-lang="en">How Language Models Work</h2>
        <h2 data-lang="zh">语言模型的工作原理</h2>
        <div data-lang="en">
          <p>A language model predicts what word comes next. That's it. Your phone's autocomplete is a simple language model. ChatGPT is a very advanced one. The difference is in <em>how well</em> they predict — and that depends on the architecture.</p>
        </div>
        <div data-lang="zh">
          <p>语言模型的本质就是预测下一个词。就是这么简单。你手机的自动补全就是一个简单的语言模型，ChatGPT 是一个非常高级的语言模型。区别在于预测得<em>有多好</em>——这取决于模型架构。</p>
        </div>

        <!-- N-gram -->
        <div class="method-card">
          <span class="mc-tag arch">Architecture</span>
          <h4 data-lang="en">N-gram: The Simplest Language Model</h4>
          <h4 data-lang="zh">N-gram：最简单的语言模型</h4>
          <div data-lang="en">
            <p>The most basic approach: predict the next word based on the previous N&minus;1 words. A bigram model (N=2) only looks at the last word; a trigram (N=3) looks at the last two. Prediction is just counting: "How often does word X appear after words A B?"</p>
            <div class="formula">P("good" | "weather is") = count("weather is good") / count("weather is")</div>
            <p>We measure language models using <strong>perplexity</strong> — think of it as "how many words the model is choosing between on average." Lower = better. A random guess over 50,000 words gives perplexity of 50,000; a decent N-gram model might get 200.</p>
            <div class="when"><strong>Limitation:</strong> N-grams can only look back 3-5 words. They can't understand "The cat that the dog chased <em>ran</em> away" because "cat" and "ran" are too far apart.</div>
          </div>
          <div data-lang="zh">
            <p>最基础的方法：根据前面 N&minus;1 个词预测下一个词。二元模型（N=2）只看最后一个词；三元模型（N=3）看最后两个。预测就是数频率："在'天气很'后面，'好'出现了多少次？"</p>
            <div class="formula">P("好" | "天气很") = count("天气很好") / count("天气很")</div>
            <p>我们用<strong>困惑度（Perplexity）</strong>来衡量语言模型——可以理解为"模型平均在多少个词之间犹豫不决"。越低越好。在 50,000 个词中随机猜的困惑度是 50,000；一个不错的 N-gram 模型可能达到 200。</p>
            <div class="when"><strong>局限：</strong>N-gram 只能回看 3-5 个词。它无法理解"那只被狗追的猫<em>跑</em>掉了"，因为"猫"和"跑"之间隔得太远。</div>
          </div>
        </div>

        <!-- Transformer -->
        <div class="method-card">
          <span class="mc-tag arch">Architecture</span>
          <h4 data-lang="en">The Transformer: Attention Is All You Need</h4>
          <h4 data-lang="zh">Transformer：注意力就是你需要的一切</h4>
          <div data-lang="en">
            <p>The 2017 paper that changed everything. The key idea is <strong>self-attention</strong>: instead of reading text one word at a time (like older models), every word can directly look at every other word in the sentence at once.</p>
            <p>How? Each word creates three things: a <strong>Query</strong> ("what am I looking for?"), a <strong>Key</strong> ("what do I contain?"), and a <strong>Value</strong> ("what information do I carry?"). Attention scores are computed by matching Queries with Keys, then using those scores to weight the Values:</p>
            <div class="formula">Attention(Q, K, V) = softmax(QK&#x1D40; / &radic;d) &times; V</div>
            <div class="analogy">Imagine a classroom where every student can whisper to every other student at the same time. Each student asks a question (Query), everyone else holds up a sign saying how relevant they are (Key), and the asker collects answers (Value) weighted by relevance. That's self-attention.</div>
            <p><strong>Multi-Head Attention</strong> runs this process multiple times in parallel (usually 8-16 "heads"), so the model can pay attention to different types of relationships simultaneously — one head might focus on grammar, another on meaning.</p>
          </div>
          <div data-lang="zh">
            <p>2017 年改变一切的论文。核心思想是<strong>自注意力（Self-Attention）</strong>：不再像老模型那样逐词阅读文本，而是让每个词同时直接看到句子中的所有其他词。</p>
            <p>怎么做到的？每个词生成三样东西：<strong>Query</strong>（"我在找什么？"）、<strong>Key</strong>（"我包含什么？"）、<strong>Value</strong>（"我携带什么信息？"）。通过 Query 和 Key 的匹配计算注意力分数，然后用分数对 Value 加权求和：</p>
            <div class="formula">Attention(Q, K, V) = softmax(QK&#x1D40; / &radic;d) &times; V</div>
            <div class="analogy">想象一个教室里，每个学生可以同时跟所有其他学生低声交流。每个学生提出一个问题（Query），其他人举牌表示自己的相关性（Key），提问者根据相关性收集答案（Value）。这就是自注意力。</div>
            <p><strong>Multi-Head Attention</strong> 把这个过程并行跑多次（通常 8-16 个"头"），这样模型可以同时关注不同类型的关系——一个头可能关注语法，另一个关注语义。</p>
          </div>
        </div>

        <!-- BERT vs GPT -->
        <div class="method-card">
          <span class="mc-tag arch">Architecture</span>
          <h4 data-lang="en">BERT vs. GPT: Two Ways to Use a Transformer</h4>
          <h4 data-lang="zh">BERT vs. GPT：Transformer 的两种用法</h4>
          <div data-lang="en">
            <p>The Transformer architecture can be used in different ways, and this choice has huge implications:</p>
          </div>
          <div data-lang="zh">
            <p>Transformer 架构有不同的使用方式，这个选择影响深远：</p>
          </div>
          <div class="compare-grid">
            <div class="compare-col">
              <div class="compare-label">BERT (Encoder)</div>
              <div data-lang="en">
                <p><strong>Sees:</strong> Both left and right context (bidirectional)</p>
                <p><strong>Pre-training:</strong> Fill in the blank — mask 15% of words, predict what's missing</p>
                <p><strong>Good at:</strong> Understanding text — classification, question answering, information extraction</p>
                <p><strong>Usage:</strong> Pre-train once, then fine-tune with labeled data for your task</p>
              </div>
              <div data-lang="zh">
                <p><strong>能看到：</strong>左右两边的上下文（双向）</p>
                <p><strong>预训练方式：</strong>完形填空——遮住 15% 的词，预测被遮的是什么</p>
                <p><strong>擅长：</strong>理解文本——分类、问答、信息提取</p>
                <p><strong>使用方式：</strong>预训练一次，然后用标注数据为你的任务微调</p>
              </div>
            </div>
            <div class="compare-col alt">
              <div class="compare-label">GPT (Decoder)</div>
              <div data-lang="en">
                <p><strong>Sees:</strong> Only what came before (left-to-right)</p>
                <p><strong>Pre-training:</strong> Predict the next word — read left to right, guess what follows</p>
                <p><strong>Good at:</strong> Generating text — writing, dialogue, code, creative tasks</p>
                <p><strong>Usage:</strong> Pre-train once, then use with prompts (no fine-tuning needed)</p>
              </div>
              <div data-lang="zh">
                <p><strong>能看到：</strong>只有前面的内容（从左到右）</p>
                <p><strong>预训练方式：</strong>预测下一个词——从左到右阅读，猜后面是什么</p>
                <p><strong>擅长：</strong>生成文本——写作、对话、代码、创意任务</p>
                <p><strong>使用方式：</strong>预训练一次，然后用提示词使用（不需要微调）</p>
              </div>
            </div>
            <div class="compare-footer" data-lang="en">Today's trend: GPT-style (decoder-only) dominates. Bigger models + simple "predict next word" = surprisingly powerful general intelligence.</div>
            <div class="compare-footer" data-lang="zh">当今趋势：GPT 路线（纯解码器）占据主流。更大的模型 + 简单的"预测下一个词" = 令人惊讶的通用智能。</div>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ========== PART III: TRAINING & ALIGNMENT ========== -->

      <div class="section">
        <h2 data-lang="en">From Raw Model to AI Assistant</h2>
        <h2 data-lang="zh">从原始模型到 AI 助手</h2>
        <div data-lang="en">
          <p>A pre-trained model only knows how to complete text — it doesn't know how to be helpful. Turning it into ChatGPT requires three more steps: scale it up, teach it to follow instructions, and align it with human preferences.</p>
        </div>
        <div data-lang="zh">
          <p>预训练模型只会补全文本——它不知道怎么才有用。把它变成 ChatGPT 还需要三步：扩大规模、教它遵循指令、让它符合人类偏好。</p>
        </div>

        <!-- Scaling -->
        <div class="method-card">
          <span class="mc-tag train">Training</span>
          <h4 data-lang="en">Scaling Laws: Bigger = Better (Predictably)</h4>
          <h4 data-lang="zh">缩放定律：越大越好（而且可预测）</h4>
          <div data-lang="en">
            <p>One of the most surprising discoveries in AI: model performance improves <em>predictably</em> as you increase three things — model size, training data, and compute. Double the parameters? Performance improves by a predictable amount. This is called a <strong>scaling law</strong>.</p>
            <p>Even more surprising: at certain scale thresholds, models suddenly gain abilities they completely lacked before — multi-step reasoning, complex math, understanding jokes. These <strong>emergent abilities</strong> can't be predicted from smaller models. It's as if the model "clicks" at a certain size.</p>
            <div class="analogy">Think of learning a language: for months you understand nothing, then suddenly things start clicking and you can hold a conversation. LLMs seem to experience similar "phase transitions" as they scale up.</div>
            <p>The <strong>Chinchilla law</strong> (DeepMind, 2022) added an important insight: many early models were too big for their training data. The optimal strategy is to scale model size and data <em>equally</em>.</p>
          </div>
          <div data-lang="zh">
            <p>AI 领域最令人惊讶的发现之一：模型性能随着三个因素<em>可预测地</em>提升——模型大小、训练数据量、计算量。参数翻倍？性能提升可预测的幅度。这就是<strong>缩放定律</strong>。</p>
            <p>更惊人的是：在某些规模临界点上，模型突然获得之前完全没有的能力——多步推理、复杂数学、理解笑话。这些<strong>涌现能力</strong>无法从小模型的表现中预测。就好像模型在某个大小上"开窍"了。</p>
            <div class="analogy">想想学外语的过程：几个月什么都听不懂，然后突然有一天开始"顿悟"，能进行对话了。LLM 在规模扩大时似乎经历类似的"相变"。</div>
            <p><strong>Chinchilla 定律</strong>（DeepMind, 2022）补充了一个重要发现：很多早期模型对于它们的训练数据来说太大了。最优策略是让模型大小和数据量<em>等比例</em>增长。</p>
          </div>
        </div>

        <!-- Prompting -->
        <div class="method-card">
          <span class="mc-tag train">Training</span>
          <h4 data-lang="en">Prompting: Using LLMs Without Training</h4>
          <h4 data-lang="zh">提示词：不用训练就能使用 LLM</h4>
          <div data-lang="en">
            <p>One of the most magical properties of large models: you can get them to do new tasks just by <em>describing the task in words</em>, with no additional training. This is called <strong>prompting</strong>, and it comes in three flavors:</p>
            <p><strong>Zero-shot:</strong> Just describe what you want. "Translate this to French: Hello" → "Bonjour"</p>
            <p><strong>Few-shot:</strong> Give a few examples, and the model learns the pattern. "cat→chat, dog→chien, bird→?" → "oiseau"</p>
            <p><strong>Chain-of-Thought:</strong> Ask the model to "think step by step." This dramatically improves reasoning, especially for math and logic.</p>
            <div class="eg">"Roger has 5 tennis balls. He buys 2 cans of 3 balls each. How many does he have now? Let's think step by step: He started with 5. He bought 2&times;3 = 6 more. Total: 5 + 6 = 11."</div>
            <div class="when"><strong>Key insight:</strong> In-context learning doesn't change any model parameters. The model simply "reads" your examples through its attention mechanism and mimics the pattern — a remarkable emergent property of the Transformer.</div>
          </div>
          <div data-lang="zh">
            <p>大模型最神奇的特性之一：你只需要<em>用文字描述任务</em>，不需要额外训练，模型就能完成新任务。这叫做<strong>提示词（Prompting）</strong>，有三种方式：</p>
            <p><strong>零样本（Zero-shot）：</strong>直接描述你想要什么。"把这句翻译成法语：你好" → "Bonjour"</p>
            <p><strong>少样本（Few-shot）：</strong>给几个例子，模型学习模式。"猫→cat, 狗→dog, 鸟→?" → "bird"</p>
            <p><strong>思维链（Chain-of-Thought）：</strong>让模型"一步步想"。这对推理能力有巨大提升，尤其是数学和逻辑题。</p>
            <div class="eg">"Roger 有 5 个网球。他又买了 2 罐，每罐 3 个。他现在有多少？让我们一步步想：他原来有 5 个，买了 2&times;3 = 6 个，总共 5 + 6 = 11 个。"</div>
            <div class="when"><strong>关键洞察：</strong>上下文学习不改变任何模型参数。模型只是通过注意力机制"读懂"你给的例子并模仿模式——这是 Transformer 架构一个了不起的涌现特性。</div>
          </div>
        </div>

        <!-- SFT + RLHF -->
        <div class="method-card">
          <span class="mc-tag train">Training</span>
          <h4 data-lang="en">Instruction Tuning &amp; RLHF: Teaching Models to Be Helpful</h4>
          <h4 data-lang="zh">指令微调与 RLHF：教模型变得有用</h4>
          <div data-lang="en">
            <p>A raw GPT model is like a very well-read person who only knows how to continue a conversation, but doesn't know how to <em>help</em> you. Two more training stages fix this:</p>
            <p><strong>Step 1 — Supervised Fine-Tuning (SFT):</strong> Show the model thousands of examples of "good assistant behavior" — questions paired with high-quality answers. This teaches it to respond helpfully instead of just completing text. InstructGPT used only ~13,000 such examples yet dramatically improved response quality.</p>
            <p><strong>Step 2 — RLHF (Reinforcement Learning from Human Feedback):</strong> Human preferences are subtle — it's hard to write down exactly what makes a "good" answer. So instead, humans rank multiple model responses ("Response A is better than Response B"), and the model learns from these preferences.</p>
            <div class="analogy">SFT is like showing a new employee examples of good customer service emails. RLHF is like having a manager review their drafts and say "this version is better" — the employee gradually learns the company's communication style without anyone writing explicit rules.</div>
            <p><strong>DPO (Direct Preference Optimization)</strong> is a simpler alternative to RLHF: skip the reward model, directly optimize from preference pairs. Mathematically equivalent, but much easier to implement.</p>
          </div>
          <div data-lang="zh">
            <p>原始 GPT 模型就像一个博览群书的人，只会接着别人说的话往下讲，但不知道怎么<em>帮助</em>你。两个额外的训练阶段解决了这个问题：</p>
            <p><strong>第一步——有监督微调（SFT）：</strong>给模型看成千上万个"好助手行为"的示例——问题配上高质量回答。这教会它有用地回答，而不是只续写文本。InstructGPT 只用了约 13,000 条这样的示例，就大幅提升了回答质量。</p>
            <p><strong>第二步——RLHF（基于人类反馈的强化学习）：</strong>人类偏好是微妙的——很难明确写下什么是"好"回答。所以让人类对模型的多个回答排名（"回答 A 比回答 B 好"），模型从这些偏好中学习。</p>
            <div class="analogy">SFT 就像给新员工看优秀客服邮件的范例。RLHF 就像让经理审阅他们的草稿说"这个版本更好"——员工逐渐学会公司的沟通风格，而不需要任何人写明确的规则。</div>
            <p><strong>DPO（直接偏好优化）</strong>是 RLHF 的更简洁替代方案：跳过奖励模型，直接从偏好对中优化。数学上等价，但实现简单得多。</p>
          </div>
        </div>

        <!-- Evaluation -->
        <div class="info-box">
          <div class="label" data-lang="en">How Do We Know If an LLM Is Good?</div>
          <div class="label" data-lang="zh">怎么判断 LLM 好不好？</div>
          <div data-lang="en">
            <p><strong>Benchmarks</strong> (MMLU for knowledge, HumanEval for coding, GSM8K for math) provide standardized tests, but models can overfit to them. <strong>Human evaluation</strong> (like Chatbot Arena where people vote on which response is better) is the gold standard but expensive. <strong>LLM-as-Judge</strong> uses a strong model like GPT-4 to evaluate others — cheap but potentially biased. Beware of <strong>data contamination</strong>: if test questions leaked into training data, scores are meaningless.</p>
          </div>
          <div data-lang="zh">
            <p><strong>基准测试</strong>（MMLU 测知识、HumanEval 测编程、GSM8K 测数学）提供标准化考试，但模型可能过拟合。<strong>人类评估</strong>（如 Chatbot Arena 让人投票哪个回答更好）是金标准但昂贵。<strong>LLM 当评委</strong>用 GPT-4 之类的强模型评判其他模型——便宜但可能有偏差。要警惕<strong>数据污染</strong>：如果测试题泄漏到了训练数据里，分数就没有意义。</p>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ========== PART IV: MAKING LLMS PRACTICAL ========== -->

      <div class="section">
        <h2 data-lang="en">Making LLMs Practical</h2>
        <h2 data-lang="zh">让 LLM 变得实用</h2>
        <div data-lang="en">
          <p>LLMs are powerful but face three real-world problems: they're expensive to customize, their knowledge has a cutoff date, and they can only generate text. Here's how each is being solved.</p>
        </div>
        <div data-lang="zh">
          <p>LLM 很强大，但面临三个现实问题：定制成本高、知识有截止日期、只能生成文字。以下是每个问题的解决方案。</p>
        </div>

        <!-- LoRA -->
        <div class="method-card">
          <span class="mc-tag app">Application</span>
          <h4 data-lang="en">LoRA: Fine-Tuning on a Budget</h4>
          <h4 data-lang="zh">LoRA：低成本微调</h4>
          <div data-lang="en">
            <p>Fine-tuning a 70-billion-parameter model normally requires hundreds of GB of GPU memory — out of reach for most people. <strong>LoRA (Low-Rank Adaptation)</strong> offers an elegant shortcut: freeze the original model and only train tiny "adapter" matrices added beside each layer.</p>
            <div class="formula">W' = W + BA, where B is d&times;r and A is r&times;d, with r typically 4-64 (vs. d in the thousands)</div>
            <div class="analogy">Instead of remodeling your entire house for a new purpose, you just add a small extension. The original structure stays intact, but you get the new functionality you need.</div>
            <p>Result: 10&times; less memory, training costs drop dramatically, and performance is nearly identical to full fine-tuning. <strong>QLoRA</strong> goes even further — combining 4-bit quantization with LoRA to fine-tune a 65B model on a single consumer GPU.</p>
          </div>
          <div data-lang="zh">
            <p>微调一个 700 亿参数的模型通常需要数百 GB 的 GPU 显存——大多数人根本做不到。<strong>LoRA（低秩适应）</strong>提供了一个优雅的捷径：冻结原始模型，只训练附加在每层旁边的微小"适配器"矩阵。</p>
            <div class="formula">W' = W + BA，其中 B 是 d&times;r，A 是 r&times;d，r 通常只有 4-64（而 d 是几千）</div>
            <div class="analogy">不用为了新用途重建整栋房子，只需加一个小扩建。原始结构完好，但你获得了需要的新功能。</div>
            <p>效果：显存减少 10 倍以上，训练成本大幅下降，性能几乎和全量微调一样好。<strong>QLoRA</strong> 更进一步——把 4-bit 量化和 LoRA 结合，在一张消费级 GPU 上微调 650 亿参数的模型。</p>
          </div>
        </div>

        <!-- RAG -->
        <div class="method-card">
          <span class="mc-tag app">Application</span>
          <h4 data-lang="en">RAG: Giving LLMs Access to Fresh Knowledge</h4>
          <h4 data-lang="zh">RAG：给 LLM 接入最新知识</h4>
          <div data-lang="en">
            <p>LLMs have a knowledge cutoff date and sometimes "hallucinate" — confidently stating things that aren't true. <strong>RAG (Retrieval-Augmented Generation)</strong> fixes this by having the model look up information before answering.</p>
            <p>How it works: Your question gets converted into a vector → The system searches a database of documents for the most relevant passages → Those passages are fed to the LLM as context → The LLM generates an answer based on the retrieved information.</p>
            <div class="analogy">It's the difference between answering from memory (might be wrong or outdated) vs. looking it up in a reference book first, then answering. RAG gives the LLM a "reference library" to consult.</div>
            <div class="when"><strong>When to use:</strong> Need up-to-date information, need to cite sources, need to reduce hallucinations, enterprise Q&amp;A over internal documents.</div>
          </div>
          <div data-lang="zh">
            <p>LLM 的知识有截止日期，有时还会"幻觉"——自信地说出不真实的事情。<strong>RAG（检索增强生成）</strong>通过让模型在回答前先查找信息来解决这个问题。</p>
            <p>工作流程：你的问题被转换成向量 → 系统在文档数据库中搜索最相关的段落 → 这些段落作为上下文输入给 LLM → LLM 基于检索到的信息生成回答。</p>
            <div class="analogy">就像凭记忆回答问题（可能出错或过时）和先翻参考书再回答的区别。RAG 给了 LLM 一个可以查阅的"参考图书馆"。</div>
            <div class="when"><strong>适用场景：</strong>需要最新信息、需要引用来源、需要减少幻觉、企业内部文档问答。</div>
          </div>
        </div>

        <!-- Multimodal -->
        <div class="method-card">
          <span class="mc-tag app">Application</span>
          <h4 data-lang="en">Multimodal LLMs: Beyond Text</h4>
          <h4 data-lang="zh">多模态 LLM：超越文本</h4>
          <div data-lang="en">
            <p>Modern LLMs aren't limited to text. By connecting a <strong>vision encoder</strong> (like CLIP) to the language model, they can understand images too. Show it a photo of a restaurant menu and ask "What vegetarian options are there?" — it reads the image, understands the menu, and answers.</p>
            <p>Representative models: <strong>GPT-4V</strong>, <strong>Gemini</strong>, <strong>LLaVA</strong>. They can describe images, answer visual questions, analyze charts, and even understand memes.</p>
          </div>
          <div data-lang="zh">
            <p>现代 LLM 不限于文本。通过连接一个<strong>视觉编码器</strong>（如 CLIP）到语言模型，它们也能理解图像。给它看一张餐厅菜单的照片问"有什么素食选项？"——它读取图像、理解菜单、然后回答。</p>
            <p>代表模型：<strong>GPT-4V</strong>、<strong>Gemini</strong>、<strong>LLaVA</strong>。它们能描述图片、回答视觉问题、分析图表，甚至理解表情包。</p>
          </div>
        </div>

        <!-- Agents -->
        <div class="method-card">
          <span class="mc-tag app">Application</span>
          <h4 data-lang="en">Language Agents: LLMs That Take Action</h4>
          <h4 data-lang="zh">语言智能体：能采取行动的 LLM</h4>
          <div data-lang="en">
            <p>Regular LLMs can only generate text. <strong>Language agents</strong> give LLMs the ability to use tools — search the web, run code, call APIs, operate software. This transforms them from "can talk" to "can do."</p>
            <p>The core framework is <strong>ReAct</strong> (Reasoning + Acting): the model alternates between thinking ("I need to find the current price") and acting ("Let me search the web for..."), looping until the task is done.</p>
            <div class="eg">"Book me the cheapest flight to Beijing tomorrow" — the agent searches flight options, compares prices, selects the best one, and completes the booking. The entire workflow is planned and executed by the LLM.</div>
            <div class="when"><strong>Trend:</strong> Agents are the frontier of LLM applications — from coding assistants to research automation to personal productivity tools.</div>
          </div>
          <div data-lang="zh">
            <p>普通 LLM 只能生成文字。<strong>语言智能体</strong>赋予 LLM 使用工具的能力——搜索网页、运行代码、调用 API、操作软件。这让它们从"会说话"变成"会做事"。</p>
            <p>核心框架是 <strong>ReAct</strong>（推理 + 行动）：模型在"思考"（"我需要查找当前价格"）和"行动"（"让我搜索一下..."）之间交替循环，直到任务完成。</p>
            <div class="eg">"帮我订明天飞北京最便宜的机票" — 智能体搜索航班选项、比较价格、选出最佳、完成预订。整个流程由 LLM 规划和执行。</div>
            <div class="when"><strong>趋势：</strong>智能体是 LLM 应用的前沿方向——从编程助手到科研自动化到个人生产力工具。</div>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ========== PART V: NLP TOOLKIT ========== -->

      <div class="section">
        <h2 data-lang="en">The NLP Toolkit</h2>
        <h2 data-lang="zh">NLP 工具箱</h2>
        <div data-lang="en">
          <p>Beyond LLMs, traditional NLP tools handle essential tasks like identifying names, analyzing grammar, and extracting structured information from text.</p>
        </div>
        <div data-lang="zh">
          <p>除了 LLM，传统 NLP 工具处理识别人名、分析语法、从文本中提取结构化信息等基础任务。</p>
        </div>

        <div class="method-card">
          <span class="mc-tag rep">NLP Pipeline</span>
          <h4 data-lang="en">NER, POS Tagging &amp; Dependency Parsing</h4>
          <h4 data-lang="zh">命名实体识别、词性标注与依存句法分析</h4>
          <div data-lang="en">
            <p>The classic NLP pipeline: <strong>Tokenization</strong> (split into words) → <strong>POS Tagging</strong> (noun? verb? adjective?) → <strong>NER</strong> (is "Apple" a fruit or a company?) → <strong>Dependency Parsing</strong> (which word modifies which?).</p>
            <p>Modern tools like <strong>spaCy</strong> handle this entire pipeline in one line of code. While LLMs can also do these tasks, dedicated NLP pipelines are faster, cheaper, and more reliable for structured extraction.</p>
            <div class="eg">From the sentence "Apple CEO Tim Cook announced the new iPhone in Cupertino" — NER extracts: Apple (ORG), Tim Cook (PERSON), iPhone (PRODUCT), Cupertino (LOC).</div>
          </div>
          <div data-lang="zh">
            <p>经典 NLP 流水线：<strong>分词</strong>（拆成词）→ <strong>词性标注</strong>（名词？动词？形容词？）→ <strong>命名实体识别 NER</strong>（"苹果"是水果还是公司？）→ <strong>依存句法分析</strong>（哪个词修饰哪个词？）。</p>
            <p>现代工具如 <strong>spaCy</strong> 一行代码就能完成整个流水线。虽然 LLM 也能做这些任务，但专用 NLP 流水线在结构化提取方面更快、更便宜、更可靠。</p>
            <div class="eg">从句子"苹果公司 CEO 库克在库比蒂诺发布了新 iPhone"中——NER 提取：苹果公司（机构）、库克（人名）、iPhone（产品）、库比蒂诺（地名）。</div>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ========== PART VI: ETHICS ========== -->

      <div class="section">
        <h2 data-lang="en">Ethics &amp; Broader Implications</h2>
        <h2 data-lang="zh">伦理与更广泛的影响</h2>
        <div data-lang="en">
          <p>LLMs bring enormous capabilities but also serious questions that researchers and practitioners must grapple with.</p>
        </div>
        <div data-lang="zh">
          <p>LLM 带来了巨大能力，也带来了研究者和从业者必须面对的严肃问题。</p>
        </div>

        <div class="card-row">
          <div class="card">
            <h4 data-lang="en">Bias</h4>
            <h4 data-lang="zh">偏见</h4>
            <div data-lang="en">
              <ul>
                <li>Models learn from internet text, which contains societal biases</li>
                <li>Word2Vec: "doctor" closer to "male", "nurse" to "female"</li>
                <li>Mitigation: debiased data, RLHF fairness constraints, continuous auditing</li>
              </ul>
            </div>
            <div data-lang="zh">
              <ul>
                <li>模型从互联网文本中学习，而互联网充满社会偏见</li>
                <li>Word2Vec 中"医生"更接近"男性"，"护士"更接近"女性"</li>
                <li>缓解措施：去偏数据、RLHF 公平性约束、持续审计</li>
              </ul>
            </div>
          </div>
          <div class="card highlight">
            <div class="card-tag" data-lang="en">Open Challenge</div>
            <div class="card-tag" data-lang="zh">开放挑战</div>
            <h4 data-lang="en">Interpretability</h4>
            <h4 data-lang="zh">可解释性</h4>
            <div data-lang="en">
              <ul>
                <li>Billions of parameters = "black box"</li>
                <li>Methods: attention visualization, probing, feature attribution</li>
                <li>Caveat: high attention ≠ causal explanation</li>
              </ul>
            </div>
            <div data-lang="zh">
              <ul>
                <li>数十亿参数 = "黑箱"</li>
                <li>方法：注意力可视化、探针实验、特征归因</li>
                <li>注意：高注意力 ≠ 因果解释</li>
              </ul>
            </div>
          </div>
          <div class="card">
            <h4 data-lang="en">Multilinguality</h4>
            <h4 data-lang="zh">多语言</h4>
            <div data-lang="en">
              <ul>
                <li>7000+ languages, but most LLMs are English-centric</li>
                <li>Surprise: multilingual models enable zero-shot cross-lingual transfer</li>
                <li>Challenge: low-resource languages still perform poorly — a digital divide</li>
              </ul>
            </div>
            <div data-lang="zh">
              <ul>
                <li>全球 7000+ 种语言，但多数 LLM 以英语为中心</li>
                <li>惊喜：多语言模型实现零样本跨语言迁移</li>
                <li>挑战：低资源语言效果仍然很差——数字鸿沟</li>
              </ul>
            </div>
          </div>
        </div>
      </div>

      <hr class="section-divider">

      <!-- ========== REFERENCES & SOFTWARE ========== -->

      <div class="section">
        <h2 data-lang="en">References &amp; Software</h2>
        <h2 data-lang="zh">参考文献与软件</h2>
        <h3 data-lang="en">Key References</h3>
        <h3 data-lang="zh">核心文献</h3>
        <ul class="ref-list">
          <li><span class="ref-tag beginner">Beginner</span>Jurafsky, D. &amp; Martin, J. H. (2024). <em>Speech and Language Processing</em> (3rd ed. draft). <a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank">https://web.stanford.edu/~jurafsky/slp3/</a></li>
          <li><span class="ref-tag fit">Transformer</span>Vaswani, A. et al. (2017). Attention is all you need. <em>NeurIPS</em>.</li>
          <li><span class="ref-tag">BERT</span>Devlin, J. et al. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. <em>NAACL-HLT</em>.</li>
          <li><span class="ref-tag applied">Scaling</span>Kaplan, J. et al. (2020). Scaling laws for neural language models. <em>arXiv:2001.08361</em>.</li>
          <li><span class="ref-tag">RLHF</span>Ouyang, L. et al. (2022). Training language models to follow instructions with human feedback. <em>NeurIPS</em>.</li>
          <li><span class="ref-tag">LoRA</span>Hu, E. J. et al. (2022). LoRA: Low-rank adaptation of large language models. <em>ICLR</em>.</li>
          <li><span class="ref-tag applied">RAG</span>Lewis, P. et al. (2020). Retrieval-augmented generation for knowledge-intensive NLP tasks. <em>NeurIPS</em>.</li>
        </ul>
        <h3 data-lang="en">Software</h3>
        <h3 data-lang="zh">软件工具</h3>
        <div class="sw-row">
          <div class="sw-pill gold">
            <h4>HuggingFace Transformers</h4>
            <div data-lang="en"><p>The hub for pre-trained models. BERT, GPT-2, LLaMA, and thousands more. Fine-tuning and inference in Python.</p></div>
            <div data-lang="zh"><p>预训练模型中心。BERT、GPT-2、LLaMA 及数千种模型。Python 微调和推理。</p></div>
          </div>
          <div class="sw-pill">
            <h4>spaCy</h4>
            <div data-lang="en"><p>Production NLP pipeline. Tokenization, POS, NER, dependency parsing. Fast and easy to use.</p></div>
            <div data-lang="zh"><p>生产级 NLP 流水线。分词、词性标注、NER、依存分析。快速易用。</p></div>
          </div>
          <div class="sw-pill">
            <h4>OpenAI / Anthropic APIs</h4>
            <div data-lang="en"><p>Access GPT-4, Claude, etc. via API. Zero-shot classification, text generation, embeddings.</p></div>
            <div data-lang="zh"><p>通过 API 使用 GPT-4、Claude 等。零样本分类、文本生成、嵌入向量。</p></div>
          </div>
        </div>
      </div>

      <!-- PAGE NAV -->
      <div class="page-nav">
        <a href="machine-learning.html">
          <div class="nav-label">&larr; Previous</div>
          <div class="nav-title">Machine Learning</div>
        </a>
        <a class="next" href="text-analysis.html">
          <div class="nav-label">Next &rarr;</div>
          <div class="nav-title">Text Analysis</div>
        </a>
      </div>

    </div>
  </div>
</div>

<script>
function setLang(lang){
  document.body.className=lang==='zh'?'zh':'';
  document.getElementById('btn-en').className='lang-btn'+(lang==='en'?' active':'');
  document.getElementById('btn-zh').className='lang-btn'+(lang==='zh'?' active':'');
  localStorage.setItem('selectedLang',lang);
}
window.addEventListener('DOMContentLoaded',function(){
  var lang=localStorage.getItem('selectedLang')||'zh';
  setLang(lang);
});
</script>
</body>
</html>
